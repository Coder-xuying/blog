# 四、MySQL篇

### WhyMysql？

NoSQL数据库四大家族 

- 列存储 Hbase
- K-V存储 Redis
- 图像存储 Neo4j
- 文档存储 MongoDB

云存储OSS

#### 海量Aerospike

​	Aerospike（简称AS）是一个分布式，可扩展的键值存储的NoSQL**数据库**。T级别大数据高并发的结构化**数据存储，**采用混合架构，索引存储在内存中，而数据可存储在机械硬盘(HDD)或固态硬盘(SSD) 上，读写操作达微妙级，99%的响应可在1毫秒内实现。

|          | Aerospike                            | Redis                        |
| -------- | ------------------------------------ | ---------------------------- |
| 类型     | Nosql数据库                          | 缓存                         |
| 线程数   | 多线程                               | 单线程                       |
| 数据分片 | 自动处理相当于分片                   | 提供分片算法、平衡各分片数据 |
| 数据扩容 | 动态增加数据卷平衡流量               | 需停机                       |
| 数据同步 | 设置复制因子后可以透明的完成故障转移 | 手动故障转移和数据同步       |
| 载体     | 内存存储索引+SSD存储数据             | 内存                         |

​	Aerospike作为一个大容量的NoSql解决方案，适合对**容量要求比较大，QPS相对低**一些的场景，主要用在广告行业，**个性化推荐厂告**是建立在了和掌握消费者独特的偏好和习性的基础之上，对消费者的购买需求做出准确的预测或引导，在合适的位置、合适的时间，以合适的形式向消费者呈现与其需求高度吻合的广告，以此来促进用户的消费行为。

<img src="https://tva1.sinaimg.cn/large/0081Kckwly1gmam43b44bj30d90d4aa7.jpg" alt="image-20210103170039711" style="zoom:50%;" />

​	（ETL数据仓库技术）抽取（extract）、转换（transform）、加载（load）

- 用户行为日志收集系统收集日志之后推送到ETL做数据的清洗和转换

- 把ETL过后的数据发送到推荐引擎计算每个消费者的推荐结果，其中推荐逻辑包括规则和算法两部分

- 收集用户最近浏览、最长停留等特征，分析商品相似性、用户相似性、相似性等算法。

- 把推荐引擎的结果存入Aerospike集群中，并提供给广告投放引擎实时获取

  分别通过HDFS和HBASE对日志进行离线和实时的分析，然后把用户画像的标签(tag : 程序猿、宅男...)结果存入高性能的Nosql数据库Aerospike中，同时把数据备份到异地数据中心。前端广告投放请求通过决策引擎（投放引擎）向用户画像数据库中读取相应的用户画像数据，然后根据竞价算法出价进行竞价。竞价成功之后就可以展现广告了。而在竞价成功之后，具体给用户展现什么样的广告，就是有上面说的个性化推荐广告来完成的。

|      | Aerospike      | Mysql    |
| ---- | -------------- | -------- |
| 库名 | Namespace      | Database |
| 表名 | Set            | Table    |
| 记录 | Bin            | Column   |
| 字段 | Record         | Row      |
| 索引 | key 、 pk 、kv | pk       |



#### 图谱Neo4j

> Neo4j是一个开源基于java开发的图形noSql数据库，它将结构化数据存储在图中而不是表中。它是一个嵌入式的、基于磁盘的、具备完全的事务特性的Java持久化引擎。程序数据是在一个面向对象的、灵活的网络结构下，而不是严格的表中，但具备完全的事务特性、企业级的数据库的所有好处。

一种基于图的数据结构，由节点(Node)和边(Edge)组成。其中节点即实体，由一个全局唯一的ID标示，边就是关系用于连接两个节点。通俗地讲，知识图谱就是把所有不同种类的信息，连接在一起而得到的一个关系网络。知识图谱提供了从“关系”的角度去分析问题的能力。

互联网、大数据的背景下，谷歌、百度、搜狗等搜索引擎纷纷基于该背景，创建自己的知识图**Knowledge Graph（谷歌**）、**知心（百度）**和**知立方（搜狗）**，主要用于改进搜索质量。

自己项目主要用作好友推荐，图数据库(Graph database)指的是以图数据结构的形式来存储和查询数据的数据库。关系图谱中，关系的组织形式采用的就是图结构，所以非常适合用图库进行存储。

- ![image-20210103191540372](https://tva1.sinaimg.cn/large/0081Kckwly1gmaq0j9otdj30pz0en0vm.jpg)

  优势总结:

- 性能上，使用cql查询，对长程关系的查询速度快

- 擅于发现隐藏的关系，例如通过判断图上两点之间有没有走的通的路径，就可以发现事物间的关联

![image-20210103192653004](https://tva1.sinaimg.cn/large/0081Kckwly1gmaqc75y6bj30wc0d60u4.jpg)

```java
// 查询三层级关系节点如下：with可以将前面查询结果作为后面查询条件
match (na:Person)-[re]-(nb:Person) where na.name="林婉儿" WITH na,re,nb match (nb:Person)- [re2:Friends]->(nc:Person) return na,re,nb,re2,nc
// 直接拼接关系节点查询
match data=(na:Person{name:"范闲"})-[re]->(nb:Person)-[re2]->(nc:Person) return data
// 使用深度运算符
显然使用以上方式比较繁琐,可变数量的关系->节点可以使用-[:TYPE*minHops..maxHops]-。
match data=(na:Person{name:"范闲"})-[*1..2]-(nb:Person) return data
```



####  **文档MongoDB**

> MongoDB 是一个基于分布式文件存储的数据库，是非关系数据库中功能最丰富、最像关系数据库的。在高负载的情况下，通过添加更多的节点，可以保证服务器性能。由 C++ 编写，可以为 WEB 应用提供可扩展、高性能、易部署的数据存储解决方案。

<img src="https://tva1.sinaimg.cn/large/0081Kckwly1gmaqyp75qsj312q0i8q5f.jpg" alt="image-20210103194830654" style="zoom:80%;" />

**什么是BSON**

> {key:value,key2:value2}和Json类似，是一种二进制形式的存储格式，支持内嵌的文档对象和数组对象，但是BSON有JSON没有的一些数据类型，比如 value包括字符串,double,Array,DateBSON可以做为网络数据交换的一种存储形式,它的优点是灵活性高，但它的缺点是空间利用率不是很理想。

BSON有三个特点：轻量性、可遍历性、高效性

```mysql
/* 查询 find() 方法可以传入多个键(key)，每个键(key)以逗号隔开*/
db.collection.find({key1:value1, key2:value2}).pretty()
/* 更新 $set ：设置字段值 $unset :删除指定字段 $inc：对修改的值进行自增*/
db.collection.update({where},{$set:{字段名:值}},{multi:true})
/* 删除 justOne :如果设为true，只删除一个文档，默认false，删除所有匹配条件的文档*/
db.collection.remove({where}, {justOne: <boolean>, writeConcern: <回执> } )
```

**优点：**

- **文档结构的存储方式，能够更便捷的获取数据。**

  对于一个层级式的数据结构来说，使用扁平式的，表状的结构来查询保存数据非常的困难。

- **内置GridFS，支持大容量的存储。**

  GridFS是一个出色的分布式文件系统，支持海量的数据存储，满足对大数据集的快速范围查询。

- **性能优越**

  千万级别的文档对象，近10G的数据，对有索引的ID的查询 不会比mysql慢，而对非索引字段的查询，则是全面胜出。 mysql实际无法胜任大数据量下任意字段的查询，而mongodb的查询性能实在牛逼。写入性能同样很令人满意，同样写入百万级别的数据，mongodb基本10分钟以下可以解决。

缺点：

- 不支持事务
- 磁盘占用空间大





MySQL 8.0 版本

**1. 性能**：MySQL 8.0 的速度要比 MySQL 5.7 快 2 倍。

**2. NoSQL**：MySQL 从 5.7 版本开始提供 NoSQL 存储功能，在 8.0 版本中nosql得到了更大的改进。

**3. 窗口函数**：实现若干新的查询方式。窗口函数与 SUM()、COUNT() 这种集合函数类似，但它不会将多行查询结果合并为一行，而是将结果放回多行当中，即窗口函数不需要 GROUP BY。

**4. 隐藏索引**：在 MySQL 8.0 中，索引可以被“隐藏”和“显示”。当对索引进行隐藏时，它不会被查询优化器所使用。我们可以使用这个特性用于性能调试，例如我们先隐藏一个索引，然后观察其对数据库的影响。如果数据库性能有所下降，说明这个索引是有用的，然后将其“恢复显示”即可；如果数据库性能看不出变化，说明这个索引是多余的，可以考虑删掉。



#### **云存储**

|        | OSS                                                          | 自建                                                         |
| ------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 可靠性 | 可用性不低于99.995%<br />数据设计持久性不低于99.9999999999%（12个9） | 受限于硬件可靠性，易出问题，一旦出现磁盘坏道，容易出现不可逆转的数据丢失。人工数据恢复困难、耗时、耗力。 |
| 安全   | 服务端加密、客户端加密、防盗链、IP黑白名单等。多用户资源隔离机制，支持异地容灾机制。 | 需要另外购买清洗和黑洞设备。需要单独实现安全机制。           |
| 成本   | 多线BGP骨干网络，无带宽限制，上行流量免费。无需运维人员与托管费用，0成本运维。 | 单线或双线接入速度慢，有带宽限制，峰值时期需人工扩容。需专人运维，成本高。 |

**使用步骤**

​	1、开通服务

​	2、创建存储空间

​	3、上传文件、下载文件、删除文件

​	4、域名绑定、日志记录

​	5、根据开放接口进行鉴权访问

**功能**

​	图片编辑（裁剪、模糊、水印）

​	视频截图

​	音频转码、视频修复

**CDN加速**

​	对象存储OSS与阿里云CDN服务结合，可优化静态热点文件下载加速的场景（即同一地区大量用户同时下载同一个静态文件的场景）。可以将OSS的存储空间（Bucket）作为源站，利用阿里云CDN将源内容发布到边缘节点。当大量终端用户重复访问同一文件时，可以直接从边缘节点获取已缓存的数据，提高访问的响应速度



#### **FastDFS**

> **开源的轻量级分布式文件系统**。它对文件进行管理，功能包括：**文件存储、文件同步、文件访问**（文件上传、文件下载）等，解决了**大容量存储和负载均衡**的问题。使用FastDFS很容易搭建一套高性能的文件服务器集群提供文件上传、下载等服务。如**相册网站、视频网站**等

**扩展能力:** 支持水平扩展，可以动态扩容；

**高可用性:** 一是整个文件系统的可用性，二是数据的完整和一致性；

**弹性存储:** 可以根据业务需要灵活地增删存储池中的资源，而不需要中断系统运行。

![image-20210107221022658](https://tva1.sinaimg.cn/large/008eGmZEly1gmfhjkvo59j30zu0b4dib.jpg)



特性

- 和流行的web server无缝衔接，FastDFS已提供apache和nginx扩展模块
- 文件ID由FastDFS生成，作为文件访问凭证，FastDFS不需要传统的name server
- 分组存储，灵活简洁、对等结构，不存在单点
- 文件不分块存储，上传的文件和OS文件系统中的文件一一对应
- 中、小文件均可以很好支持，支持海量小文件存储
- 支持相同内容的文件只保存一份，节约磁盘空间
- 支持多块磁盘，支持单盘数据恢复
- 支持在线扩容 支持主从文件
- 下载文件支持多线程方式，支持断点续传



**组成**

- **客户端（client）**

  通过专有接口，使用TCP/IP协议与跟踪器服务器或存储节点进行数据交互。

- **跟踪器（tracker）** 

  Trackerserver作用是负载均衡和调度，通过Tracker server在文件上传时可以根据策略找到文件上传的地址。Tracker在访问上起负载均衡的作用。

- **存储节点（storage）**

  Storageserver作用是文件存储，客户端上传的文件最终存储在Storage服务器上，Storage server**没有实现自己的文件系统而是利用操作系统的文件系统来管理文件**。存储节点中的服务器均可以**随时增加或下线而不会影响线上服务**。

**上传**

<img src="https://tva1.sinaimg.cn/large/008eGmZEly1gmfhvk0wwzj30ue0h4dlw.jpg" alt="image-20210107222155291" style="zoom:50%;" />

**下载**

<img src="https://tva1.sinaimg.cn/large/008eGmZEly1gmfhww8zmfj30uw0g6n37.jpg" alt="image-20210107222312338" style="zoom:50%;" />

**断点续传**

​	续传涉及到的文件大小MD5不会改变。续传流程与文件上传类似，先**定位到源storage**，完成完整或部分上传，再**通过binlog进行同group内server文件同步**。

**配置优化**

配置文件：tracker.conf 和 storage.conf 

```java
// FastDFS采用内存池的做法。 
// v5.04对预分配采用增量方式，tracker一次预分配 1024个，storage一次预分配256个。 
max_connections = 10240
// 根据实际需要将 max_connections 设置为一个较大的数值，比如 10240 甚至更大。
// 同时需要将一个进程允许打开的最大文件数调大
vi /etc/security/limits.conf 重启系统生效 
* soft nofile 65535 
* hard nofile 65535
```

```java
work_threads = 4 
// 说明：为了避免CPU上下文切换的开销，以及不必要的资源消耗，不建议将本参数设置得过大。
// 公式为： work_threads + (reader_threads + writer_threads) = CPU数
```

```java
// 对于单盘挂载方式，磁盘读写线程分 别设置为 1即可 
// 如果磁盘做了RAID，那么需要酌情加大读写线程数，这样才能最大程度地发挥磁盘性能
disk_rw_separated：磁盘读写是否分离 
disk_reader_threads：单个磁盘读线程数 
disk_writer_threads：单个磁盘写线程数 
```

**避免重复**

​	如何避免文件重复上传 解决方案 上传成功后计算文件对应的MD5然后**存入MySQL**,添加文件时把**文件MD5和之前存入MYSQL中的存储的信息对比** 。DigestUtils.md5DigestAsHex(bytes)。

















### 事务

#### **1、事务4大特性** 

**事务4大特性：**原子性、一致性、隔离性、持久性

​	**原⼦性：** 事务是最⼩的执⾏单位，不允许分割。事务的原⼦性确保动作要么全部完成，要么全不执行

​	**一致性：** 执⾏事务前后，数据保持⼀致，多个事务对同⼀个数据读取的结果是相同的；

​	**隔离性：** 并发访问数据库时，⼀个⽤户的事务不被其他事务所⼲扰，各并发事务之间数据库是独⽴的；

​	**持久性：** ⼀个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发⽣故障也不应该对其有任何影响。

**实现保证：**

​		MySQL的存储引擎InnoDB使用重做日志保证一致性与持久性，回滚日志保证原子性，使用各种锁来保证隔离性。



#### **2、事务隔离级别**

**读未提交：**最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。

**读已提交：**允许读取并发事务已经提交的数据，可以阻⽌脏读，但是幻读或不可重复读仍有可能发⽣。

**可重复读：**同⼀字段的多次读取结果都是⼀致的，除⾮数据是被本身事务⾃⼰所修改，可以阻⽌脏读和不可重复读，会有幻读。

**串行化：**最⾼的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执⾏，这样事务之间就完全不可能产⽣⼲扰。

| 隔离级别 | 并发问题                         |
| -------- | -------------------------------- |
| 读未提交 | 可能会导致脏读、幻读或不可重复读 |
| 读已提交 | 可能会导致幻读或不可重复读       |
| 可重复读 | 可能会导致幻读                   |
| 可串行化 | 不会产⽣⼲扰                     |



#### **3、默认隔离级别-RR** 

**默认隔离级别：**可重复读；

​		同⼀字段的多次读取结果都是⼀致的，除⾮数据是被本身事务⾃⼰所修改；

​		可重复读是有可能出现幻读的，如果要保证绝对的安全只能把隔离级别设置成SERIALIZABLE；这样所有事务都只能顺序执行，自然不会因为并发有什么影响了，但是性能会下降许多。

​		第二种方式，使用MVCC解决**快照读幻读问题**（如简单select），读取的不是最新的数据。维护一个字段作为version，这样可以控制到每次只能有一个人更新一个版本。

```mysql
select id from table_xx where id = ? and version = V
update id from table_xx where id = ? and version = V+1
```

​		第三种方式，如果需要读最新的数据，可以通过GapLock+Next-KeyLock可以解决**当前读幻读问题**，

```mysql
select id from table_xx where id > 100 for update;
select id from table_xx where id > 100 lock in share mode;
```



#### **4、RR和RC使用场景**

​		事务隔离级别RC(read commit)和RR（repeatable read）两种事务隔离级别基于多版本并发控制MVCC(multi-version concurrency control）来实现。

|        | RC                                   | RR                         |
| ------ | ------------------------------------ | -------------------------- |
| 实现   | 多条查询语句会创建多个不同的ReadView | 仅需要一个版本的ReadView   |
| 粒度   | 语句级读一致性                       | 事务级读一致性             |
| 准确性 | 每次语句执行时间点的数据             | 第一条语句执行时间点的数据 |



#### **5、行锁，表锁，意向锁** 

**InnoDB⽀持⾏级锁(row-level locking)和表级锁,默认为⾏级锁**	

​	InnoDB按照不同的分类的锁：

​	共享/排它锁(Shared and Exclusive Locks)：行级别锁，

​	意向锁(Intention Locks)，表级别锁

​	间隙锁(Gap Locks)，锁定一个区间

​	记录锁(Record Locks)，锁定一个行记录

**表级锁：（串行化）**

​		Mysql中锁定 粒度最大的一种锁，对当前操作的整张表加锁，实现简单 ，资源消耗也比较少，加锁快，不会出现死锁 。其锁定粒度最大，触发锁冲突的概率最高，并发度最低，MyISAM和 InnoDB引擎都支持表级锁。

**行级锁：（RR、RC）**

​		Mysql中锁定 粒度最小 的一种锁，只针对当前操作的行进行加锁。 行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。 InnoDB支持的行级锁，包括如下几种：

​		**记录锁（Record Lock）:** 对索引项加锁，锁定**符合条件的行**。其他事务不能修改和删除加锁项；

​		**间隙锁（Gap Lock）:** 对索引项之间的“间隙”加锁，锁定**记录的范围**，不包含索引项本身，其他事务不能在锁范围内插入数据。

​		**Next-key Lock：** 锁定索引项本身和索引范围。即Record Lock和Gap Lock的结合。可解决幻读问题。



InnoDB 支持多粒度锁（multiple granularity locking），它允许行级锁与表级锁共存，而意向锁就是其中的一种表锁。

**共享锁**（ shared lock, S ）锁允许持有锁读取行的事务。加锁时将自己和子节点全加S锁，父节点直到表头全加IS锁

**排他锁**（ exclusive lock， X ）锁允许持有锁修改行的事务。 加锁时将自己和子节点全加X锁，父节点直到表头全加IX锁  

**意向共享锁**（intention shared lock, IS）：事务有意向对表中的某些行加**共享锁**（S锁）

**意向排他锁**（intention exclusive lock, IX）：事务有意向对表中的某些行加**排他锁**（X锁）

| 互斥性       | 共享锁（S） | 排它锁（X） | 意向共享锁IS | 意向排他锁IX |
| ------------ | ----------- | ----------- | ------------ | ------------ |
| 共享锁（S）  | ✅           | ❌           | ✅            | ❌            |
| 排它锁（X）  | ❌           | ❌           | ❌            | ❌            |
| 意向共享锁IS | ✅           | ❌           | ✅            | ✅            |
| 意向排他锁IX | ❌           | ❌           | ✅            | ✅            |



#### **6、MVCC多版本并发控制** 

​		MVCC是一种多版本并发控制机制，通过事务的可见性看到自己预期的数据，能降低其系统开销.（RC和RR级别工作）

​		InnoDB的MVCC,是通过在每行记录后面保存系统版本号(可以理解为事务的ID)，每开始一个新的事务，系统版本号就会自动递增，事务开始时刻的系统版本号会作为事务的ID。这样可以确保事务读取的行，要么是在事务开始前已经存在的，要么是事务自身插入或者修改过的，防止幻读的产生。

​		1.MVCC手段只适用于Msyql隔离级别中的读已提交（Read committed）和可重复读（Repeatable Read）.

​		2.Read uncimmitted由于存在脏读，即能读到未提交事务的数据行，所以不适用MVCC.

​		3.简单的select快照度不会加锁，删改及select for update等需要当前读的场景会加锁

​		原因是MVCC的创建版本和删除版本只要在事务提交后才会产生。客观上，mysql使用的是乐观锁的一整实现方式，就是每行都有版本号，保存时根据版本号决定是否成功。Innodb的MVCC使用到的快照存储在Undo日志中，该日志通过回滚指针把一个数据行所有快照连接起来。



**版本链**

在InnoDB引擎表中，它的聚簇索引记录中有两个必要的隐藏列：

**trx_id**

这个id用来存储的每次对某条聚簇索引记录进行修改的时候的事务id。

**roll_pointer**

每次对哪条聚簇索引记录有修改的时候，都会把老版本写入undo日志中。这个roll_pointer就是存了一个指针，它指向这条聚簇索引记录的上一个版本的位置，通过它来获得上一个版本的记录信息。(注意插入操作的undo日志没有这个属性，因为它没有老版本)

每次修改都会在版本链中记录。**SELECT可以去版本链中拿记录，这就实现了读-写，写-读的并发执行，**提升了系统的性能。



### 索引

#### **1、Innodb和Myisam引擎** 

**Myisam：**支持表锁，适合读密集的场景，不支持外键，不支持事务，索引与数据在不同的文件

**Innodb：**支持行、表锁，默认为行锁，适合并发场景，支持外键，支持事务，索引与数据同一文件



#### **2、哈希索引**

​		哈希索引用索引列的值计算该值的hashCode，然后在hashCode相应的位置存执该值所在行数据的物理位置，因为使用散列算法，因此访问速度非常快，但是一个值只能对应一个hashCode，而且是散列的分布方式，因此哈希索引不支持范围查找和排序的功能



#### **3、B+树索引** 

**优点：**

​		B+树的磁盘读写代价低，更少的查询次数，查询效率更加稳定，有利于对数据库的扫描

​		B+树是B树的升级版，B+树只有叶节点存放数据，其余节点用来索引。索引节点可以全部加入内存，增加查询效率，叶子节点可以做双向链表，从而**提高范围查找的效率，增加的索引的范围**

​		在大规模数据存储的时候，红黑树往往出现由于**树的深度过大**而造成磁盘IO读写过于频繁，进而导致效率低下的情况。所以，只要我们通过某种较好的树结构减少树的结构尽量减少树的高度，B树与B+树可以有多个子女，从几十到上千，可以降低树的高度。

[^页存储]: 自mysql5.7后，提供了一个设定page大小的参数innodb_page_size，默认值是16K。我们可以通过来改变page的大小来间接改变m树B+树的m的大小。比如我们现在要存20G大小的数据，那么page=16K和page=4K，树的高度是不一样的。换句话说，树的高度是根据你要存下的数据是多少来决定的。

​		**磁盘预读原理**：将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。为了达到这个目的，在实际实现B-Tree还需要使用如下技巧：每次新建节点时，直接申请一个页的空间，这样就保证**一个节点物理上也存储在一个页里**，加之计算机存储分配都是按页对齐的，就实现了一个node只需一次I/O。



#### 4、创建索引

```sql
CREATE  [UNIQUE | FULLTEXT]  INDEX  索引名 ON  表名(字段名) [USING 索引方法]；

说明：
UNIQUE:可选。表示索引为唯一性索引。
FULLTEXT:可选。表示索引为全文索引。
INDEX和KEY:用于指定字段为索引，两者选择其中之一就可以了，作用是一样的。
索引名:可选。给创建的索引取一个新名称。
字段名1:指定索引对应的字段的名称，该字段必须是前面定义好的字段。
注：索引方法默认使用B+TREE。
```



#### **5、聚簇索引和非聚簇索引** 

​	**聚簇索引：**将数据存储与索引放到了一块，索引结构的叶子节点保存了行数据（**主键索引**）

​	**非聚簇索引：**将数据与索引分开存储，索引结构的叶子节点指向了数据对应的位置（**辅助索引**）

​	聚簇索引的叶子节点就是数据节点，而非聚簇索引的叶子节点仍然是索引节点，只不过有指向对应数据块的指针。



#### 6、最左前缀问题

​		最左前缀原则主要使用在联合索引中，联合索引的B+Tree是按照第一个关键字进行索引排列的。

​		联合索引的底层是一颗B+树，只不过联合索引的B+树节点中存储的是键值。由于构建一棵B+树只能根据一个值来确定索引关系，所以数据库依赖联合索引最左的字段来构建。

​		采用>、<等进行匹配都会导致后面的列无法走索引，因为通过以上方式匹配到的数据是不可知的。

 



### SQL查询

#### **1、SQL语句的执行过程** 

**查询语句：**

```mysql
select * from student  A where A.age='18' and A.name='张三';
```

<img src="http://s0.lgstatic.com/i/image2/M01/8B/0F/CgotOV14ySKAMxohAAH2VHcAzkE612.png" alt="img" style="zoom: 67%;" />

结合上面的说明，我们分析下这个语句的执行流程：

①通过客户端/服务器通信协议与 MySQL 建立连接。并查询是否有权限

②Mysql8.0之前开看是否开启缓存，开启了 Query Cache 且命中完全相同的 SQL 语句，则将查询结果直接返回给客户端；

③由解析器进行语法语义解析，并生成解析树。如查询是select、表名tb_student、条件是id='1'

④查询优化器生成执行计划。根据索引看看是否可以优化

⑤查询执行引擎执行 SQL 语句，根据存储引擎类型，得到查询结果。若开启了 Query Cache，则缓存，否则直接返回。



#### **2、回表查询和覆盖索引** 

**普通索引**（唯一索引+联合索引+全文索引）需要扫描两遍索引树

（1）先通过普通索引定位到主键值id=5；

（2）在通过聚集索引定位到行记录；

这就是所谓的**回表查询**，先定位主键值，再定位行记录，它的性能较扫一遍索引树更低。

**覆盖索引**：主键索引==聚簇索引==覆盖索引

​	如果where条件的列和返回的数据在一个索引中，那么不需要回查表，那么就叫覆盖索引。

**实现覆盖索引**：常见的方法是，将被查询的字段，建立到联合索引里去。



#### 3、Explain及优化

参考：https://www.jianshu.com/p/8fab76bbf448

```mysql
mysql> explain select * from staff;
+----+-------------+-------+------+---------------+------+---------+------+------+-------+
| id | select_type | table | type | possible_keys | key  | key_len | ref  | rows | Extra |
+----+-------------+-------+------+---------------+------+---------+------+------+-------+
|  1 | SIMPLE      | staff | ALL  | NULL          | 索引  | NULL    | NULL |    2 | NULL  |
+----+-------------+-------+------+---------------+------+---------+------+------+-------+
1 row in set
```

**索引优化：**

​	①最左前缀索引：like只用于'string%'，语句中的=和in会动态调整顺序

​	②唯一索引：唯一键区分度在0.1以上

​	③无法使用索引：!=  、is null 、 or、>< 、（**5.7以后根据数量自动判定）in 、not in**

​	④联合索引：避免select * ，查询列使用覆盖索引

```mysql
SELECT uid From user Where gid = 2 order by ctime asc limit 10
ALTER TABLE user add index idx_gid_ctime_uid(gid,ctime,uid) #创建联合覆盖索引，避免回表查询
```



**语句优化：**

​	①char固定长度查询效率高，varchar第一个字节记录数据长度

​	②应该针对Explain中Rows增加索引

​	③group/order by字段均会涉及索引

​	④Limit中分页查询会随着start值增大而变缓慢，通过子查询+表连接解决

```sql
select * from mytbl order by id limit 100000,10  改进后的SQL语句如下：
select * from mytbl where id >= ( select id from mytbl order by id limit 100000,1 ) limit 10
select * from mytbl inner ori join (select id from mytbl order by id limit 100000,10) as tmp on tmp.id=ori.id;
```

​	⑤count会进行全表扫描，如果估算可以使用explain

​	⑥delete删除表时会增加大量undo和redo日志， 确定删除可使用trancate

**表结构优化：**

​	①单库不超过200张表

​	②单表不超过500w数据

​	③单表不超过40列

​	④单表索引不超过5个

**数据库范式** ：

​	①第一范式（1NF）列不可分割

​	②第二范式（2NF）属性完全依赖于主键 [ 消除部分子函数依赖 ]

​	③第三范式（3NF）属性不依赖于其它非主属性 [ 消除传递依赖 ]

**配置优化：**

​	配置连接数、禁用Swap、增加内存、升级SSD硬盘



#### 4、JOIN查询 

<img src="https://image-static.segmentfault.com/276/780/2767807589-5c122586a23c4_articlex" style="align:left;zoom: 60%;" />

**left join(左联接)** 返回包括左表中的所有记录和右表中关联字段相等的记录 

**right join(右联接)** 返回包括右表中的所有记录和左表中关联字段相等的记录

**inner join(等值连接)** 只返回两个表中关联字段相等的行



### **集群**

#### 1、主从复制过程 

**MySQl主从复制：**

- **原理**：将主服务器的binlog日志复制到从服务器上执行一遍，达到主从数据的一致状态。
- **过程**：从库开启一个I/O线程，向主库请求Binlog日志。主节点开启一个binlog dump线程，检查自己的二进制日志，并发送给从节点；从库将接收到的数据保存到中继日志（Relay log）中，另外开启一个SQL线程，把Relay中的操作在自身机器上执行一遍
- **优点**：
  - 作为备用数据库，并且不影响业务
  - 可做读写分离，一个写库，一个或多个读库，在不同的服务器上，充分发挥服务器和数据库的性能，但要保证数据的一致性

**binlog记录格式：**statement、row、mixed

​		基于语句statement的复制、基于行row的复制、基于语句和行（mix）的复制。其中基于row的复制方式更能保证主从库数据的一致性，但日志量较大，在设置时考虑磁盘的空间问题



#### 2、数据一致性问题

"主从复制有延时"，这个延时期间读取从库，可能读到不一致的数据。

**缓存记录写key法：**

​		在cache里记录哪些记录发生过的写请求，来路由读主库还是读从库

**异步复制：**

​		在异步复制中，主库执行完操作后，写入binlog日志后，就返回客户端，这一动作就结束了，并不会验证从库有没有收到，完不完整，所以这样可能**会造成数据的不一致**。

**半同步复制：**

​		当主库每提交一个事务后，不会立即返回，而是等待其中一个从库接收到Binlog并成功写入Relay-log中才返回客户端，通过一份在主库的Binlog，另一份在其中一个从库的Relay-log，可以保证了数据的安全性和一致性。

**全同步复制：**

​		指当主库执行完一个事务，所有的从库都执行了该事务才返回给客户端。因为需要等待所有从库执行完该事务才能返回，所以全同步复制的**性能必然会收到严重的影响**。



#### 3、集群架构

 **Keepalived + VIP + MySQL 主从/双主**

​		当写节点 Master db1 出现故障时，由 MMM Monitor 或 Keepalived 触发切换脚本，将 VIP 漂移到可用的 Master db2 上。当出现网络抖动或网络分区时，MMM Monitor 会误判，严重时来回切换写 VIP 导致集群双写，当数据复制延迟时，应用程序会出现数据错乱或数据冲突的故障。有效避免单点失效的架构就是采用共享存储，单点故障切换可以通过分布式哨兵系统监控。

<img src="http://s0.lgstatic.com/i/image2/M01/89/48/CgoB5l12KuGALf-cAAGuHVmMkHs743.png" alt="img" style="zoom: 67%;" />

 **架构选型：**MMM 集群  -> MHA集群 -> MHA+Arksentinel。

<img src="http://s0.lgstatic.com/i/image2/M01/89/68/CgotOV12KuKAe_HOAABl-wRATa0772.png" alt="img"  />



#### 4、故障转移和恢复

**转移方式及恢复方法**

    1. 虚拟IP或DNS服务 （Keepalived +VIP/DNS  和 MMM 架构）

​	问题：在虚拟 IP 运维过程中，刷新ARP过程中有时会出现一个 VIP 绑定在多台服务器同时提供连接的问题。这也是为什么要避免使用 Keepalived+VIP 和 MMM 架构的原因之一，因为它处理不了这类问题而导致集群多点写入。

    2. 提升备库为主库（MHA、QMHA）

​	尝试将原 Master 设置 read_only 为 on，避免集群多点写入。借助 binlog server 保留 Master 的 Binlog；当出现数据延迟时，再提升 Slave 为新 Master 之前需要进行数据补齐，否则会丢失数据。



### 面试题

#### 分库分表

##### 如何进行分库分表

> **分表**用户id进行分表，每个表控制在300万数据。
>
> **分库**根据业务场景和地域分库，每个库并发不超过2000

**Sharding-jdbc** 这种 client 层方案的**优点在于不用部署，运维成本低，不需要代理层的二次转发请求，性能很高**，但是各个系统都需要**耦合** Sharding-jdbc 的依赖，升级比较麻烦

**Mycat** 这种 proxy 层方案的**缺点在于需要部署**，自己运维一套中间件，运维成本高，但是**好处在于对于各个项目是透明的**，如果遇到升级之类的都是自己中间件那里搞就行了

**水平拆分**：一个表放到多个库，分担高并发，加快查询速度

- **id**保证业务在关联多张表时可以在同一库上操作
- **range**方便扩容和数据统计
- **hash**可以使得数据更加平均

**垂直拆分**：一个表拆成多个表，可以将一些冷数据拆分到冗余库中



> 不是写瓶颈优先进行分表

- 分库数据间的数据无法再通过数据库直接查询了。会产生深分页的问题

- 分库越多，出现问题的可能性越大，维护成本也变得更高。

- 分库后无法保障跨库间事务，只能借助其他中间件实现最终一致性。



分库首先需考虑满足业务最核心的场景：

1、订单数据按**用户**分库，可以**提升用户的全流程体验**

2、超级客户导致**数据倾斜**可以使用最细粒度唯一标识进行hash拆分

3、按照最细粒度如订单号拆分以后，数据库就无法进行单库排重了



三个问题：

- 富查询：采用分库分表之后，如何满足跨越分库的查询？**使用ES**的宽表

  借助**分库网关+分库业务**虽然能够实现**多维度查询的能力**，但整体上性能不佳且对正常的写入请求有一定的影响。业界应对**多维度实时查询**的最常见方式便是借助 **ElasticSearch**

- 数据倾斜：数据分库基础上再进行分表

- 分布式事务：跨多库的修改及多个微服务间的写操作导致的分布式事务问题？

- 深分页问题：按游标查询，或者叫每次查询都带上上一次查询经过排序后的最大 ID





#### 如何将老数据进行迁移

**双写不中断迁移**

- 线上系统里所有写库的地方，增删改操作，**除了对老库增删改，都加上对新库的增删改**
- 系统部署以后，还需要跑程序读老库数据写新库，写的时候需要判断updateTime
- 循环执行，直至两个库的数据完全一致，最后重新部署分库分表的代码就行了



#### 系统性能的评估及扩容

和家亲目前有1亿用户：场景 10万写并发，100万读并发，60亿数据量

设计时考虑极限情况，32库*32表~64个表，一共1000 ~ 2000张表

- 支持**3万**的写并发，配合MQ实现每秒10万的写入速度
- 读写分离**6万**读并发，配合分布式缓存每秒100读并发
- 2000张表每张300万，可以最多写入60亿的数据

- 32张用户表，支撑亿级用户，后续最多也就扩容一次

**动态扩容的步骤**

1. 推荐是 32 库 * 32 表，对于我们公司来说，可能几年都够了。
2. 配置路由的规则，uid % 32 = 库，uid / 32 % 32 = 表
3. 扩容的时候，申请增加更多的数据库服务器，呈倍数扩容
4. 由 DBA 负责将原先数据库服务器的库，迁移到新的数据库服务器上去
5. 修改一下配置，重新发布系统，上线，原先的路由规则变都不用变
6. 直接可以基于 n 倍的数据库服务器的资源，继续进行线上系统的提供服务。



#### 如何生成自增的id主键

- 使用redis可以
- 并发不高可以单独起一个**服务**，生成自增id
- 设置数据库**step**自增步长可以支撑水平伸缩
- UUID适合文件名、编号，但是**不适合做主键**
- **snowflake雪花算法**，综合了**41时间**（ms）、**10机器**、**12序列号**（ms内自增）

其中机器预留的10bit可以根据自己的业务场景配置





### 线上故障及优化

#### 更新失败 | 主从同步延时

以前线上确实处理过因为主从同步延时问题而导致的线上的 bug，属于小型的生产事故。

是这个么场景。有个同学是这样写代码逻辑的。先插入一条数据，再把它查出来，然后更新这条数据。在生产环境高峰期，写并发达到了 2000/s，这个时候，主从复制延时大概是在小几十毫秒。线上会发现，每天总有那么一些数据，我们期望更新一些重要的数据状态，但在高峰期时候却没更新。用户跟客服反馈，而客服就会反馈给我们。

我们通过 MySQL 命令：

```
show slave status
```

查看 `Seconds_Behind_Master` ，可以看到从库复制主库的数据落后了几 ms。

一般来说，如果主从延迟较为严重，有以下解决方案：

- 分库，拆分为多个主库，每个主库的写并发就减少了几倍，主从延迟可以忽略不计。
- 重写代码，写代码的同学，要慎重，插入数据时立马查询可能查不到。
- 如果确实是存在必须先插入，立马要求就查询到，然后立马就要反过来执行一些操作，对这个查询**设置直连主库**或者**延迟查询**。主从复制延迟一般不会超过50ms

#### **应用崩溃 | 分库分表优化**

​	我们有一个线上通行记录的表，由于数据量过大，进行了分库分表，当时分库分表初期经常产生一些问题。典型的就是通行记录查询中使用了深分页，通过一些工具如MAT、Jstack追踪到是由于sharding-jdbc内部引用造成的。

​	通行记录数据被存放在两个库中。如果没有提供**切分键**，查询语句就会被分发到所有的数据库中，比如查询语句是 limit 10、offset 1000，最终结果只需要返回 10 条记录，但是数据库中间件要完成这种计算，则需要 (1000+10)*2=2020 条记录来完成这个计算过程。如果 offset 的值过大，使用的内存就会暴涨。虽然 sharding-jdbc 使用归并算法进行了一些优化，但在实际场景中，深分页仍然引起了**内存和性能**问题。

​	这种在中间节点进行**归并聚合**的操作，在分布式框架中非常常见。比如在 ElasticSearch 中，就存在相似的数据获取逻辑，**不加限制的深分页**，同样会造成 ES 的内存问题。

**业界解决方案：**

**方法一：全局视野法**

（1）将order by time offset X limit Y，改写成order by time offset 0 limit X+Y

（2）服务层对得到的N*(X+Y)条数据进行内存排序，内存排序后再取偏移量X后的Y条记录

这种方法随着翻页的进行，性能越来越低。

**方法二：业务折衷法-禁止跳页查询**

（1）用正常的方法取得第一页数据，并得到第一页记录的time_max

（2）每次翻页，将order by time offset X limit Y，改写成order by time where time>$time_max limit Y

以保证每次只返回一页数据，性能为常量。

**方法三：业务折衷法-允许模糊数据**

（1）将order by time offset X limit Y，改写成order by time offset X/N limit Y/N

**方法四：二次查询法**

（1）将order by time offset X limit Y，改写成order by time offset X/N limit Y

（2）找到最小值time_min

（3）between二次查询，order by time between $time_min and $time_i_max

（4）设置虚拟time_min，找到time_min在各个分库的offset，从而得到time_min在全局的offset

（5）得到了time_min在全局的offset，自然得到了全局的offset X limit Y





#### 查询异常 | SQL 调优

分库分表前，有一段用用户名来查询某个用户的 SQL 语句：

```python
select * from user where name = "xxx" and community="other";
```

为了达到动态拼接的效果，这句 SQL 语句被一位同事进行了如下修改。他的本意是，当 name 或者 community 传入为空的时候，动态去掉这些查询条件。这种写法，在 MyBaits 的配置文件中，也非常常见。大多数情况下，这种写法是没有问题的，因为结果集合是可以控制的。但随着系统的运行，用户表的记录越来越多，当传入的 name 和 community 全部为空时，悲剧的事情发生了:

```
select * from user where 1=1
```

数据库中的所有记录，都会被查询出来，载入到 JVM 的内存中。由于数据库记录实在太多，直接把内存给撑爆了。由于这种原因引起的内存溢出，发生的频率非常高，比如导入Excel文件时。

通常的解决方式是**强行加入分页功能**，或者对一些**必填的参数进行校验**

![img](https://tva1.sinaimg.cn/large/008eGmZEly1gobovqjvijj30zd0lctbp.jpg)

**Controller 层**

现在很多项目都采用前后端分离架构，所以 Controller 层的方法，一般使用 @ResponseBody 注解，把查询的结果，解析成 JSON 数据返回。这在数据集非常大的情况下，会占用很多内存资源。假如结果集在解析成 JSON 之前，占用的内存是 10MB，那么在解析过程中，有可能会使用 20M 或者更多的内存

因此，保持结果集的精简，是非常有必要的，这也是 DTO（Data Transfer Object）存在的必要。互联网环境不怕小结果集的高并发请求，却非常恐惧大结果集的耗时请求，这是其中一方面的原因。

**Service 层**

Service 层用于处理具体的业务，更加贴合业务的功能需求。一个 Service，可能会被多个 Controller 层所使用，也可能会使用多个 dao 结构的查询结果进行计算、拼装。

```java
int getUserSize() {
        List<User> users = dao.getAllUser();
        return null == users ? 0 : users.size();
}
```

代码review中发现了定时炸弹，这种在数据量达到一定程度后，才会暴露问题。

**ORM 层**

比如使用Mybatis时，有一个批量导入服务，在 MyBatis 执行批量插入的时候，竟然产生了内存溢出，按道理这种插入操作是不会引起额外内存占用的，最后通过源码追踪到了问题。

这是因为 MyBatis 循环处理 batch 的时候，操作对象是数组，而我们在接口定义的时候，使用的是 List；当传入一个非常大的 List 时，它需要调用 List 的 toArray 方法将列表转换成数组（浅拷贝）；在最后的拼装阶段，又使用了 StringBuilder 来拼接最终的 SQL，所以实际使用的内存要比 List 多很多。

事实证明，不论是插入操作还是查询动作，只要涉及的数据集非常大，就容易出现问题。由于项目中众多框架的引入，想要分析这些具体的内存占用，就变得非常困难。所以保持小批量操作和结果集的干净，是一个非常好的习惯。



































































































































# **五、Redis篇** 

### WhyRedis

​		速度快，完全基于内存，使用C语言实现，网络层使用epoll解决高并发问题，单线程模型避免了不必要的上下文切换及竞争条件；

|        | GuavaCache  | Tair       | EVCache      | Aerospike         |
| ------ | ----------- | ---------- | ------------ | ----------------- |
| 类别   | 本地JVM缓存 | 分布式缓存 | 分布式缓存   | 分布式nosql数据库 |
| 应用   | 本地缓存    | 淘宝       | Netflix、AWS | 广告              |
| 性能   | 非常高      | 较高       | 很高         | 较高              |
| 持久化 | 无          | 有         | 有           | 有                |
| 集群   | 无          | 灵活配置   | 有           | 自动扩容          |

​		与传统数据库不同的是 Redis 的数据是存在内存中的，所以读写速度非常快，因此 redis 被广泛应用于缓存方向，每秒可以处理超过 10万次读写操作，是已知性能最快的Key-Value DB。另外，Redis 也经常用来做分布式锁。除此之外，Redis 支持事务 、持久化、LUA脚本、LRU驱动事件、多种集群方案。

#### 1、简单高效

​		1）完全基于内存，绝大部分请求是纯粹的内存操作。数据存在内存中，类似于 HashMap，查找和操作的时间复杂度都是O(1)；

​		2）数据结构简单，对数据操作也简单，Redis 中的数据结构是专门进行设计的；

​		3）采用单线程，避免了多线程不必要的上下文切换和竞争条件，不存在加锁释放锁操作，减少了因为锁竞争导致的性能消耗；（6.0以后多线程）

​		4）使用EPOLL多路 I/O 复用模型，非阻塞 IO；

​		5）使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis 直接自己构建了 VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；



#### 2、Memcache

| redis                                 | Memcached                  |
| ------------------------------------- | -------------------------- |
| 内存高速数据库                        | 高性能分布式内存缓存数据库 |
| 支持hash、list、set、zset、string结构 | 只支持key-value结构        |
| 将大部分数据放到内存                  | 全部数据放到内存中         |
| 支持持久化、主从复制备份              | 不支持数据持久化及数据备份 |
| 数据丢失可通过AOF恢复                 | 挂掉后，数据不可恢复       |
| 单线程（2~4万TPS）                    | 多线程（20-40万TPS）       |

**使用场景：**

​	1、如果有持久方面的需求或对数据类型和处理有要求的应该选择redis。 
​	2、如果简单的key/value 存储应该选择memcached。	



#### 3、Tair

​	Tair(Taobao Pair)是淘宝开发的分布式Key-Value存储引擎，既可以做缓存也可以做数据源（三种引擎切换）

- MDB（Memcache）属于内存型产品,支持kv和类hashMap结构,性能最优
- RDB（Redis）支持List.Set.Zset等复杂的数据结构,性能次之,可提供缓存和持久化存储两种模式
- LDB（levelDB）属于持久化产品,支持kv和类hashmap结构,性能较前两者稍低,但持久化可靠性最高

**分布式缓存**

大访问少量临时数据的存储（kb左右）

用于缓存，降低对后端数据库的访问压力

session场景

高速访问某些数据结构的应用和计算（rdb）

**数据源存储**

快速读取数据（fdb）

持续大数据量的存入读取（ldb），交易快照

高频度的更新读取（ldb），库存

**痛点**：redis集群中，想借用缓存资源必须得指明redis服务器地址去要。这就增加了程序的维护复杂度。因为redis服务器很可能是需要频繁变动的。所以人家淘宝就想啊，为什么不能像操作分布式数据库或者hadoop那样。增加一个中央节点，让他去代理所有事情。在tair中程序只要跟tair中心节点交互就OK了。同时tair里还有配置服务器概念。又免去了像操作hadoop那样，还得每台hadoop一套一模一样配置文件。改配置文件得整个集群都跟着改。





#### 4、Guava

​		分布式缓存一致性更好一点，用于集群环境下多节点使用同一份缓存的情况；有网络IO，吞吐率与缓存的数据大小有较大关系；

​		本地缓存非常高效，本地缓存会占用堆内存，影响垃圾回收、影响系统性能。

**本地缓存设计：**

​		以 Java 为例，使用自带的 map 或者 guava 实现的是本地缓存，最主要的特点是轻量以及快速，生命周期随着 jvm 的销毁而结束，并且在多实例的情况，每个实例都需要各自保存一份缓存，缓存不具有一致性。

**解决缓存过期：**

​	1、将缓存过期时间调为永久

​	2、将缓存失效时间分散开，不要将缓存时间长度都设置成一样；比如我们可以在原有的失效时间基础上增加一个随机值，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。

**解决内存溢出：**

​	**第一步**，修改JVM启动参数，直接增加内存。(-Xms，-Xmx参数一定不要忘记加。)

　**第二步**，检查错误日志，查看“OutOfMemory”错误前是否有其它异常或错误。

　**第三步**，对代码进行走查和分析，找出可能发生内存溢出的位置。



**Google Guava Cache** 

**自己设计本地缓存痛点：**

- 不能按照一定的规则淘汰数据，如 LRU，LFU，FIFO 等。
- 清除数据时的回调通知
- 并发处理能力差，针对并发可以使用CurrentHashMap，但缓存的其他功能需要自行实现
- 缓存过期处理，缓存数据加载刷新等都需要手工实现

**Guava Cache 的场景：**

- 对性能有非常高的要求
- 不经常变化，占用内存不大
- 有访问整个集合的需求
- 数据允许不实时一致

**Guava Cache 的优势**：

- 缓存过期和淘汰机制

在GuavaCache中可以设置Key的过期时间，包括访问过期和创建过期。GuavaCache在缓存容量达到指定大小时，采用LRU的方式，将不常使用的键值从Cache中删除

- 并发处理能力

GuavaCache类似CurrentHashMap，是线程安全的。提供了设置并发级别的api，使得缓存支持并发的写入和读取，采用分离锁机制，分离锁能够减小锁力度，提升并发能力，分离锁是分拆锁定，把一个集合看分成若干partition, 每个partiton一把锁。更新锁定

- 防止缓存击穿

一般情况下，在缓存中查询某个key，如果不存在，则查源数据，并回填缓存。（Cache Aside Pattern）在高并发下会出现，多次查源并重复回填缓存，可能会造成源的宕机（DB），性能下降 GuavaCache可以在CacheLoader的load方法中加以控制，对同一个key，只让一个请求去读源并回填缓存，其他请求阻塞等待。（相当于集成数据源，方便用户使用）

- 监控缓存加载/命中情况

统计

**问题：**

​	OOM->设置过期时间、使用弱引用、配置过期策略



#### 5、EVCache

EVCache是一个Netflflix（网飞）公司开源、快速的分布式缓存，是基于Memcached的内存存储实现的，用以构建超大容量、高性能、低延时、跨区域的全球可用的缓存数据层。

E：Ephemeral：数据存储是短暂的，有自身的存活时间

V：Volatile：数据可以在任何时候消失

EVCache典型地适合对强一致性没有必须要求的场合

典型用例：Netflflix向用户推荐用户感兴趣的电影

<img src="https://tva1.sinaimg.cn/large/0081Kckwly1gmapdnh0yaj30ku0aigmc.jpg" alt="image-20210103185340548" style="zoom:50%;" />

**EVCache集群**在峰值每秒可以处理**200kb**的请求，

Netflflix生产系统中部署的EVCache经常要处理超过**每秒3000万个**请求，存储数十亿个对象，

跨数千台memcached服务器。整个EVCache集群**每天处理近2万亿个**请求。

EVCache集群响应平均延时大约是1-5毫秒，最多不会超过20毫秒。

EVCache集群的缓存命中率在99%左右。

**典型部署**

EVCache 是线性扩展的，可以在一分钟之内完成扩容，在几分钟之内完成负载均衡和缓存预热。

<img src="https://tva1.sinaimg.cn/large/0081Kckwly1gmapg99q8lj30ix0f3jrw.jpg" alt="image-20210103185611516" style="zoom:50%;" />

1、集群启动时，EVCache向服务注册中心（Zookeeper、Eureka）注册各个实例

2、在web应用启动时，查询命名服务中的EVCache服务器列表，并建立连接。

3、客户端通过key使用一致性hash算法，将数据分片到集群上。



#### 6、ETCD

​	**和Zookeeper一样，CP模型追求数据一致性，**越来越多的系统开始用它保存关键数据。比如，秒杀系统经常用它**保存各节点信**息，以便控制消费 MQ 的服务数量。还有些业务系统的**配置数据**，也会通过 etcd 实时同步给业务系统的各节点，比如，秒杀管理后台会使用 etcd 将秒杀活动的**配置数据实时同步给秒杀 API 服务各节点**。

![image-20210418174251742](Users/suhongliu/Library/Application Support/typora-user-images/image-20210418174251742.png)



### Redis底层

#### 1、redis数据类型

| 类型   | 底层      | 应用场景                                       | 编码类型              |
| ------ | --------- | ---------------------------------------------- | --------------------- |
| String | SDS数组   | 帖子、评论、热点数据、输入缓冲                 | RAW << EMBSTR << INT  |
| List   | QuickList | 评论列表、商品列表、发布与订阅、慢查询、监视器 | LINKEDLIST << ZIPLIST |
| Set    | intSet    | 适合交集、并集、查集操作，例如朋友关系         | HT << INSET           |
| Zset   | 跳跃表    | 去重后排序，适合排名场景                       | SKIPLIST << ZIPLIST   |
| Hash   | 哈希      | 结构化数据，比如存储对象                       | HT << ZIPLIST         |
| Stream | 紧凑列表  | 消息队列                                       |                       |



#### **2、相关API**

> http://redisdoc.com

|        |       |        |           |       |         |        |          |       |           |
| ------ | ----- | ------ | --------- | ----- | ------- | ------ | -------- | ----- | --------- |
| String | SET   | SETNX  | SETEX     | GET   | GETSET  | INCR   | DECR     | MSET  | MGET      |
| Hash   | HSET  | HSETNX | HGET      | HDEL  | HLEN    | HMSET  | HMGET    | HKEYS | HGETALL   |
| LIST   | LPUSH | LPOP   | RPUSH     | RPOP  | LINDEX  | LREM   | LRANGE   | LLEN  | RPOPLPUSH |
| ZSET   | ZADD  | ZREM   | ZSCORE    | ZCARD | ZRANGE  | ZRANK  | ZREVRANK |       | ZREVRANGE |
| SET    | SADD  | SREM   | SISMEMBER | SCARD | SINTER  | SUNION | SDIFF    | SPOP  | SMEMBERS  |
| 事务   | MULTI | EXEC   | DISCARD   | WATCH | UNWATCH |        |          |       |           |



#### 3、redis底层结构

**SDS数组结构**，用于存储字符串和整型数据及输入缓冲。

```java
struct sdshdr{ 
  int len;//记录buf数组中已使用字节的数量 
  int free; //记录 buf 数组中未使用字节的数量 
  char buf[];//字符数组，用于保存字符串
}
```

**跳跃表**：将有序链表中的部分节点分层，每一层都是一个有序链表。

​	1、可以快速查找到需要的节点 O(logn) ，额外存储了一倍的空间

​	2、可以在O(1)的时间复杂度下，快速获得跳跃表的头节点、尾结点、长度和高度。			

**字典dict:** 又称散列表(hash)，是用来存储键值对的一种数据结构。 

​	Redis整个数据库是用字典来存储的(K-V结构) —Hash+数组+链表

​	Redis字典实现包括:**字典(dict)、Hash表(dictht)、Hash表节点(dictEntry)**。

​	字典达到存储上限(阈值 0.75)，需要rehash(扩容)

​	1、初次申请默认容量为4个dictEntry，非初次申请为当前hash表容量的一倍。

​	2、rehashidx=0表示要进行rehash操作。

​	3、新增加的数据在新的hash表h[1] 、修改、删除、查询在老hash表h[0]

​	4、将老的hash表h[0]的数据重新计算索引值后全部迁移到新的hash表h[1]中，这个过程称为 rehash。

​	**渐进式rehash**

 	由于当数据量巨大时rehash的过程是非常缓慢的，所以需要进行优化。 可根据服务器空闲程度批量rehash部分节点

**压缩列表zipList**

​	压缩列表(ziplist)是由一系列特殊编码的连续内存块组成的顺序型数据结构，节省内容

​	**sorted-set和hash元素个数少**且是小整数或短字符串(直接使用) 

​	list用快速链表(quicklist)数据结构存储，而**快速链表是双向列表与压缩列表**的组合。(间接使用)

**整数集合intSet**

​	整数集合(intset)是一个有序的(整数升序)、存储整数的连续存储结构。 

​	当Redis集合类型的元素都是整数并且都处在64位有符号整数范围内(2^64)，使用该结构体存储。

**快速列表quickList**

​	快速列表(quicklist)是Redis底层重要的数据结构。是Redis3.2列表的底层实现。

​	(在Redis3.2之前，Redis采 用双向链表(adlist)和压缩列表(ziplist)实现。)

**Redis Stream**的底层主要使用了listpack(紧凑列表)和Rax树(基数树)。

​	**listpack**表示一个字符串列表的序列化，listpack可用于存储字符串或整数。用于存储stream的消息内 容。

​	**Rax树**是一个有序字典树 (基数树 Radix Tree)，按照 key 的字典序排列，支持快速地定位、插入和删除操 作。



#### 4、Zset底层实现

​		跳表(skip List)是一种随机化的数据结构，基于并联的链表，实现简单，插入、删除、查找的复杂度均为O(logN)。简单说来跳表也是链表的一种，只不过它在链表的基础上增加了跳跃功能，正是这个跳跃的功能，使得在查找元素时，跳表能够提供O(logN)的时间复杂度

​		Zset**数据量少的时候使用压缩链表ziplist**实现，有序集合使用紧挨在一起的压缩列表节点来保存，第一个节点保存member，第二个保存score。ziplist内的集合元素按score从小到大排序，score较小的排在表头位置。 **数据量大的时候使用跳跃列表skiplist和哈希表hash_map**结合实现，查找删除插入的时间复杂度都是O(longN)

​		Redis使用跳表而不使用红黑树，是因为跳表的索引结构序列化和反序列化更加快速，方便持久化。

**搜索**

​		跳跃表按 score 从小到大保存所有集合元素，查找时间复杂度为平均 *O(logN)，最坏 O(N) 。*

**插入**

  选用链表作为底层结构支持，为了高效地动态增删。因为跳表底层的单链表是有序的，为了维护这种有序性，在插入前需要遍历链表，找到该插入的位置，单链表遍历查找的时间复杂度是O(n)，同理可得，跳表的遍历也是需要遍历索引数，所以是O(logn)。

**删除**

  如果该节点还在索引中，删除时不仅要删除单链表中的节点，还要删除索引中的节点；单链表在知道删除的节点是谁时，时间复杂度为O(1)，但针对单链表来说，删除时都需要拿到前驱节点O(logN)才可改变引用关系从而删除目标节点。



### **Redis可用性**

#### 1、redis持久化 

持久化就是把内存中的数据持久化到本地磁盘，防止服务器宕机了内存数据丢失

Redis 提供两种持久化机制 **RDB（默认）** 和 **AOF 机制**，Redis4.0以后采用混合持久化，用 AOF 来**保证数据不丢失**，作为数据恢复的第一选择; 用 RDB 来做不同程度的**冷备**

**RDB：**是Redis DataBase缩写快照

​		RDB是Redis默认的持久化方式。按照一定的时间将内存的数据以快照的形式保存到硬盘中，对应产生的数据文件为dump.rdb。通过配置文件中的save参数来定义快照的周期。

​	**优点：**

​	1）只有一个文件 dump.rdb，方便持久化；

​	2）容灾性好，一个文件可以保存到安全的磁盘。

​	3）性能最大化，fork 子进程来进行持久化写操作，让主进程继续处理命令，只存在毫秒级不响应请求。

​	4）相对于数据集大时，比 AOF 的启动效率更高。

​	**缺点：**

​	数据安全性低，RDB 是间隔一段时间进行持久化，如果持久化之间 redis 发生故障，会发生数据丢失。

**AOF：持久化**

​		AOF持久化(即Append Only File持久化)，则是将Redis执行的每次写命令记录到单独的日志文件中，当重启Redis会重新将持久化的日志中文件恢复数据。

​	**优点：**

​	1）数据安全，aof 持久化可以配置 appendfsync 属性，有 always，每进行一次 命令操作就记录到 aof 文件中一次。

​	2）通过 append 模式写文件，即使中途服务器宕机，可以通过 redis-check-aof 工具解决数据一致性问题。

**缺点：**

​	1）AOF 文件比 RDB 文件大，且恢复速度慢。

​	2）数据集大的时候，比 rdb 启动效率低。



#### 2、redis事务

​		事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。事务是一个原子操作：事务中的命令要么全部被执行，要么全部都不执行。

**Redis事务的概念**

​		Redis 事务的本质是通过MULTI、EXEC、WATCH等一组命令的集合。事务支持一次执行多个命令，一个事务中所有命令都会被序列化。在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。总结说：redis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令。

Redis的事务总是具有ACID中的**一致性和隔离性**，其他特性是不支持的。当服务器运行在AOF持久化模式下，并且appendfsync选项的值为always时，事务也具有耐久性。

Redis事务功能是通过MULTI、EXEC、DISCARD和WATCH 四个原语实现的

**事务命令：**

**MULTI：**用于开启一个事务，它总是返回OK。MULTI执行之后，客户端可以继续向服务器发送任意多条命令，这些命令不会立即被执行，而是被放到一个队列中，当EXEC命令被调用时，所有队列中的命令才会被执行。

**EXEC：**执行所有事务块内的命令。返回事务块内所有命令的返回值，按命令执行的先后顺序排列。当操作被打断时，返回空值 nil 。

**WATCH ：**是一个乐观锁，可以为 Redis 事务提供 check-and-set （CAS）行为。可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行，监控一直持续到EXEC命令。（**秒杀场景**）

**DISCARD：**调用该命令，客户端可以清空事务队列，并放弃执行事务，且客户端会从事务状态中退出。

**UNWATCH**：命令可以取消watch对所有key的监控。



#### 3、redis失效策略 

**内存淘汰策略**

1）全局的键空间选择性移除

​	**noeviction**：当内存不足以容纳新写入数据时，新写入操作会报错。（字典库常用）

​	**allkeys-lru**：在键空间中，移除最近最少使用的key。（缓存常用）

​	**allkeys-random**：在键空间中，随机移除某个key。

2）设置过期时间的键空间选择性移除

​	**volatile-lru**：在设置了过期时间的键空间中，移除最近最少使用的key。

​	**volatile-random**：在设置了过期时间的键空间中，随机移除某个key。

​	**volatile-ttl**：在设置了过期时间的键空间中，有更早过期时间的key优先移除。

**缓存失效策略**

​	**定时清除：**针对每个设置过期时间的key都创建指定定时器

​	**惰性清除：**访问时判断，对内存不友好

​	**定时扫描清除：**定时100ms随机20个检查过期的字典，若存在25%以上则继续循环删除。

#### 4、redis读写模式

​	**CacheAside旁路缓存**

写请求更新数据库后删除缓存数据。读请求不命中查询数据库，查询完成写入缓存

<img src="https://img-blog.csdnimg.cn/20200806194316539.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2x6eF92aWN0b3J5,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom: 15%;" />

<img src="https://img-blog.csdnimg.cn/20200806194300826.png" style="zoom: 15%;" />

​	业务端处理所有数据访问细节，同时利用 **Lazy 计算**的思想，更新 DB 后，直接删除 cache 并通过 DB 更新，确保数据以 DB 结果为准，则可以大幅降低 cache 和 DB 中数据不一致的概率

​	如果没有专门的存储服务，同时是对**数据一致性要求比较高的业务，或者是缓存数据更新比较复杂的业务**，适合使用 Cache Aside 模式。如微博发展初期，不少业务采用这种模式

```java
// 延迟双删，用以保证最终一致性,防止小概率旧数据读请求在第一次删除后更新数据库
public void write(String key,Object data){
	redis.delKey(key);
	db.updateData(data);
	Thread.sleep(1000);
	redis.delKey(key);
}
```

高并发下保证绝对的一致，先删缓存再更新数据，需要用到**内存队列做异步串行化**。非高并发场景，先更新数据再删除缓存，**延迟双删**策略基本满足了

- 先更新db后删除redis：删除redis失败则出现问题
- 先删redis后更新db：删除redis瞬间，旧数据被回填redis
- 先删redis后更新db休眠后删redis：同第二点，休眠后删除redis 可能宕机
- java内部jvm队列：不适用分布式场景且降低并发



​	**Read/Write Though**（读写穿透）

​		**先查询**缓存中数据是否存在,如果存在则直接返回,如果**不存在**,则由**缓存组件负责从数据库中同步加载数据.**

​	<img src="https://img-blog.csdnimg.cn/20200806194334623.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2x6eF92aWN0b3J5,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom: 50%;" />

​	先查询要**写入的数据在缓存中**是否已经存在,如果已经存在,则**更新缓存中的数据**，并且由**缓存组件同步更新**到数据库中。

​	<img src="https://img-blog.csdnimg.cn/20200806194346642.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2x6eF92aWN0b3J5,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom: 50%" />

​	用户**读操作**较多.相较于Cache aside而言更适合缓存一致的场景。使用简单屏蔽了**底层数据库的操作**,只是操作缓存.

**场景：**

微博 Feed 的 Outbox Vector（即用户最新微博列表）就采用这种模式。一些粉丝较少且不活跃的用户发表微博后，Vector 服务会首先查询 Vector Cache，如果 cache 中没有该用户的 Outbox 记录，则不写该用户的 cache 数据，直接更新 DB 后就返回，只有 cache 中存在才会通过 CAS 指令进行更新。

​	

**Write Behind Caching（异步缓存写入）**

<img src="https://tva1.sinaimg.cn/large/008eGmZEly1gorlsg74i6j31950e3dhs.jpg" alt="img" style="zoom:35%;" />

比如对一些计数业务，一条 **Feed 被点赞** 1万 次，如果更新 1万 次 DB 代价很大，而合并成一次请求直接加 1万，则是一个非常轻量的操作。但这种模型有个显著的缺点，即数据的一致性变差，甚至在一些极端场景下可能会丢失数据。



#### 5、多级缓存

**浏览器本地内存缓存：**专题活动，一旦上线，在活动期间是不会随意变更的。

**浏览器本地磁盘缓存：**Logo缓存，大图片懒加载

**服务端本地内存缓存：**由于没有持久化，重启时必定会被穿透

**服务端网络内存缓存**：Redis等，针对穿透的情况下可以继续分层，必须保证数据库不被压垮

**为什么不是使用服务器本地磁盘做缓存？**

​	当系统处理大量磁盘 IO 操作的时候，由于 CPU 和内存的速度远高于磁盘，可能导致 CPU 耗费太多时间等待磁盘返回处理的结果。对于这部分 CPU 在 IO 上的开销，我们称为 **iowait**



### Redis七大经典问题

#### 1、缓存雪崩

​		指缓存同一时间大面积的失效，所以，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。

​	**解决方案：**

- **Redis 高可用**，主从+哨兵，Redis cluster，避免全盘崩溃
- 本地 ehcache 缓存 + hystrix **限流&降级**，避免 MySQL 被打死
- 缓存数据的**过期时间设置随机**，防止同一时间大量数据过期现象发生。

- **逻辑上永不过期**给每一个缓存数据增加相应的**缓存标记**，缓存标记失效则更新数据缓存
- **多级缓存**，失效时通过二级更新一级，由第三方插件更新二级缓存。



#### **2、缓存穿透**

​		https://blog.csdn.net/lin777lin/article/details/105666839

​		缓存穿透是指缓存和数据库中都没有的数据，导致所有的请求都落到数据库上，造成数据库短时间内承受大量请求而崩掉。

​	**解决方案：**

​	1）**接口层增加校验**，如用户鉴权校验，id做基础校验，id<=0的直接拦截；

​	2）从缓存取不到的数据，在数据库中也没有取到，这时也可以将**key-value对写为key-null**，缓存有效时间可以设置短点，如30秒。这样可以防止攻击用户反复用同一个id暴力攻击；

​	3）采用**布隆过滤器**，将所有可能存在的数据哈希到一个足够大的 bitmap 中，一个一定不存在的数据会被这个 bitmap 拦截掉，从而避免了对底层存储系统的查询压力。（宁可错杀一千不可放过一人）



#### **3、缓存击穿**

​		这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。和缓存雪崩不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库

​	**解决方案：**

​	1）设置**热点数据永远不过期**，异步线程处理。

​	2）加**写回操作加互斥锁**，查询失败默认值快速返回。

​	3）缓存预热

​		系统上线后，将相关**可预期（例如排行榜）**热点数据直接加载到缓存。

​		写一个缓存刷新页面，手动操作热点数据**（例如广告推广）**上下线。



#### 4、数据不一致

​	在缓存机器的带宽被打满，或者机房网络出现波动时，缓存更新失败，新数据没有写入缓存，就会导致缓存和 DB 的数据不一致。缓存 rehash 时，某个缓存机器反复异常，多次上下线，更新请求多次 rehash。这样，一份数据存在多个节点，且每次 rehash 只更新某个节点，导致一些缓存节点产生脏数据。

- Cache 更新失败后，可以进行重试，则将重试失败的 key 写入mq，待缓存访问恢复后，将这些 key 从缓存删除。这些 key 在再次被查询时，重新从 DB 加载，从而保证数据的一致性

- 缓存时间适当调短，让缓存数据及早过期后，然后从 DB 重新加载，确保数据的最终一致性。

- 不采用 rehash 漂移策略，而采用缓存分层策略，尽量避免脏数据产生。



#### 5、数据并发竞争

​	数据并发竞争在大流量系统也比较常见，比如车票系统，如果某个火车车次缓存信息过期，但仍然有大量用户在查询该车次信息。又比如微博系统中，如果某条微博正好被缓存淘汰，但这条微博仍然有大量的转发、评论、赞。上述情况都会造成并发竞争读取的问题。

- ​	加**写回操作加互斥锁**，查询失败默认值快速返回。
- ​	对缓存数据保持多个备份，减少并发竞争的概率

​	

#### 6、热点key问题

​	明星结婚、离婚、出轨这种特殊突发事件，比如奥运、春节这些重大活动或节日，还比如秒杀、双12、618 等线上促销活动，都很容易出现 Hot key 的情况。

如何提前发现HotKey？

- 对于重要节假日、线上促销活动这些提前已知的事情，可以提前评估出可能的热 key 来。
- 而对于突发事件，无法提前评估，可以**通过 Spark，对应流任务进行实时分析**，及时发现新发布的热点 key。而对于之前已发出的事情，逐步发酵成为热 key 的，则可以通过 Hadoop 对批处理任务离线计算，找出最近历史数据中的高频热 key。

**解决方案：**

- 这 n 个 key 分散存在多个缓存节点，然后 client 端请求时，随机访问其中某个后缀的 hotkey，这样就可以把热 key 的请求打散，避免一个缓存节点过载

- 缓存集群可以单节点进行主从复制和垂直扩容

- 利用应用内的前置缓存，但是需注意需要设置上限

- 延迟不敏感，定时刷新，实时感知用主动刷新

- 和缓存穿透一样，限制逃逸流量，单请求进行数据回源并刷新前置

- 无论如何设计，最后都要写一个兜底逻辑，千万级流量说来就来

  

#### 7、BigKey问题

​	比如互联网系统中需要保存用户最新 1万 个粉丝的业务，比如一个用户个人信息缓存，包括基本资料、关系图谱计数、发 feed 统计等。微博的 feed 内容缓存也很容易出现，一般用户微博在 140 字以内，但很多用户也会发表 1千 字甚至更长的微博内容，这些长微博也就成了大 key

- 首先Redis底层数据结构里，根据Value的不同，会进行数据结构的重新选择
- 可以扩展新的数据结构，进行序列化构建，然后通过 restore 一次性写入
- 将大 key 分拆为多个 key，设置较长的过期时间



### Redis分区容错

#### **1、redis数据分区** 

**Hash：（不稳定）**

​		客户端分片：哈希+取余

​		节点伸缩：数据节点关系变化，导致数据迁移

​		迁移数量和添加节点数量有关：建议翻倍扩容

​		一个简单直观的想法是直接用Hash来计算，以Key做哈希后对节点数取模。可以看出，在key足够分散的情况下，均匀性可以获得，但一旦有节点加入或退出，所有的原有节点都会受到影响，稳定性无从谈起。

**一致性Hash：（不均衡）**

​		客户端分片：哈希+顺时针（优化取余）

​		节点伸缩：只影响邻近节点，但是还是有数据迁移

​		翻倍伸缩：保证最小迁移数据和负载均衡

​		一致性Hash可以很好的解决稳定问题，可以将所有的存储节点排列在收尾相接的Hash环上，每个key在计算Hash后会顺时针找到先遇到的一组存储节点存放。而当有节点加入或退出时，仅影响该节点在Hash环上顺时针相邻的后续节点，将数据从该节点接收或者给予。但这又带来均匀性的问题，即使可以将存储节点等距排列，也会在**存储节点个数变化时带来数据的不均匀**。

**Codis的Hash槽**

​		Codis 将所有的 key 默认划分为 1024 个槽位(slot)，它首先对客户端传过来的 key 进行 crc32 运算计算 哈希值，再将 hash 后的整数值对 1024 这个整数进行取模得到一个余数，这个余数就是对应 key 的槽位。

**RedisCluster**

​		Redis-cluster把所有的物理节点映射到[0-16383]个**slot**上,对key采用crc16算法得到hash值后对16384取模，基本上采用平均分配和连续分配的方式。



#### **2、主从模式=简单**

​	主从模式最大的优点是**部署简单**，最少**两个节点便可以构成主从模式**，并且可以通过**读写分离避免读和写同时不可用**。不过，一旦 Master 节点出现故障，主从节点就**无法自动切换**，直接导致 SLA 下降。所以，主从模式一般**适合业务发展初期，并发量低，运维成本低**的情况

<img src="https://s0.lgstatic.com/i/image/M00/80/25/Ciqc1F_QgPOAaL8TAAC5EiNlvo4795.png" alt="Drawing 1.png" style="zoom:50%;" />



**主从复制原理：**

​	①通过从服务器发送到PSYNC命令给主服务器

​	②如果是首次连接，触发一次**全量复制**。此时主节点会启动一个后台线程，生成 RDB 快照文件

​	③主节点会将这个 RDB 发送给从节点，slave 会先写入本地磁盘，再从本地磁盘加载到内存中

​	④master会将此过程中的写命令写入缓存，从节点**实时同步**这些数据

​	⑤如果网络断开了连接，自动重连后主节点通过命令传播**增量复制**给从节点部分缺少的数据

**缺点**

​	所有的slave节点数据的复制和同步都由master节点来处理，会照成master节点压力太大，使用主从从结构来解决，redis4.0中引入psync2 解决了slave重启后仍然可以增量同步。



#### 3、**哨兵模式**=读多

​	由一个或多个sentinel实例组成sentinel集群可以监视一个或多个主服务器和多个从服务器。**哨兵模式适合读请求远多于写请求的业务场景，比如在秒杀系统**中用来缓存活动信息。 如果写请求较多，当集群 Slave 节点数量多了后，Master 节点同步数据的压力会非常大。

<img src="https://tva1.sinaimg.cn/large/0081Kckwly1gluq6vlvglj30nw0e076f.jpg" alt="image-20201220231241725" style="zoom:50%;" />

当主服务器进入下线状态时，sentinel可以将该主服务器下的某一从服务器升级为主服务器继续提供服务，从而保证redis的高可用性。

**检测主观下线状态**

​	Sentinel每秒一次向所有与它建立了命令连接的实例(主服务器、从服务器和其他Sentinel)发送PING命 令

​	实例在down-after-milliseconds毫秒内返回无效回复Sentinel就会认为该实例主观下线(**SDown**)

**检查客观下线状态**

​	当一个Sentinel将一个主服务器判断为主观下线后 ，Sentinel会向监控这个主服务器的所有其他Sentinel发送查询主机状态的命令

​	如果达到Sentinel配置中的quorum数量的Sentinel实例都判断主服务器为主观下线，则该主服务器就会被判定为客观下线(**ODown**)。

**选举Leader Sentinel** 

​	当一个主服务器被判定为客观下线后，监视这个主服务器的所有Sentinel会通过选举算法(raft)，选出一个Leader Sentinel去执行**failover(故障转移)**操作。

​	**Raft算法**

​	Raft协议是用来解决分布式系统一致性问题的协议。 Raft协议描述的节点共有三种状态:Leader, Follower, Candidate。 Raft协议将时间切分为一个个的Term(任期)，可以认为是一种“逻辑时间”。 选举流程:
 	①Raft采用心跳机制触发Leader选举系统启动后，全部节点初始化为Follower，term为0

​	 ②节点如果收到了RequestVote或者AppendEntries，就会保持自己的Follower身份 

​	 ③节点如果一段时间内没收到AppendEntries消息，在该节点的超时时间内还没发现Leader，Follower就会转换成Candidate，自己开始竞选Leader。 一旦转化为Candidate，该节点立即开始下面几件事情:
​		--增加自己的term，启动一个新的定时器
​		--给自己投一票，向所有其他节点发送RequestVote，并等待其他节点的回复。

​	 ④如果在计时器超时前，节点收到多数节点的同意投票，就转换成Leader。同时通过 AppendEntries，向其他节点发送通知。

​	 ⑤每个节点在一个term内只能投一票，采取先到先得的策略，Candidate投自己， Follower会投给第一个收到RequestVote的节点。

​	 ⑥Raft协议的定时器采取随机超时时间（选举的关键），先转为Candidate的节点会先发起投票，从而获得多数票。

**主服务器的选择**

​	当选举出Leader Sentinel后，Leader Sentinel会根据以下规则去从服务器中选择出新的主服务器。

1. 过滤掉主观、客观下线的节点
2. 选择配置slave-priority最高的节点，如果有则返回没有就继续选择
3. 选择出复制偏移量最大的系节点，因为复制偏移量越大则数据复制的越完整
4. 选择run_id最小的节点，因为run_id越小说明重启次数越少

**故障转移**

​	当Leader Sentinel完成新的主服务器选择后，Leader Sentinel会对下线的主服务器执行故障转移操作，主要有三个步骤:

​	1、它会将失效 Master 的其中一个 Slave 升级为新的 Master , 并让失效 Master 的其他 Slave 改为复制新的 Master ;

​	2、当客户端试图连接失效的 Master 时，集群会向客户端返回新 Master 的地址，使得集群当前状态只有一个Master。

​	3、Master 和 Slave 服务器切换后， Master 的 redis.conf 、 Slave 的 redis.conf 和 sentinel.conf 的配置文件的内容都会发生相应的改变，即 Master 主服务器的 redis.conf配置文件中会多一行 replicaof 的配置， sentinel.conf 的监控目标会随之调换。



#### 4、集群模式=写多



​	为了避免单一节点负载过高导致不稳定，集群模式采用**一致性哈希算法或者哈希槽的方法**将 Key 分布到各个节点上。其中，每个 Master 节点后跟若干个 Slave 节点，用于**出现故障时做主备切换**，客户端可以**连接任意 Master 节点**，集群内部会按照**不同 key 将请求转发到不同的 Master** 节点

​	集群模式是如何实现高可用的呢？集群内部节点之间会**互相定时探测**对方是否存活，如果多数节点判断某个节点挂了，则会将其踢出集群，然后从 **Slave** 节点中选举出一个节点**替补**挂掉的 Master 节点。**整个原理基本和哨兵模式一致**

​	虽然集群模式避免了 Master 单节点的问题，但**集群内同步数据时会占用一定的带宽**。所以，只有在**写操作比较多的情况下人们才使用集群模式**，其他大多数情况，使用**哨兵模式**都能满足需求



#### 5、分布式锁

**利用Watch实现Redis乐观锁**

​	乐观锁基于CAS(Compare And Swap)比较并替换思想，不会产生锁等待而消耗资源，但是需要反复的重试，但也是因为重试的机制，能比较快的响应。因此我们可以利用redis来实现乐观锁**（秒杀）**。具体思路如下:

1、利用redis的watch功能，监控这个redisKey的状态值 
2、获取redisKey的值，创建redis事务，给这个key的值+1 
3、执行这个事务，如果key的值被修改过则回滚，key不加1

**利用setnx防止库存超卖**
	分布式锁是控制分布式系统之间同步访问共享资源的一种方式。 利用Redis的单线程特性对共享资源进行串行化处理

```java
// 获取锁推荐使用set的方式
String result = jedis.set(lockKey, requestId, "NX", "EX", expireTime);
String result = jedis.setnx(lockKey, requestId); //如线程死掉，其他线程无法获取到锁
```

```java
// 释放锁，非原子操作，可能会释放其他线程刚加上的锁
if (requestId.equals(jedis.get(lockKey))) { 
  jedis.del(lockKey);
}
// 推荐使用redis+lua脚本
String lua = "if redis.call('get',KEYS[1]) == ARGV[1] then return redis.call('del',KEYS[1]) else return 0 end";
Object result = jedis.eval(lua, Collections.singletonList(lockKey),
```



**分布式锁存在的问题**：

- **客户端长时间阻塞导致锁失效问题**

​	计算时间内异步启动另外一个线程去检查的问题，这个key是否超时，当锁超时时间快到期且逻辑未执行完，延长锁超时时间。

- **Redis服务器时钟漂移问题导致同时加锁
  redis的过期时间是依赖系统时钟的，如果时钟漂移过大时 理论上是可能出现的 **会影响到过期时间的计算。

- **单点实例故障，锁未及时同步导致丢失**

  **RedLock算法**

1. 获取当前时间戳T0，配置时钟漂移误差T1

2. 短时间内逐个获取全部N/2+1个锁，结束时间点T2

3. 实际锁能使用的处理时长变为：TTL - （T2 - T0）- T1

   该方案通过多节点来**防止Redis的单点故障**，效果一般，也无法防止：

- **主从切换导致的两个客户端同时持有锁**

  大部分情况下**持续时间极短**，而且使用**Redlock在切换的瞬间**获取到节点的锁，也存在问题。已经是极低概率的时间，无法避免。**Redis分布式锁适合幂等性事务**，如果一定要**保证安全**，应该**使用Zookeeper或者DB**，但是，**性能会急剧下降**。



**与zookeeper分布式锁对比**

- redis 分布式锁，其实**需要自己不断去尝试获取锁**，比较消耗性能。
- zk 分布式锁，注册个监听器即可，不需要不断主动尝试获取锁，ZK获取锁会按照加锁的顺序，所以是公平锁，性能和mysql差不多，和redis差别大





**Redission生产环境的分布式锁**

​	Redisson是基于NIO的Netty框架上的一个Java驻内存数据网格(In-Memory Data Grid)分布式锁开源组件。 

<img src="https://tva1.sinaimg.cn/large/0081Kckwly1glurlfrrp4j30qk0g876c.jpg" alt="image-20201221000119586" style="zoom:67%;" />

但当业务必须要数据的强一致性，即不允许重复获得锁，比如金融场景(重复下单，重复转账)，**请不要使用redis分布式锁**。可以使用CP模型实现，比如:**zookeeper和etcd。**

|            | Redis    | zookeeper  | etcd       |
| ---------- | -------- | ---------- | ---------- |
| 一致性算法 | 无       | paxos(ZAB) | raft       |
| CAP        | AP       | CP         | CP         |
| 高可用     | 主从集群 | n+1        | n+1        |
| 实现       | setNX    | createNode | restfulAPI |





#### 6、redis心跳检测

在命令传播阶段，从服务器默认会以每秒一次的频率向主服务器发送ACK命令:

​	1、检测主从的连接状态 检测主从服务器的网络连接状态

​			lag的值应该在0或1之间跳动，如果超过1则说明主从之间的连接有 故障。

​	2、辅助实现min-slaves,Redis可以通过配置防止主服务器在不安全的情况下执行写命令

```yaml
min-slaves-to-write 3 (min-replicas-to-write 3 )

min-slaves-max-lag 10 (min-replicas-max-lag 10)
```

​		上面的配置表示:从服务器的数量少于3个，或者三个从服务器的延迟(lag)值都大于或等于10 秒时，主服务器将拒绝执行写命令。

​	3、检测命令丢失，增加重传机制

​		如果因为网络故障，主服务器传播给从服务器的写命令在半路丢失，那么当从服务器向主服务器发 送REPLCONF ACK命令时，主服务器将发觉从服务器当前的复制偏移量少于自己的复制偏移量， 然后主服务器就会根据从服务器提交的复制偏移量，在复制积压缓冲区里面找到从服务器缺少的数据，并将这些数据重新发送给从服务器。



### Redis实战

#### 1、Redis优化

![img](https://tva1.sinaimg.cn/large/008eGmZEly1gorm5m7b4gj30uy0hjwfp.jpg)

**读写方式**
	简单来说就是不用**keys**等，用**range、contains**之类。比如，用户粉丝数，大 V 的粉丝更是高达几千万甚至过亿，因此，获取粉丝列表只能部分获取。另外在判断某用户是否关注了另外一个用户时，也只需要关注列表上进行检查判断，然后返回 True/False 或 0/1 的方式更为高效。

**KV size**
	如果单个业务的 KV size 过大，需要分拆成多个 KV 来缓存。拆分时应**考虑访问频率**

**key 的数量**
	如果数据量巨大，则在缓存中尽可能只保留频繁访问的热数据，对于冷数据直接访问 DB。

**读写峰值**
	如果小于 10万 级别，简单分拆到独立 Cache 池即可
	如果达到 100万 级的QPS，则需要对 Cache 进行分层处理，可以同时使用 Local-Cache 配合远程 cache，甚至远程缓存内部继续分层叠加分池进行处理。**（多级缓存）**

**命中率**
	缓存的命中率对整个服务体系的性能影响甚大。对于核心高并发访问的业务，需要预留足够的容量，确保核心业务缓存维持较高的命中率。比如微博中的 Feed Vector Cache（**热点资讯**），常年的命中率高达 99.5% 以上。为了持续保持缓存的命中率，缓存体系需要持续监控，及时进行故障处理或故障转移。同时在部分缓存节点异常、命中率下降时，故障转移方案，需要考虑是采用一致性 Hash 分布的访问漂移策略，还是采用数据多层备份策略。

**过期策略**

​	可以设置较短的过期时间，让冷 key 自动过期；也可以让 key 带上时间戳，同时设置较长的过期时间，比如很多业务系统内部有这样一些 key：key_20190801。

**缓存穿透时间**
	平均缓存穿透加载时间在某些业务场景下也很重要，对于一些缓存穿透后，加载时间特别长或者需要复杂计算的数据，而且访问量还比较大的业务数据，要配置更多容量，维持更高的命中率，从而减少穿透到 DB 的概率，来确保整个系统的访问性能。

**缓存可运维性**
	对于缓存的可运维性考虑，则需要考虑缓存体系的集群管理，如何进行一键扩缩容，如何进行缓存组件的升级和变更，如何快速发现并定位问题，如何持续监控报警，最好有一个完善的运维平台，将各种运维工具进行集成。

**缓存安全性**
	对于缓存的安全性考虑，一方面可以限制来源 IP，只允许内网访问，同时加密鉴权访问。



#### 2、Redis热升级

> 在 Redis 需要升级版本或修复 bug 时，如果直接重启变更，由于需要数据恢复，这个过程需要近 10 分钟的时间，时间过长，会严重影响系统的可用性。面对这种问题，可以对 Redis 扩展热升级功能，从而在毫秒级完成升级操作，完全不影响业务访问。

热升级方案如下，首先构建一个 Redis 壳程序，将 redisServer 的所有属性（包括redisDb、client等）保存为全局变量。然后将 Redis 的处理逻辑代码全部封装到动态连接库 so 文件中。Redis 第一次启动，从磁盘加载恢复数据，在后续升级时，通过指令，壳程序重新加载 Redis 新的 redis-4.so 到 redis-5.so 文件，即可完成功能升级，毫秒级完成 Redis 的版本升级。而且整个过程中，所有 Client 连接仍然保留，在升级成功后，原有 Client 可以继续进行读写操作，整个过程对业务完全透明。





