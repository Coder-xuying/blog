# 计算机网络

## 0.基础

### 1.TCP/IP网络模型有几层？

#### 1.应用层

最上层，我们的电脑、手机使用的应用软件都是在应用层实现的。

> 应用层提供的协议或者功能

- HTTP、FTP、Telnet、DNS、SMTP

**应用层在操作系统的用户态，传输层及以下的在内核态**

#### 2.传输层

传输层的两个协议：TCP和UDP

- TCP 的全称叫传输控制协议（*Transmission Control Protocol*），TCP比UDP多了很多特性，比如流量控制、超时重传、拥塞控制等，都是为了保证数据包能够可靠的传输给对方。

- UDP就很简单，只负责发送数据包，实效性强传输效率高。
- 应用层传输的数据很大，当超过MSS（TCP最大报文段长度），需要将数据包分块，每个块称为一个TCP段，当有一个块丢失损坏，只需要重新传送这一个分快就可以。

#### 3、网络层

实际中的网络十分复杂，中间有各种各样的线路，把一个设备的数据传到另一个设备由网络层来实现。

网络层使用的IP协议，将传输层的报文作为数据部分，加上IP报文头组成IP报文，如果IP报文超过MTU（通常1500字节）就再次分片。

> 网络层怎么找到对应的接受设备？

- IP寻址：（IP地址和子网掩码）

- 路由：两台设备并不是用一条网线连接起来的，而是通过很多网关、路由器、交换机等众多网络设备连接起来的，需要通过路由算法决定下一步走哪条路径

**IP 协议的寻址作用是告诉我们去往下一个目的地该朝哪个方向走，路由则是根据「下一个目的地」选择路径。寻址更像在导航，路由更像在操作方向盘**。

#### 4.网络接口层





## 1、HTTP

### 1.1常见的面试题

#### 1.HTTP常见的状态码

- 1XX  提示信息，表示目前是协议处理的中间状态
- 2XX  服务器成功处理了客户端的请求
  - 200，成功处理，响应头会有body
  - 204 ，和200基本相同，响应头没有body数据
- 3XX 客户端请求的资源发生了变动，需要用新的URL重新发送请求，重定向
  - 301 永久重定向，资源已经不在了，需要改用新的URL访问
  - 302 临时重定向，资源还在，暂时需要去另一个URL来访问
- 4XX  客户端发送的报文有误，服务器无法处理
  - 400 客户端请求报文有错误，笼统的
  - 403 服务器禁止访问资源，没有权限，不是客户端请求出错
  - 404 资源在服务器上不存在
- 5XX 服务器处理请求错误，内部错误
  - 500 服务器发生错误，笼统的，不知道什么情况
  - 501 客户端请求的功能还不支持
  - 502 服务器作为网关或者代理返回的错误码，表示服务器自身工作正常，访问后端服务器发生错误
  - 503 服务器忙

#### 2.HTTP常见的字段

HOST：客户端发送请求，指定服务器的域名

Content-Length： 表示服务端返回的数据长度

Connection： 用于TCP持久连接的，1.1默认持久连接，老版本可以设置为Keep-Alive，可以连接复用了

Content-type： 服务端返回数据的格式

Content-Encoding： 服务端返回的数据的压缩方法



#### 3.Get和POST的区别

GET：

- 是从服务器获取资源
- 是安全和幂等的

POST：

- 是向URL指定资源的提交数据，数据放在报文的body里
- 不安全的，也不是幂等的

#### 4.Http缓存

对于一些有重复性的http请求，比如每次得到的数据都一样，就可以吧响应的数据缓存在本地，下次直接读取本地。HTTP 协议的头部有不少是针对缓存的字段，HTTP 缓存有两种实现方式，分别是**强制缓存和协商缓存**

> 强制缓存

强制缓存是指只要浏览器判断缓存没有过期，直接使用本地缓存，缓存的决定权在浏览器这里。强制缓存利用的是响应头里的下面两个字段：

-  `Cache-Control`， 是一个相对时间；（**优先级更高**（有了这个字段和Expires字段，用这个字段的时间），通常用这个）

- `Expires`，是一个绝对时间；

**过程**：当浏览器第一次请求服务器，服务器会在返回资源的同时，在返回的头部加上Cache-Control字段，当浏览器再次请求该资源时，先比较请求时间和设置的过期时间，如果没有过期，则使用该缓存，否则重新请求服务器（服务器收到请求后会更新Cache-Control字段）

> 协商缓存

304字段，就是协商的。

过程：

- 浏览器向服务器请求获得资源，资源缓存在本地。
- 浏览器再次向服务器请求，服务器获得请求之后进行比较，发现资源基本没什么改变，于是返回304字段告诉浏览器可以走本地缓存
- 浏览器收到304后，就从本地缓存中加载资源。

协商缓存两种实现：

- 1.请求头部中的 `If-Modified-Since` 字段与响应头部中的 `Last-Modified` 字段实现：返回的响应头中有 `Last-Modified` ，那么下次请求就将这个字段的值给 `If-Modified-Since`。
- 2.请求头部中的 `If-None-Match` 字段与响应头部中的 `ETag` 字段（类似于hash吧，给一个唯一的），同上响应头中带有ETag字段，然后请求的时候将值赋给 `If-None-Match` ，服务器比较ETag的值，如果没有改变，就返回304
- （ETag的优先级更高，如果同时有这两个字段就走ETag）

协商缓存都需要配合强制缓存的的Cache—Control使用，先判断有没有过期，如果过期了，再走协商缓存。

#### 5、HTTP1.1的优缺点

**优点**：

- 简单，容易理解和学习
- 灵活和容易扩展
- 应用广泛，跨平台

**缺点**：

- 无状态

  - 好处：减轻了服务器的负担，不需要记忆http的状态

  - 缺点：对完成有关联性的操作会比较麻烦

    - 一般用Cookie解决无状态的问题

- 明文传输不安全

  - 使用HTTPS解决

#### 6.HTTP1.1 如何优化

- *尽量避免发送 HTTP 请求*；
  - 缓存
- *在需要发送 HTTP 请求时，考虑如何减少请求次数*；
  - *减少重定向请求次数*；
    - **重定向的工作交由代理服务器完成，就能减少 HTTP 请求次数了**
  - 合并请求
    - 减少请求，也就意味着**减少了重复发送的 HTTP 头部**。
    - 把小资源的请求整合成大资源（多个小图片，可以合成一个大的，然后做切割，或者将图片）
      - 问题：如果小资源改变了，必须重新请求大资源，带来了额外的网络消耗
  - 延迟发送请求：可以通过「**按需获取**」的方式，来减少第一时间的 HTTP 请求次数。不需要的资源后面慢慢请求
- *减少服务器的 HTTP 响应的数据大小*；对响应的资源进行**压缩**
  - 无损压缩：
    - 无损压缩是指资源经过压缩后，信息不被破坏，还能完全恢复到压缩前的原样
    - 比如gzip，gzip 的压缩效率相比 Google 推出的 Brotli 算法还是差点意思
  - 有损压缩
    - 解压的数据会与原始数据不同但是非常接近（牺牲一些质量）。这种方法经常用于压缩多媒体数据，比如音频、视频、图片。

### 1.2 HTTPs

#### 1. HTTPS和HTTP区别

- HTTP明文传输，HTTPS加入了SSL/TLS安全协议，报文加密传输
- HTTP连接建立简单三次握手，HTTPS在三次握手之后还需要进行SSL/TLS的握手
- HTTP端口号-80，HTTPS-443
- HTTPS需要向CA申请数字证书，来保证服务器的身份是可信的

#### 2.HTTPS解决了HTTP的哪些问题？

> HTTP的三个风险

- 窃听风险：明文传输，账号密码（可以从通信链路中获取）
- 篡改风险：篡改通信内容，强制植入垃圾广告
- 冒充风险：冒充淘宝网站之类的

> HTTPS如何解决的

- 信息加密：混合加密实现信息的**机密性**
  - 混合加密：非对称加密交换`会话密钥`，使用对称加密的密钥加密明文数据
- 校验机制：摘要算法实现信息的**完整性**
  - 摘要算法+数字签名
  - 1.将响应的内容做一个hash作为摘要一起返回回去=》中间人还是可以替换
  - 2.数字签名，使用`私钥加密，公钥解密`的方式保证消息不会被冒充，也就是非对称密钥私钥加密hash的值制作一份数字签名，然后接收着用公钥解开它
    - 公钥如果也是假的怎么办，看下面的身份验证
- 身份证书：服务器的公钥给CA，解决了冒充风险
  - 数字证书：需要一个可信第三方CA
    - 服务器将自己的公钥注册到 CA，CA用自己的私钥给服务器的公钥进行签名，把这个加密之后的东西叫做数字证书，然后将数字证书给服务器
    - 服务器返回公钥和数字证书给客户端
    - 客户端拿到数字证书和公钥，会使用CA的公钥进行解密确认（CA的公钥一开始就内嵌到浏览器了），就能验证公钥是不是正确的，然后用这个公钥加密数据发送



#### 3. HTTPS怎么建立连接，握手过程

四次握手：

- *ClientHello*：客户端发起加密通信请求
  - 信息：SSL/TLS协议版本，客户端随机数，客户端支持的密码套件
- ServerHello：服务器响应
  - 信息：确认 SSL/ TLS 协议版本，如果浏览器不支持，关闭加密通道，服务器随机数，确认密码套件，**数字证书**
- 客户端回应：客户端会先用浏览器的CA验证数字证书的正确性，如果是正确的从数字证书中拿出服务器的公钥，然后用公钥加密报文，报文包含的信息有
  - 信息：随机数，加密通信算法改变通知（之后都用会话密钥），客户端握手结束（把之前所有数据做一个摘要，让服务端检验）
  - 客户端和服务端会用上面的三个随机数，生成会话密钥，随机数用公钥加密，其他的都是用会话密钥加密发送过去的（并不是一次发送，而是一个一个发过去）
- 服务器最后回应：用会话密钥加密发送信息
  - 信息：加密通信算法改变通知，之前所有数据做一个摘要（让客户端检验）

### 1.3 HTTP1.1 、HTTP2、HTTP3

##### HTTP1

> HTTP1.1协议存在的一些问题

- 消息的大小变大了
- 页面资源变多，一个页面100多资源
- 内容的形式变多样了
- 实时性要求更高

这些使HTTP1.1的延迟变高，就会影响用户的体验

- 并发连接有限
- 队头阻塞
- HTTP头部巨大且重复
- 不支持服务器推送消息，只能client需要获取通知的时候，通过定时器拉取消息，浪费了带宽和服务器资源

##### HTTP2

> HTTP2就是为了解决上述问题的

http2兼容http1.1. 只在应用层做了改变，HTTP2把HTTP分解成了语义和语法两部分，语义不做改变与HTTP1.1保持一致，比如请求方法，头字段，状态码等， 语法层面改了很多，改变了HTTP报文的传输格式



> 改变如下

http2是基于https的，所以安全性有保障

**做的改变**：

**优点**：

- 头部压缩
  - http的**头部信息**未经压缩就发送，每次都发送相同的头部浪费也多(含很多固定的字段，比如Cookie、 User Agent、Accept 等，)
  - http2会压缩头部，如果你同时发送多个请求，他们的头一样或者类似，协议会帮你消除重复的部分(**HPACK算法**：**在客户端和服务器端维护一张头信息表**，所有字段放进这个表里，然后生成一个索引号，只发送索引号)
  - HAPCK组成部分
    - **静态字典** ：为高频字段和字符串建立了一张表，这个在HTTP2的框架里面，大概61组。
      - 例子： **index** : 2   **value**： `  method:Get`   3就表示post方法    8表示状态码为200  等等 有的value是空着的，代表不是固定的，就用Huffman编码再发送过去
      - server: nghttpx\r\n 的头部。总共17字节，用静态表和Huffman编码可以压缩成8字节
      - HTTP/2 头部用二进制编码，不要用冒号空格\n\r来分割，用字符串长度来分割value和index
    - **动态字典**：将首次发送过来的头部，存起来用放进字典里。客户端和服务端都更新自己的动态表，下次发送同样的请求头直接发动态表里的index过去。这样每次有新的头部，动态表就会+1，会占用较大的内存，影响服务器的性能。因此有一个限制连接上的请求数量，避免动态表无限增大，到达上限之后，会关闭HTTP2连接来释放内存
    - Huffman编码
- 二进制帧 ： 响应报文分为两个帧，一个是首部，一个是数据DATA
  - ![image-20210819100644128](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210819100644.png)  <img src="https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210819100705.png" style="zoom:50%;" />
    - 帧类型有10中，分为数据帧和控制帧
  - http2不是http1.1里的纯文本形式的报文，而是全面采用了二进制格式，这样对机器更友好，可以直接解析二进制报文，增加了数据传输的效率
- 并发传输：**多个Stream复用一条TCP连接，达到并发的效果**，一个TCP里有多个Stream，一个Stream有多个Message(对应HTTP1的请求和响应)，一个Message有多个Frame（二进制压缩后的数据，存放头部和包体）这是最小的单位。
  - 不同Stream是可以乱序发送的，，每个帧头部会携带Stream的ID，之后接收端通过Stream ID有序组装成HTTP消息，一个Stream内部的帧必须严格有序
  - 服务器使用偶数的Stream ID，客户端使用奇数的StreamID
  - 可以在一个连接中并发多个请求或者回应，不用按照顺序一一对应，降低了延迟，提高了链接的利用率
- 服务器主动推送资源：使用偶数号Stream。通过PUSH_PROMISE传输头部，并通过帧中的Promised Stream ID 告诉client，会在哪个偶数号Stream中发送包体
  - <img src="https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210819101515.png" alt="image-20210819101515441" style="zoom:50%;" /> 可以看到在Stream 1中通知客户端CSS资源即将到来，然后在Stream2中发送CSS资源， 1和2可以并行发送

**缺点**：

- HTTP2多个请求复用一个TCP链接，**一旦丢包**，数据包会在内核等待，就会阻塞住所有的HTTP请求(TCP的机制)
- TCP和TLS的握手，延迟有点高，TCP3次握手，TLS四次握手
- HTTP1和2是通过四元组(源IP、 源端口、目的IP、目的端口)确定TCP连接的,网络迁移需要重新连接，也就是IP地址改变(移动网络切换为wifi) ，就要重新握手



##### HTTP3

> HTTP3出现

HTTP3就是把HTTP2底层的 传输协议TCP改成了UDP，然后UDP是不可靠的，基于UDP的QUIC协议可以实现类似TCP的可靠性传输

- QUIC协议可以保证数据包的可靠性，UDP不关心数据包丢失的问题，QUIC会重传丢失的报文。然后数据才交付给HTTP3.也就是Stream的一个流阻塞了，其他的流还是可以正常传输，数据交付给HTTP3
- HTTP中TCP和TLS是分层的，所以握手要分批次。HTTP三种的QUIC是包含TLS，握手的时候两个可以一起我，只需要一次RTT就可以完成
- QUIC不是通过四元组方式绑定连接，而是通过连接ID来标记通信的端点。这样即使网络IP变化，只要有连接ID和TLS密钥，就可以复用连接。不需要再次握手

   

![image-20210810094611171](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210810094611.png)



#### 7、HTTP如何优化

- 避免发送HTTP请求 -- 缓存起来
  - 就是把一些重复性的HTTP请求，得到的数据缓存在本地，URL作为key，响应当做value，然后发起相同请求，先去磁盘通过key找到value，就可以直接在本地读取了。 可能会有响应修改的问题
  - 服务器在发送http响应时，会估算一个过期时间放在响应头，然后客户端查看响应头信息，发现过期了，就重新发送网络请求
  - 第二次发送网络连接的时候，只需要在请求头的Etag加上第一次获得的响应头的摘要，然后服务器收到会进行摘要的比对，发现资源据并没有更新，也就是缓存可以继续使用，那么服务器知返回304Not Modifidied的响应，这样可以减少响应资源在网络中传输的延时。

- 减少HTTP请求次数
  - 减少重定向次数
  - 合并请求
  - 延迟发送，其实就是异步加载
- 减少HTTP响应的数据大小
  - 对响应的资源进行压缩，减少响应数据的大小，提高网络传输的效率
  - 有损压缩 -牺牲质量来减少数据量
  - 无所压缩 - gzip



## 1、 WebSocket

#### 1.是什么

WebSocket，

- 是一种网络传输协议，位于应用层。可在单个`TCP`连接上进行全双工通信，能更好的节省服务器资源和带宽并达到**实时通迅**。

- 客户端和服务器只需要完成一次握手（在TCP三次握手建立链接之后），两者之间就可以创建持久性的连接，并进行双向数据传输。

- 在`websocket`出现之前，开发实时`web`应用的方式为轮询，不停地向服务器发送 HTTP 请求，问有没有数据，有数据的话服务器就用响应报文回应。如果轮询的频率比较高，那么就可以**近似地实现“实时通信”**的效果



#### 2.特点

- 全双工，通信允许数据在两个方向上同时传输
- 二进制帧
- 协议名
  - 引入`ws`和`wss`分别代表明文和密文的`websocket`协议，且默认端口使用80或443，几乎与`http`一致
- 握手报文
  - Connection：必须设置Upgrade，表示客户端希望连接升级
  - Upgrade：必须设置Websocket，表示希望升级到Websocket协议
  - Sec-WebSocket-Key：客户端发送的一个 base64 编码的密文，用于简单的认证秘钥。要求服务端必须返回一个对应加密的“Sec-WebSocket-Accept应答，否则客户端会抛出错误，并关闭连接
  - 服务器响应报文：
    - 状态码： 101，它其实是指**协议切换**。
    - Sec-WebSocket-Accept：根据客户端生成的 Sec-WebSocket-Key码，用某个**公开的**算法变成另一段字符串
    - connection和upgrade字段和握手的一样
- 优点
  - 较少的控制开销：数据包头部协议较小，不同于http每次请求需要携带完整的头部
  - 更强的实时性
  - 保持连接状态：创建通信后，可省略状态信息，不同于HTTP每次请求需要携带身份验证
  - 更好的二进制支持：定义了二进制帧，更好处理二进制内容
  - 支持扩展：用户可以扩展websocket协议、实现部分自定义的子协议

#### 3.WebSocket的消息格式

![image-20221025131950645](/Users/xuying/Library/Application Support/typora-user-images/image-20221025131950645.png)

重点字段：

- **opcode字段**：用来标志这是个**什么类型**的数据帧
  - 等于 1 ，是指text类型（`string`）的数据包
  - 等于 2 ，是二进制数据类型（`[]byte`）的数据包
  - 等于 8 ，是关闭连接的信号
- **payload字段**，存放的是我们**真正想要传输的数据的长度**，单位是**字节**。
  - 可以看到有多个payload的字段，那么怎么确定长度？
  - 先读第一个payload的，也就是7字节的
  - 如果是0-125，那么这就是数据的长度。
  - 如果是126，那么还要再读接下来的16字节的数据（扩展用的字段），这16字节的数据是数据的真实长度
  - 如果是127，那么读后面的64字节的数据，这是数据的长度，能放TB级别了
- payloadData，这个是存放真正要传输的数据



#### 4.应用场景

- 弹幕
- 基于位置的应用
- 股票基金报价实时更新
- 协同编辑

## 2、TCP连接

### TCP的基本认识

#### TCP的头部字段

- 源端口号和目的端口号：16位
- 序列号：建立连接时的随机数，每次发送一次，就加上发送的数据的字节数，**用来解决网络包乱序问题（SYN包）**，32位
- 确认应答号：下一次希望收到的数据的序列号，收到这个意味着之前发送的数据已经接受了。**用来解决丢包问题**，32位
- 控制位：
  - ACK：为1时，确认应答字段有效，只有最开始的SYN包时，ACK为0
  - RST：为1时，表示TCP连接出现异常，必须立刻断开连接
  - SYN：为1时，表示希望建立连接，并随机序列号
  - FIN：为1时，表示之后不再有数据发送，希望断开连接

#### TCP和UDP的区别

- TCP面向连接，发送数据之前需要建立连接，UDP不需要
- TCP是一对一对，UDP是一对一，一对多，多对多的
- TCP是可靠的，UDP不可靠
- TCP有拥塞控制和流量控制来保证数据传输的安全性，UDP没有
- TCP的首部开销比较大，有选项这个字段，开启选项之后是不定长的，UDP只有8字节固定不变的
- TCP是流式传输，没有边界，保证顺序可靠交付，UDP是一个包一个包的发送，有边界，但是会丢包和乱序



### 三次握手

Tcp报文首部重要字段：

- 序号(seq)，4个字节。TPC连接中传送的字节流中的每个字节都按顺序编号。 一段报文的序号字段值是 301 ，而携带的数据共有100字段，显然下一个报文段（如果还有的话）的数据序号应该从401开始；
- 确认号，占4个字节，是期望收到对方下一个报文的第一个数据字节的序号。例如，B收到了A发送过来的报文，其序列号字段是501，而数据长度是200字节，这表明B正确的收到了A发送的到序号700为止的数据。因此，B期望收到A的下一个数据序号是701，于是B在发送给A的确认报文段中把确认号置为701；
- 确认ACK，ACK=1，确认号字段才有效
- 同步SYN，在连接建立时用来同步序号。当SYN=1，ACK=0，表明是连接请求报文，若同意连接，则响应报文中应该使SYN=1，ACK=1；
- 终止FIN，用来释放连接。当FIN=1，表明此报文的发送方的数据已经发送完毕，并且要求释放

![image-20210722151245488](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210722151245.png)



![image-20210710205729198](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210710205729.png)



#### 为什么需要三次握手？

- 为了防止旧的重复连接初始化造成混乱
  - 比如遇到网络拥堵，旧的数据包先到达目的主机了，这时候服务器就会返回一个旧的ack+1给客户端，客户端一比较，这个ack和自己需要的有点不一样，就发送RST中止连接。之后新的数据包又到达主机 了，主机又返回ack+1,给客户端，客户端这次可以，就把第三次握手发送过去，建立连接
  - 如果是两次握手： 久的连接发送过去，服务端立马就established，然后服务端就能传数据来，等客户端收到旧连接的ack之后，就要发送RST，此时服务端再断开连接。问题：**服务端先建立连接了，白白发送了部分资源**
- 建立可信传输通道
- 同步双方初始序列号 （序列号都是随机的，三次握手可以让双方知道对方的序列号）

#### 握手报文丢失会发什么

##### 第一次握手丢失，会怎么样

- 客户端迟迟收不到ack，会处罚超时重传，**重传的 SYN 报文的序列号都是一样的**
- SYN 报文最大重传次数由 `tcp_syn_retries`内核参数控制，这个参数是可以自定义的，默认值一般是 5
  - 每一次重传时间是上一次的两倍
  - 达到最大重传次数之后，再等一会（上一次超时时间的两倍），如果没有收到ack，就断开连接

##### 第二次握手丢失，会怎么样

- 客户端迟迟收不到ack，会触发超时重传，重传SYN报文
- 服务端就收不到ack，于是**服务端这边会触发超时重传机制，重传 SYN-ACK 报文**。
- 同上，超过了最大重传次数，比如客户端超过了，客户端就断开连接

##### 第三次握手丢失

- 服务端就收不到第ack，于是**服务端这边会触发超时重传机制，重传 SYN-ACK 报文**。
- 客户端什么都不做，就等着对面再发过来。

### SYN攻击

在 TCP 三次握手的时候，Linux 内核会维护两个队列，分别是：

- 半连接队列，也称 SYN 队列；
- 全连接队列，也称 accept 队列；

这两个队列的工作流程：

- 客户端发送SYN报文，服务端收到后，会创建一个半连接对象，放进半连接队列中，并发送SYN-ACK报文回去，等待客户端发送ACK过来
- 服务端收到客户端发送的ACK之后，就会从半连接队列中取出这个对象，然后生成一个全连接对象，放入accept队列
- 应用通过调用accept()接口，从accept队列中取出连接对象

半连接队列和全连接队列都有最大长度，当满了之后，再发送报文过来，会直接丢弃

> 怎么避免SYN攻击

- 增大 TCP 半连接队列
- 开启 net.ipv4.tcp_syncookies，设置为1即可
  - 开启 syncookies 功能就可以在不使用 SYN 半连接队列的情况下成功建立连接
  - 过程：当SYN队列满了，会根据算法计算出cookie，并放进第二次握手的报文的序列号中，发送给客户端。之后客户端回应ACK，服务端检验这个ACK的合法性，如果合法就放进ACCEPT队列
  - 0 值，表示关闭该功能；
  - 1 值，表示仅当 SYN 半连接队列放不下时，再启用它；
  - 2 值，表示无条件开启功能；
- 减少 SYN+ACK 重传次数
  - 因为一直收不到ACK，所以会重发SYN-ACK，只要减小重传次数，当超过重传次数之后，就会断开这个链接

### 四次挥手

> 四次挥手

![image-20210722152846041](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210722152846.png)

![image-20210722152523993](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210722152524.png)



**为什么需要等待2MSL？**

MSL：报文最长生存时间

为了确保客户端发送的最后一个ACK能够到达服务器。如果这个ACK丢了，服务器过了一会没收到信息，就以为自己发送的报文对方没收到，然后重新发送。客户端就能够在2MSL的时间里收到这个重传的报文，这时候就给出回应，然后刷新2MSL计时器。



https://blog.csdn.net/qzcsu/article/details/72861891





### 如何保证可靠传输

#### 1、重传机制

> 超时重传

发送数据时，设置一个定时器，超过指定的时间，没有收到对方的ACK确认应答报文，就重发数据。

两种情况下发生：

- 数据包丢失
- 确认应答ack丢失

RTT(往返时间)，一般把超时时间设置为略大于RTT。

超时时间太长就降低传输的效率，太短会有不必要的重传

> 快速重传

不以时间为驱动，以数据驱动重传

发送1,2,3,4,5分数据过去，结果2丢了，然后3,4,5传过去，收到了三次ACK2(三次相同的ack)，就知道要重传数据。但是我们要重传2，还是要重传2345了。根据tcp的实现都有可能

> SACK方法  选择性确认

![image-20210814104217680](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210814104217.png)



我们收到了三次同样的ack，就知道需要重传哪一部分的数据了。这个必须双方都支持sack才行



#### 2、滑动窗口

窗口的实现实际上是操作系统开辟的一个缓存空间，发送方主机在等到确认应答返回之前，必须在缓冲区中保留已发送的数据。如果按期收到确认应答，此时数据就可以从缓存区清除。

**累积确认**

![image-20210814110055715](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210814110055.png)



收到了ack700，意味着700之前的数据都被接受到了

> 窗口的大小

通常窗口的大小是由接收方的窗口大小来决定的。发送方不能大于它，否则接收方无法正常接收到数据

> 发送方的滑动窗口

![image-20210814110244202](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210814110244.png)

发送窗口就是发送方能发送的数据大小，如果一次都发送出去了，没有收到ack之前，这个窗口的容量就是0，收到32-36字节的ack确认信息之后，滑动窗口就右移5字节，接下来的52-56就变成**可用的窗口**了。



> 接收方的滑动窗口

![image-20210814110536443](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210814110536.png)



#### 3、流量控制

发送方不能无脑的发送数据给接收方，控制窗口的大小



> 操作系统的缓冲区和滑动窗口的关系

实际上，发送窗口和接收窗口中所存放的字节数，都是放在操作系统内存缓冲区中的，而操作系统的缓冲区，会被操作系统调整。



这么一个过程： 可用窗口都是360字节

- 客户端发了140字节的数据过来，可用窗口就是360-140 = 220
- 服务端收到了140字节的数据，但是服务端比较忙，应用进程只读取了40字节，还有100字节在缓冲区里面，于是接收窗口就收缩到了360-100 = **260**
- 客户端收到确认和窗口通告的报文，发送窗口减少为260
- 客户端发送数据180，可用窗口就是260-180 = 80
- 服务端收到180，但是没有读取任何数据，直接留在缓冲区了，于是 260-180 = 80
- 客户端再次更新自己的发送窗口，然后发送80过去
- 服务端收到80 给缓冲区，80-80 = 0，接受窗口就变成0，并返回给客户端，客户端也变成0
- 最后窗口都收缩成了0，就发生窗口关闭

窗口关闭了之后，发送方会定时发送窗口探测报文，来知道接收方的窗口有没有改变



第二种情况： 操作系统直接减少了缓冲区的大小，那么应用程序无法及时读取缓冲区数据，会发生数据包丢失的现象

如果发生了先减少缓存，再收缩窗口，就会出现丢包的现象。(**因为缓存少了，但是窗口还没变，就发了这么多数据过来，缓存放不下，就丢失了**)
为了防止这种情况发生，TCP规定是不允许同时减少缓存又收缩窗口的，而是**采用先收缩窗口，过段时间再减少缓存**，这样就可以避免了丢包情况。

> 窗口关闭

如果窗口的大小变成0，就会阻止发送方给接收方传递数据，直到窗口变为非0为止，这就是窗口关闭。

如果关闭就会有一个问题，加入服务器那边，窗口恢复了，发送报告的报文在传输过程中丢了，那么client端就不知道窗口恢复了，还在继续等待，就会陷入死锁。

TCP为了解决这个问题，为每个连接设置了一个持续定时器，只要TCP连接一方收到对方的零窗口通知，就启动计时器。如果计时器超时，就会发送窗口探测报文。窗口探测的次数一般为3次，每次几十秒。如果3次之后还是0，**有的TCP会发送RST报文来中断连接**



![image-20210817205920198](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210817205920.png)











#### 4、拥塞控制

拥塞窗口cwnd是**发送方**维护的一个的状态变量，它会根据网络的拥塞程度动态变化的。没有拥塞，cwnd就增大，出现拥塞，cwnd就减少

发送窗口的值 = min(cwnd,rwnd)。 rwnd是接收窗口



在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时TCP就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大

就有了拥塞控制，控制的目的就是避免「发送方」的数据填满整个网络。



**拥塞控制主要是四个算法:**

- **慢启动** ： 每收到一个ack，cwnd就加1.所以每次都会翻倍增长(当它为2，就会收到两个ack，就变成4)
- **拥塞避免**：每收到一个ack，cwnd就增加1/cwmd。 所以每轮会增加1
- **拥塞发生**：当网络出现拥塞，也就是会发生数据包重传，重传机制主要有两种。
  - 超时重传：就使用拥塞发生算法：直接回到初始值重新开始慢启动 (慢启动太激进了，会造成网络卡顿)
  - 快速重传：使用快速恢复算法，
- **快速恢复**：让ssthresh变为拥塞发生时候的cwnd的1/2，然后起始位置就是ssthresh+3.再重新进入拥塞发生算法

**整个过程如下**：

   先慢启动，从1开始，每次翻倍增长，然后有一个慢启动门限ssthresh(一般来说ssthresh的大小是65535字节)，假设是8，当cwnd>=8 就使用拥塞避免算法，也就是每轮+1，一直拥塞发生，**假设在12**的时候发生拥塞，那么有两种情况。如果是使用超时重传算法，那么cwnd就变成1，然后重新慢启动，拥塞避免。 如果是快速重传，那么就使用快速恢复算法，ssthresh = cwnd/2 = 12/2 = 6.然后把cwnd设置为ssthrest+3 = 9.然后直接进行拥塞避免算法

![image-20210814111653162](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210814111653.png)

## 3、IP篇

#### IP协议相关技术

##### 1.DNS域名解析

- 根DNS服务器
- 顶级DNS服务器
- 权威DNS服务器

![image-20210807094908601](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210807094908.png)

- 1.先查看浏览器自身的DNS缓存有没有该URL，如果有直接访问，如果没有，就去系统dns缓存里面找，如果还是没有就去hosts文件里面找，如果里面有，就去访问这里面的地址
- 2.如果还没有找到，就去请求-本地域名服务器(区域服务器)-来解析这个域名。找到本地dns之后，也是先去查询一下自己的缓存。
- 3.本地域名找不到，就去问根域名服务器。
- 4.根发现是.com结尾的，就让本地DNS服务器 去问.com顶级域名服务器。
- 5.顶级域名服务器会返回负责.google.com权威域名服务的地址
- 6.本地dns就去找权威域名服务器，然后这个服务器就返回网址的ip
- 7.找到了，就把地址缓存到电脑上

所有网址真正的解析过程为: . -> .com -> google.com. -> www.google.com.

客户给本地dns进行查找是递归的操作，然后本地dns去找根、顶级、权威域名服务器都是迭代查找的





##### 2.ARP协议

传输一个IP数据报的时候，知道目的IP地址，会通过主机路由表确定这个数据包下一个跳的地方，但是网络层下一层是数据链路层，我们要知道下一跳的MAC地址才行。我们可以通过ARP协议获得Ip地址对应的MAC的地址

**ARP请求和ARP响应**

主机会通过广播发送ARP请求，这个包含了需要转化的IP地址。然后一个链路的所有设备收到之后，回去拆解请求包里面的内容。如果ARP里的地址和自己的是一样的，那么就把自己的MAC地址放进ARP响应包中返回给主机。操作系统也会把这个MAC地址缓存起来，不过缓存有期限的。



如果两个主机不是一个链路里的，即使知道主机B的MAC地址也不能直接通信，而是经过路由器转发到主机B的局域网，才能找到B。此时A的ARP缓存表中缓存的不是B的MAC地址，而是下一跳路由器的MAC地址。

> RARP协议

这个和ARP刚好相反，是将MAC地址求IP地址。比如打印机等设备接入网络。 

- 设备会发送我的MAC地址是XXX，请告诉我，我的IP地址应该是多少。
- RARP服务器接到这个消息后返回「MAC地址为XXXX的设备，IP地址为XXXX」的信息给这个设备。
- 最后，设备就根据从RARP服务器所收到的应答信息设置自己的IP地址。



##### 3.有IP地址为什么还需要MAC地址

IP地址相当于是地址，MAC地址相当于是收信的人。 只有IP地址只能知道你是在哪个大概的子网范围内(ip地址是可以改变的)，定位了MAC地址才能直接定位到你这个人。



##### 5、ICMP

ICMP，互联网控制协议报文

主要功能：

- 确认IP包是否成功送达目标地址
- 报告发送过程中IP包被丢弃的原因和改善网络
- 

##### 4、ping的过程

ping是ICMP(网络控制报文协议)中的一个应用，ICMP是网络层的协议，ping用来测试两个主机之间的连通性。

ping的工作过程

- 向目的主机发送多个ICMP回送请求报文
  - 构建IP数据包，组成如下
    - IP头(源地址，目标地址，协议：1(代表ICMP)) 
    -  ICMP回送请求报文
    - MAC头(目标MAC(**通过ARP获得**)，源MAC  )
- 根据目的主机返回的回送报文的时间和成功响应的次数，来估算数据包往返的时间和丢包率





# 操作系统





## 1.进程、线程

### 进程

#### 进程的控制结构

在操作系统中，是用**进程控制块**（*process control block，PCB*）数据结构来描述进程的。

PCB是**进程存在的唯一标识**。

PCB包括：

- 进程描述信息
  - 进程标识符：唯一的，类似唯一标识符（id）
  - 用户标识符：进程归属的用户，主要为了共享和保护
- 进程控制和管理信息：
  - 进程当前状态
  - 进程优先级
- 资源分配清单：虚拟地址空间的信息，比如打开的文件列表，使用的IO设备
- CPU相关信息：CPU各个寄存器的值，当进程切换时，这些数据保存在PCB中，之后进程可以接着执行

> PCB是如何组织的

PCB通过链表连接的。相同状态的PCB放在一个链表队列里。比如就绪队列，里面链接着就序状态的PCB

#### 进程的控制

- 创建进程： 一个进程可以创建另外一个进程，子进程能够使用父进程的拥有的资源
  - 申请一个空白的PCB，往里面添加一些控制和管理的信息，比如id
  - 为该进程分配运行需要的资源，比如内存
  - 将进程放入就绪队列
- 终止进程，有三种情况，正常结束、异常结束、外部干预（kill）。
  - 如果子进程被终止，那么子进程继承的父进程的资源会被收回。如果父进程被终止，子进程会变成孤儿进程，交给1号进程收养，由1号进程完成状态收集工作。
  - 先去查找要终止进程的PCB
  - 如果是执行状态，立刻中止执行，将CPU的资源分配给其他进程
  - 如果有子进程，那么将子进程交给1号进程管理
  - 将进程分配得到的资源返回给操作系统
  - 在队列中删除进程的PCB
- 阻塞进程：当进程需要等待某一事件，那么可以调用阻塞命令让自己阻塞等待。等待状态下，必须让另外一个进程唤醒
  - 找到要阻塞的进程标示号的PCB
  - 如果是运行状态，则保留现场，更改状态，停止运行
  - 把PCB放进阻塞队列
- 唤醒进程：（和阻塞反着来，更改状态为就绪状态，放进队列里，等待调度）



#### 进程的上下文切换

> CPU上下文切换

保留上一次执行的寄存器和程序计数器的内容，



> 进程的上下文切换

进程由内核管理的，所以切换发生在内核态，切换的资源包括：用户空间的资源（虚拟内存、栈、全局变量）+内核空间（内核堆栈，寄存器）。会把交换的消息放在PCB，从PCB中取出上下文。



发生上下文切换的场景：

- 进程时间片耗尽
- 进程需要的资源不足
- 进程自己调用sleep，让自己休眠
- 优先级更高的进程抢占资源
- 硬件中断



### 线程

多进程的这种方式，依然会存在问题：进程之间如何通信，共享数据？维护进程的系统开销较大

需要有一种新的实体，满足特性：1.实体之间可以并发运行 2.实体之间共享相同的地址空间。--- **线程**



同一个进程内多个线程之间可以共享代码段、数据段、打开的文件等资源，但每个线程各自**都有一套独立的寄存器和栈**，这样可以确保线程的控制流是相对独立的。

> 线程的优缺点

优点：

- 多个线程可以并发
- 多个线程共享地址空间和文件资源
- 一个进程有多个线程

缺点：一个线程崩溃，可能会引起进程的崩溃（c/c++） java不会，**因为在虚拟机内部定义了信号处理函数**



#### 线程与进程的比较

- 进程是资源分配的单位，线程是CPU调度的单位
- 进程拥有完整的资源平台，线程只独享比不可少的资源，比如栈，寄存器
- 线程同样具有就绪、阻塞、执行三种基本状态，同样具有状态之间的转换关系；
- 线程能减少并发执行的时间和空间开销
  - 线程的创建时间比进程快，进程在创建的过程中，还需要资源管理信息（内存管理，文件管理），线程创建的时候不需要，而是共享
  - 线程的终止时间比进程快，因为线程释放的资源相比进程少很多；
  - 同一个进程内的线程切换比进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同一个进程的线程都具有同一个页表，那么在切换的时候不需要切换页表。
  - 线程之间共享内存，线程之间数据传递的时候，就不需要经过内核



#### 线程上下文切换

对于线程和进程，我们可以这么理解：

- 当进程只有一个线程时，可以认为进程就等于线程；
- 当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源，这些资源在上下文切换时是不需要修改的；
- 线程也有自己的私有数据，比如栈和寄存器等，这些在**上下文切换时需要保存**

> 线程上下文切换的是什么？

这还得看线程是不是属于同一个进程：

- 当两个线程不是属于同一个进程，则切换的过程就跟进程上下文切换一样；
- **当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据**



#### 线程的实现

主要有三种线程的实现方式：

- **用户线程（\*User Thread\*）**：在用户空间实现的线程，不是由内核管理的线程，是由用户态的线程库来完成线程的管理；
- **内核线程（\*Kernel Thread\*）**：在内核中实现的线程，是由内核管理的线程；
- **轻量级进程（\*LightWeight Process\*）**：在内核中来支持用户线程；

> 用户线程

用户线程是基于用户态的线程管理库来实现的，那么**线程控制块（\*Thread Control Block, TCB\*）** 也是在库里面来实现的，操作系统看不到用户线程的TCB。**用户线程的整个线程管理和调度，操作系统是不直接参与的，而是由用户级线程库函数来完成线程的管理，包括线程的创建、终止、同步和调度等。**



#### 进程调度

> 调度算法

- 非抢占式调度算法：进程被选择执行之后，一直到线程阻塞或者执行完成，才会调用另外一个线程，不会有时钟中断
- 抢占式调度算法：选择后，只让其执行某段时间，之后会将其阻塞，从就绪队列中选择另一个线程执行。这种会在时间间隔的末端发生时钟中断，也就是说的时间片机制

##### 调度算法

> 先来先服务（First Come First Serve, FCFS）算法

非抢占式的，FCFS 对长作业有利，适用于 CPU 繁忙型作业的系统，而不适用于 I/O 繁忙型作业的系统。

> 最短作业优先

它会**优先选择运行时间最短的进程来运行**，这有助于提高系统的吞吐量。对长作业不友好，如果短作业过多，会导致长作业一直无法执行

>高响应比优先调度算法

**先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行**，响应比：（等待时间+服务时间）/服务时间

因为服务时间不可预知，所以这是理想中的算法，无法实现

> 时间片轮转调度算法 

每个进程分配一个时间片，可以执行这么长时间，如果时间超时或者时间未到就执行完成，就会切换。

> 最高优先级调度算法

调度程序能**从就绪队列中选择最高优先级的进程进行运行**

进程的优先级可以分为，静态优先级和动态优先级：

- 静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化；
- 动态优先级：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是**随着时间的推移增加等待进程的优先级**。

该算法也有两种处理优先级高的方法，非抢占式和抢占式：

- 非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程。
- 抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行。

但是依然有缺点，可能会导致低优先级的进程永远不会运行

>多级反馈队列调度算法

多个队列，优先级由大到小，时间片长度由小到大。 第一个队列就1分钟，优先级最高，新任务进来先放进第一个队列，如果执行时间结束，就中断放入第二个队列排队执行。（这里每个队列都是遵循FCFS的，如果有新的进来，那么其他队列都先暂停，先吧优先级最大的执行一下）

![image-20221016150923173](/Users/xuying/Library/Application Support/typora-user-images/image-20221016150923173.png)

### 进程通信

进程通信指的是进程之间的信息交换。进程是分配资源的单位，因此各进程拥有的内存地址空间相互独立

![image-20210723154656085](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210723154656.png)

#### 进程通信的方式

##### 1.共享存储

![image-20210723154743579](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210723154743.png)

两个进程对共享空间的访问必须是互斥的。通过PV操作实现。

> 基于数据结构的共享

比如共享空间里面只能放一个长度为10的数组。这种方式速度慢，限制读。是一种**低级通信方式**

> 基于存储区的共享

在内存中画出一块共享存储区，数据的形式和位置都由进程控制。这种方式速度快，是一种高级通信方式

**效率高**，因为进程可以直接读写内存，而不需要任何数据的拷贝，

##### 2.消息传递

进程间的数据交换以格式化的消息为单位。通过操作系统提供的"发送、接受消息"两个原语进行数据交换

消息：  消息头和消息体组成。  消息头包括发送进程ID、接受进程的ID，。。。  跟报文一样

> 直接通信方式

就是进程1直接把消息放到进程2的消息缓冲队列上

> 间接通信方式

进程1发送消息到一个中间实体(信箱)，进程2从信箱中接收

##### 3.管道通信

管道存的是文件

想要全双工，就建立两个管道

> 无名管道(匿名) pipe

它是**半双工**的（即数据只能在一个方向上流动），具有固定的读端和写端。

它只**能用于具有亲缘关系的进程**之间的通信（也是父子进程或者兄弟进程之间）。

> 命名管道 fifo

半双工

在磁盘上有对应的节点，但没有数据块——换言之，只是拥有一个名字和相应的访问权限 ，任何进程都可以通过文件名将其打开和进行读写

##### 消息队列

消息队列，就是一个消息的链表，是一系列保存在内核中消息的列表。

用户进程可以向消息队列添加消息，也可以向消息队列读取消息。

消息队列与管道通信相比，其优势是对每个消息指定特定的消息类型，接收的时候不需要按照队列次序，而是**可以根据自定义条件接收特定类型的消息。**

#### 线程间同步

线程同步是两个或多个共享关键资源的线程的并发执行。

- **互斥量**：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如 Java 中的 synchronized 关键词和各种 Lock 都是这种机制。
- **信号量**：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量
- **事件**：wait\notify。通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操





### 协程

是一种基于线程之上，但又比线程更加轻量级的存在，这种由程序员自己写程序来管理的轻量级线程叫做『用户空间线程』，具有对内核来说不可见的特性。一个线程也可以拥有多个协程。

1. 线程的切换由操作系统负责调度，协程由用户自己进行调度，因此减少了上下文切换，提高了效率。
2. 线程的默认Stack大小是1M，而协程更轻量，接近1K。因此可以在相同的内存中开启更多的协程。
3. 由于在同一个线程上，因此可以避免竞争关系而使用锁。
4. 适用于被阻塞的，且需要大量并发的场景。但不适用于大量计算的多线程，遇到此种情况，更好实用线程去解决。

# linux



#### 1.du和ds的区别

du,disk usage 通过搜索文件计算每个文件的大小，然后累加。du能看到的文件只是当前存在的，没有被删除的

df，disk free 通过文件系统快速获取空间大小的信息。我们删除一个文件的时候，这个文件不是马上就在文件系统当中消失了，而是暂时消失了，当所有程序都不用时，才会根据OS的规则释放掉已经删除的文件。df可以**看到已经删除的文件**，计算也加上了，所以更加准群

#### 2.如何查看端口占用

```bash
netstat -ap | grep 8080

#
ps -ef|grep xxx(进程名

kill -9  进程PID
```

#### 3.linux各种进程

> 僵尸进程

1.linux中，任何一个子进程在调用结束运行后，**内核会释放该进程的所有资源**。同时会留下一个僵尸进程(Zombie)的数据结构。Zombie中储存了该进程的进程号、**退出状态**等信息。**即僵尸进程是死亡的子进程**，但是在进程表中占了一个位置。

2.如果父进程**在没有释放掉僵尸进程就**提前结束**，僵尸进程则会**由init进程接管。**init进程就为僵尸进程收尸**

3.**但是如果父进程是一个循环，不会结束，并且没有调用`wait()/waitpid()`函数为僵尸进程收尸，则该僵尸进程会一直在系统中存在。**

- **僵尸进程的危害：**如果系统中存在很多僵尸进程，进程号会被它们一直占用。这时，有限的进程号将会耗尽，使得**系统无法创建新的进程**。
- **如何杀死僵尸进程**：
  - 查看系统中是否存在僵尸进程
    - top命令监控进程占用情况，zombie前面是僵尸进程的数量。进程状态为z，后面有defunct标记的就是僵尸进程
    - 然后使用ps -ef | grep defunct 查看僵尸进程。杀死僵尸进程的父进程(PPID) ，可以让僵尸进程给init进程管理，就会被释放



> 孤儿进程（orphan）

1. 父进程退出，而它的一个或多个子进程还在运行，这些子进程将成为孤儿进程（`orphan process`）。
2. 孤儿进程将会被`init`进程收养，并由`init`进程完成对它们的**状态收集工作**。
3. 由于孤儿进程会被`init`进程收养，因此孤儿进程调用`exit()`结束运行时，也会由`init`进程完成回收工作，而**不会对系统造成危害**。（这是和僵尸进程的一个区别，僵尸进程如果没有被父进程回收，就会占用系统中有限的进程号，会对系统有危害）。

> 守护进程（Daemon）

- 守护进程是**运行在后台**的一种特殊进程，**独立于控制终端**，**并且周期性的执行某种任务**或者**等待处理某些发生的事件**。(可以看成是一个定时任务，一直存在的任务)

- 守护进程**一般在系统启动时就开启了**，除非强制终止，否则直到系统关机都保持运行。
- **守护进程的父进程是init进程：** 创建守护进程时，父进程在fork出子进程后就提前结束运行了。守护进程将会变成孤儿进程，由`init`进程收养。(守护进程的老爸一生下它就走了，所以交给init托管了)



#### java的守护线程

专门用于服务其他的线程，如果其他的线程都执行完毕了，包括main线程。(进程里面只有守护线程了)，守护线程才会停止执行。