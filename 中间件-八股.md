# Mysql

## 1.简单的八股

#### 1.索引

##### 1.索引的优缺点



**优点**：

- 大大加快数据查询的检索速度
- 创建唯一性索引，可以保证数据的唯一性

**缺点**：

- 创建和维护索引会消耗时间
- 索引会耗费一定的空间
- 对表中的数据进行修改时，如果数据有索引，那么索引也要修改，会降低sql的执行效率
- 如果建立聚簇索引，需要的空间更大。如果非聚簇索引很多，一旦聚簇索引改变，所有的非聚簇索引都会跟着改变



##### 2.索引的数据结构

>**1.hash**

hash查询特别快。Mysql为什么不用hash做索引的数据结构？

原因：hash索引不支持顺序和范围查询。 即不能对表中的数据进行排序或者进行范围查询

> **2.B树**

B 树也称 B-树,全称为 **多路平衡查找树** ，B+ 树是 B 树的一种变体。B 树和 B+树中的 B 是 `Balanced` （平衡）的意思。

**B 树& B+树两者有何异同呢？**

- B 树的所有节点既存放键(key) 也存放 数据(data)，而 B+树只有叶子节点存放 key 和 data，其他内节点只存放 key。
- B 树的叶子节点都是独立的;B+树的叶子节点有一条引用链指向与它相邻的叶子节点。
- B 树的检索的过程相当于对范围内的每个节点的关键字做二分查找，可能还没有到达叶子节点，检索就结束了。而 B+树的检索效率就很稳定了，任何查找都是从根节点到叶子节点的过程，叶子节点的顺序检索很明显。

##### 3.索引类型 和对数据库性能的影响

> 主键索引

一张数据表有只能有一个主键，并且主键不能为 null，不能重复。

特殊的唯一索引。一张表中只能定义一个主键索引，用于标识一条记录





> 二级索引(辅助索引)

二级索引又称为辅助索引，是因为二级索引的**叶子节点存储的数据是主键**。也就是说，通过二级索引，可以定位主键的位置。

- 普通索引
- 唯一索引：数据记录的唯一性
- 联合索引：索引可以覆盖多个数据列，
- 全文索引：倒排索引。可以提升检索效率， like的时候用这个
- 前缀索引(Prefix) ：前缀索引只适用于字符串类型的数据。前缀索引是对文本的前几个字符创建索引，相比普通索引建立的数据更小， 因为只取前几个字符。



> 聚簇索引和非聚簇索引

聚集索引：

- 优点：查询速度很快
- 缺点：
  - 依赖有序的数据。如果数据是字符串或者UUID这种，插入或者查找速度就比较慢
  - 更新代价要大一些

非聚簇索引：就是二级索引。叶子节点存放的可能是数据的指针也可能是主键

- 优点：更新代价小，因为叶子节点不存放数据
- 缺点：
  - 也依赖有序的数据
  - 可能会二次查询(回表)，就是用**指针的地址**再找一下

> 覆盖索引

**覆盖索引即需要查询的字段正好是索引的字段，那么直接根据该索引，就可以查到数据了， 而无需回表查询。**



##### 4、创建索引的注意事项

- 选择合适的字段创建索引
  - 不为null的字段。为null的数据库不好优化
  - 被频繁查询的字段
  - 作为条件的字段
  - 频繁需要排序的字段
- 被频繁更新的字段要慎重建立索引。 一个字段经常被修改，维护成本就很大
- 尽可能的考虑建立联合索引而不是单列索引  。 
  - 因为建立联合索引，多个字段在一个索引上，那么将会节约很大磁盘空间，且修改数据的操作效率也会提升。
- 注意避免冗余索引



![image-20210716191739176](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210716191739.png)

```sql
#1.添加 PRIMARY KEY（主键索引）
ALTER TABLE `table_name` ADD PRIMARY KEY ( `column` )

#2.添加 UNIQUE(唯一索引)
ALTER TABLE `table_name` ADD UNIQUE ( `column` )

#3.添加 INDEX(普通索引)
ALTER TABLE `table_name` ADD INDEX index_name ( `column` )

#4.添加 FULLTEXT(全文索引)
ALTER TABLE `table_name` ADD FULLTEXT ( `column`)

#5.添加多列索引
ALTER TABLE `table_name` ADD INDEX index_name ( `column1`, `column2`, `column3` )
```



#### 2.MyISAM 和InnoDB的区别

- 行级锁
  - MyISAM只有表级锁，InnoDB既支持**表级锁**又支持**行级锁**
- 事务
  - MyISAM不支持事务，InnoDb支持事务
- 故障恢复
  - MyISAM不支持数据库异常之后的恢复，InnoDB支持恢复，主要依赖redo log
  - InnoDB使用 **undo log(回滚日志)** 来保证事务的**原子性**。
- 是否支持外键
  - MyISAM不支持外键。InnoDB支持外键
  - 不过我们不建议在数据库层面设置外键，可以在应用层解决（会有数据一致性的问题）。
- 是否支持MVCC
  - MyISAM不支持，InnoDB支持
  - MVCC相当于行级锁的升级，可以减少加锁操作，提高性能

#### 3、锁机制和InnoDB锁算法

表级锁：粒度最大的锁，对当前整个表加锁，实现简单，加锁快，资源消耗少，**触发锁冲突概率最高**，并发度低。

行级锁：粒度最小的锁，对当前操作的行加锁。能大大减少数据库操作的冲突，并发度高，加锁开销大，资源消耗多，会出现死锁。

InnoDB锁算法有：

- Record lock：记录锁，单个行记录上的锁
- Gap lock：间隙锁，锁定一个范围，不包括记录本身
- next-key lock： record + gap。锁定一个范围+记录本身

#### 4、事务

##### 1.什么是事务

数据库事务可以保证，多个对数据库的操作构成一个整体，这些操作要么全部执行，要么都不执行。

##### 2.ACID特性

atomicity**原子性**：事务是最小的执行单位。 要么全部完成，要不不起作用

consistency**一致性**：事务操作前后，数据保持一致。A给B转账50，那么A-50，B就要+50

Insolation**隔离性**：并发执行事务，一个用户的事务不会被其他事务干扰。

durablilty**持久性**：事务提交后，对数据库的改变是持久的。

##### 3.数据事务的实现原理

mysql数据库，使用undo log(回滚)来保证**原子性**，使用redo log(恢复机制)实现持久性，

使用锁来保证隔离性。以上全部满足，就可以保证一致性

#### 4、并发事务带来的问题

1.**脏读**：事务1对数据A进行修改，但是没有提交。此时事务2读取数据A。

​	例子：A=50，事务1修改A = 20，未提交，事务2读取A得到A=20，事务1有问题，回滚事务。那么刚刚事务2读的就是脏数据

2.**丢失修改**：事务1读取到了A=20，事务2读取到了A=20，事务1修改A = A-1，事务2修改A = A-1。最后A的结果是19.事务1的操作丢失

3.**不可重复读**：顾名思义，就是事务1多次读取**同一个数据**，事务2在这个过程中对这个数据进行修改。造成前后数据不一样的情况

4.**幻读**：和不可重复读很像，**区别在于幻读是一次读取多行数据**，事务1先读取多行数据，然后事务2之后插入或者删除了一些数据，这时候事务1又读了多行数据，发现这些数据怎么这么奇怪（多了几行，或者少了几行），发生幻觉了。

#### 5、事务的隔离级别

读取未提交：最低的隔离级别，允许读取尚未提交的数据变更，可能会**脏读**及以上

读取已提交：允许读取并发事务已经提交的数据，只能**防止脏读**

可重复读： 对**同一字段**的多次读取结果是一致的，除非数据是被本身事务修改，可以阻止**脏读和不可重复读**。仍可能会幻读

​		- 就是外面修改了，不会对这个事务里读到的数据有影响，里面一直是5000，外面改成4000提交了，这个事务还是5000

可串行化：最高的隔离级别，完全服从ACID的隔离级别。 所有事务依次执行，事务之间完全不会产生干扰。可以防止上面所有的问题



> 扩展

MySQL INNODB的默认隔离级别是**可重读**，但是mysql可以使用加锁读来避免幻读的产生。这个锁机制就是Next-key Locks

隔离级别越低，事务请求的锁就越少，所以大部分的数据库隔离级别都是**读取已提交**。而INNODB使用**可重读**的性能不会有损失。

InnoDB在分布式事务的情况下会用到**串行化**的隔离级别

#### 6、MVCC

MVCC，全称Multi-Version Concurrency Control，即多版本并发控制

- 当前读：加锁的读
- 快照读：不加锁的select操作就是快照读

MVCC就是为了实现**读-写冲突不加锁**，MVCC多版本并发控制指的是 “维持一个数据的多个版本，使得读写操作没有冲突” 这么一个概念。

##### 数据库并发场景有三种，分别为：

- 读-读：不存在任何问题，也不需要并发控制
- 读-写：有线程安全问题，可能会造成事务隔离性问题，可能遇到脏读，幻读，不可重复读
- 写-写：有线程安全问题，可能会存在更新丢失问题，比如第一类更新丢失，第二类更新丢失

MVCC可以为数据库解决以下问题：

- 在并发读写数据库时，可以做到在读操作时不用阻塞写操作，写操作也不用阻塞读操作，提高了数据库并发读写的性能
- 同时还可以解决脏读，幻读，不可重复读等事务隔离问题，但不能解决更新丢失问题





MVCC + 悲观锁
MVCC解决读写冲突，悲观锁解决写写冲突

MVCC + 乐观锁
MVCC解决读写冲突，乐观锁解决写写冲突
 这种组合的方式就可以最大程度的提高数据库并发性能，并解决读写冲突，和写写冲突导致的问题

##### 实现原理

里面有三个隐式字段。隐式主键，事务ID，每做一次操作就+1，回滚指针，指向undo log，undo log里面会记录修改的内容。后面没看懂

![image-20210721162528325](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210721162528325.png)





## Mysql45讲

### Mysql基础篇

![image-20210805110050300](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210805110050.png)

#### 1.基础架构

##### 1.连接器

连接器负责跟客户端建立连接、获取权限、维持和管理连接。连接命令中的 mysql 是客户端工具，用来跟服务端建立连接。在完成经典的 TCP 握手后，连接器就要开始认证你的身份，这个时候用的就是你输入的用户名和密码。

一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限(这次连接不会生效，下次连接才会生效)

客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数 wait_timeout 控制的，默认值是 8 小时。



数据库里面，**长连接**是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。(连接的建立比较复杂，推荐使用长连接。就是连接之后不要断开。**比如jdbc操作的话，我们使用完之后会有一个close()的方法，这就是短连接。如果我们使用数据库连接池，就是长链接**)





MySQL 在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。长连接累积下来，可能导致内存占用太大，被系统强行杀掉，也即mysql异常重启

> 怎么解决

- 定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。
- 可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。



##### 2.查询缓存

MySQL 拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。**但是大多数情况下我会建议你不要使用查询缓存，为什么呢？因为查询缓存往往弊大于利**。查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。

**MySQL 8.0 版本直接将查询缓存的整块功能删掉了**

##### 3.分析器

- 词法分析：**先确定里面的字符串的意义**，代表什么。select 是查询，表名是T。。等等
- 语法分析：会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。单词错误会报错，一般语法错误会提示第一个出现错误的位置

分析阶段判断语句是否正确，表是否存在，列是否存在等。

##### 4.优化器

经过了分析器，MySQL 就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。

**优化器是在表里面有多个索引的时候，决定使用哪个索引或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。**

优化器阶段完成后，这个语句的执行方案就确定下来了，然后进入执行器阶段

##### 5.执行器

开始执行的时候，要**先判断**一下你对这个表 T **有没有执行查询的权限**，如果没有，就会返回没有权限的错误。(分析器之后也会做权限认证，precheck)

如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。



#### 2.日志系统

更新流程会涉及到日志模块。redo log（重做日志）和 binlog（归档日志）。

##### redo log  

------------------------**保证事务的持久性**------------------------

**如果每次修改直接对mysql进行，那么就很慢**。因为要去磁盘进行查找，然后IO更新。于是就先写在log上，然后根据log的记录之后进行修改(其实就是 MySQL 里经常说到的 WAL 技术，**WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘**)

InnoDB 引擎就会先把记录写到 redo log里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。





> redo log 大小

可以配置为一组 4 个文件，每个文件的大小是 1GB，那么这块“粉板”总共就可以记录 4GB 的操作

redo log满了之后又有记录进来，就需要删除之前的记录，也就是擦除

从头开始写，写到末尾就又回到开头循环写

![image-20210805112739101](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210805112739.png)

write pos，当前记录的位置，写完往后移。checkpoint是已经擦除的位置，也是往后移，可以理解成是一个环形栈空间。**write pos 和 checkpoint 之间的**是“粉板”上还空着的部分，可以用来记录新的操作。

可以看成上面的绿色的是空闲的空间。黄色的是已经写了的记录的空间。

如果 write pos 追上 checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得**停下来先擦掉一些记录**，把 checkpoint 推进一下。

> crash-safe

有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为 crash-safe。就是出现问题，我们可以去redo log上找存放的记录，进行一个恢复操作

##### binlog

redo log 是 InnoDB 引擎特有的日志，而 **Server 层也有自己的日志，称为 binlog（归档日志）。**

binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。

binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。

![image-20210805121603577](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210805121603.png)



> 怎样让数据库恢复到半个月内任意一秒的状态？

binlog 会记录所有的逻辑操作，并且是采用“追加写”的形式。如果你的 DBA 承诺说半个月内可以恢复，那么备份系统中一定会**保存最近半个月的所有 binlog**，同时**系统会定期做整库备份**。这里的“定期”取决于系统的重要性，可以是一天一备，也可以是一周一备。



==一次误删操作的恢复==

如果我要恢复的话，首先是找到与指定时间最近一次的全量备份(整库备份)，将这个备份恢复到临时库，然后找到备份的时间点，从这个时间点开始，执行bin log里的操作，一直到误删表之前的那个时刻。

这样临时库就是跟误删之前的线上库一样了。



##### redo log 和 bin log 的理解

- redo log
  - 记录的是磁盘上数据的物理变化（记录这个页 “做了什么改动”）。
  - redo log是物理日志，物理日志与存储引擎相关
- binlog
  - 记录的是当时所执行的高级编程语言
  - bin log是逻辑日志，逻辑日志可以跨存储引擎。
  - Binlog有两种模式，statement 格式的话是记sql语句， row格式会记录行的内容，记两条，更新前和更新后都有。

#### 3.事务隔离

##### 1.隔离性和隔离级别

隔离性：

- 当数据库上有多个事务同时执行的时候，就可能出现**脏读**（dirty read）、**不可重复读**（non-repeatable read）、**幻读（**phantom read）的问题

隔离级别：

- 读未提交（read uncommitted)：一个事务还没提交时，它做的变更就能被别的事务看到
- 读提交（read committed）：一个事务提交之后，它做的变更才会被其他事务看到。
- 可重复读（repeatable read）：一个事务执行过程中看到的数据，总是跟这个事务在**启动时**看到的数据是一致的。
- 串行化（serializable ）：读取前锁定所有要读读取的数据，当前事务提交前其他事务不允许修改

> 分析

![image-20210806142440115](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210806142440.png)

不同隔离级别下得到的值：

- RU。V1 = 2. V2 =V3 =2 。B没有提交，但是结果还是被A看到了
- RC。V1 = 1，V2 =2.V3 = 2。 因为B没提交，所以V1的值还是之前看到的那个。提交之后，这个值才能被A看到
- RR。V1 = 1，V2 = 1，V3 = 2。事务在执行期间看到的数据前后必须是一致的。
- 串行化。V1 = V2 =1 。V3 =2 。但是事务B执行“将 1 改成 2”的时候，**会被锁住**。必须事务A提交之后才能继续执行

实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。**在“可重复读”隔离级别下，这个视图是在事务启动时创建的**，整个事务存在期间都用这个视图。**在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的**。

**注意**：读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；而“串行化”隔离级别下直接用加锁的方式来避免并行访问。

总结来说，存在即合理，每种隔离级别都有自己的使用场景，你要根据自己的业务情况来定。





##### 事务隔离的实现

> 可重复读

在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。

假设一个值从 1 被按顺序改成了 2、3、4，在回滚日志（undo log）里面就会有类似下面的记录。

![image-20210806143353025](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210806143353.png)

当前值是 4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的 read-view。

同一条记录在系统中可以存在多个版本，就是**数据库的多版本并发控制（MVCC）**。对于 read-view A，要得到 1，就必须将当前值依次执行图中所有的回滚操作得到。



同时你会发现，即使现在有另外一个事务正在将 4 改成 5，这个事务跟 read-view A、B、C 对应的事务是不会冲突的。

回滚日志总不能一直保留吧，什么时候删除呢？答案是，在不需要的时候才删除。也就是说，系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。

什么时候才不需要了呢？就是当系统里没有比这个回滚日志更早的 read-view 的时候。

**最好不用长事务**：

- 长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。

##### 事务的启动方式

- 显示启动事务，begin 或 start transaction。配套的提交语句是 commit，回滚语句是 rollback。
- set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接
- 

#### 4.索引

##### 常见的索引类型

- 哈希表 （key-value）：把值放在数组里，用一个哈希函数把 key 换算成一个确定的位置，然后把 value 放在数组的这个位置。多个key经过hash 的值可能相同，使用拉链法处理。
  - 哈希表这种结构适用于只有**等值查询**的场景
- 有序数组：而有序数组在**等值查询和范围查询场景**中的性能就都非常优秀。
  - 有序数组索引只适用于**静态存储引擎**：（更新数据需要挪动很多数据，开销大）。比如你要保存的是 2017 年某个城市的所有人口信息，这类不会再修改的数据。
- 二叉树是搜索效率最高的，但是实际上大多数的数据库存储却并不使用二叉树。其原因是，索引不止存在内存中，还要写到磁盘上。**使用多叉树**。“N 叉”树中的**“N”取决于数据块的大小。**
  - 以 InnoDB 的一个整数字段索引为例，这个 N 差不多是 1200。这棵树高是 4 的时候，就可以存 1200 的 3 次方个值，这已经 17 亿了。考虑到树根的数据块总是在内存中的，一个 10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。
- 跳表、LSM 树等数据结构也被用于引擎设计

##### InnoDB的索引模型

InnoDB 使用了 B+ 树索引模型，所以数据都是存储在 B+ 树中的。**每一个索引在 InnoDB 里面对应一棵 B+ 树。**

![image-20210806144636639](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210806144636.png)

主键索引的叶子节点存的是整行数据。主键索引也被称为聚簇索引（clustered index）。

非主键索引的叶子节点内容是主键的值，非主键索引也被称为二级索引（secondary index）。

基于**非主键索引的查询需要多扫描一棵索引树**。如果我们要查的值是主键，就可以不用回表重新扫描，这就是**索引覆盖**。因此，我们在应用中应该尽量使用主键查询。



> 索引维护

B+ 树为了维护索引有序性，在插入新值的时候需要做必要的维护。根据上图的，如果插入700，只需要在R5的后面插入一个新的值，如果插入的是400就需要逻辑上挪动后面的数据。还可能R5的数据页慢了，B+就需要申请一个新的数据页，然后挪动部分数据过去，这就是**页分裂**。

页分裂：

- 性能会有影响
- 空间利用率降低，原来一个页的数据，现在要放到两个页

有分裂就有合并，如果删除数据之后，利用率比较低，会将数据页做一个合并。



> **自增主键**：

插入新纪录可以不指定ID的值，获取当前最大的ID的值+1.就跟上面直接插入700的例子一样，使用自增主键的话，后面添加新的记录，只需要在最后一个数据页里面**追加**，不需要挪动其他数据。如果这个数据页慢了，就直接申请新的页，将后面的值添加到新的数据页里面，然后更新上面的索引页。**如果申请的数据页比较多，那么索引页还是会进行一个分裂的操作。**

显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。所以，从性能和存储空间方面考量，**自增主键往往是更合理的选择**。因为业务逻辑的字段**不容易保证有序的插入**。而且如果是字符串类型的，一般需要用20个字节。整形数据做主键只需要4个字节，或者长整型的8个字节。就可以一个页放更多的数据了。

有没有什么场景适合用业务字段直接做主键的呢？还是有的。比如，有些业务的场景需求是这样的：

- 只有一个索引
- 该索引必须是唯一索引。



##### 最左前缀匹配

**联合索引**：

![image-20210806151823599](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210806151823.png)

这是一个name和age的联合索引，顺序是按照name来排列的。然后当name相同，才是按照age进行一个排序。



如果你要查的是所有名字第一个字是“张”的人，你的 SQL 语句的条件是"where name like ‘张 %’"。这时，你也能够用上这个索引，查找到第一个符合条件的记录是 ID3，然后向后遍历，直到不满足条件为止。

**只要满足最左前缀，就可以利用索引来加速检索**。最左前缀可以是联合索引的最左 N 个字段

>在建立联合索引的时候，如何安排索引内的字段顺序。

所以当已经有了 (a,b) 这个联合索引后，**一般就不需要单独在 a 上建立索引了**。

第一原则是，**如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的**。

##### 索引下推

**这里建立了name和age的联合索引**

select * from tuser where name like '张%' and age=10 and ismale=1;

你已经知道了前缀索引规则，所以这个语句在搜索索引树的时候，只能用 “张”，找到第一个满足条件的记录 ID3。

MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。

 **其实就是索引空间里面存放着有name和age，然后查找name之后，直接用age的值进行比较，然后不满足的，就不回表比对**

![image-20210806152626965](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210806152627.png)







#### 5.各种锁

**DML**：数据库管理语言，如select、update这些

**DDL**：数据库定义语言，这个是对表的操作，比如给表加字段的命令

##### 全局锁

全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的语句会被阻塞(DML、DDL)。

全局锁的典型使用场景是，做**全库逻辑备份**。在备份过程中整个库完全处于只读状态。这是比较危险的：

- 如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆；
- 如果你在从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致主从延迟。



> 我们可以不用加锁，也能实现的备份

在可重复读隔离级别下开启一个事务。能够拿到一致性视图

官方自带的逻辑备份工具是 mysqldump。当 mysqldump 使用参数–single-transaction 的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的。

但是有的数据库引擎不支持事务，或者这个隔离级别。所以需要使用FTWRL。



##### 表锁

MySQL 里面表级别的锁有两种：一种是**表锁**，一种是**元数据锁（meta data lock，MDL)**。

表锁的语法是 lock tables … read/write。与 FTWRL 类似，可以用 unlock tables 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。

举个例子, 如果在某个线程 A 中执行 lock tables t1 read, t2 write; 这个语句，则其他线程写 t1、读写 t2 的语句都会被阻塞。同时，线程 A 在执行 unlock tables 之前，也只能执行读 t1、读写 t2 的操作。连写 t1 都不允许，自然也不能访问其他表。

表锁是最常用的处理并发的方式。而对于 InnoDB 这种支持行锁的引擎，一般不使用 lock tables 命令来控制并发，毕竟锁住整个表的影响面还是太大。



**另一类表级的锁是 MDL（metadata lock)**

当对一个表做增删改查操作的时候(DML语句)，加 MDL 读锁；当要对**表做结构变更**操作的时候(DDL语句)，加 **MDL 写锁**。

- 读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。
- 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。



![image-20210818183031032](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210818183031.png)

我们可以看到 session A 先启动，这时候会对表 t 加一个 MDL 读锁。由于 session B 需要的也是 MDL 读锁，因此可以正常执行。之后 session C 会被 blocked，是因为 session A 的 MDL 读锁还没有释放，而 session C 需要 MDL 写锁，因此只能被阻塞。之后所有要在表 t 上新申请 MDL 读锁的请求**也会被 session C 阻塞**。就都被锁住，等于这个表现在完全不可读写了。

==为什么C锁住了，后面的读锁也都锁住==是因为申请MDL锁的时候，会形成一个队列，队列中**写锁的获取的优先级高于读锁**。于是写锁如果等待了，后面的读锁就抢不过写锁，也会阻塞住。

> ==实际操作中，必须把D提交了，C才能继续执行，怎么会出现插队的情况？？？== 

是因为mysql的online ddl机制，DDL(更改表结构的语句)，ddl执行的时候，如果锁住表就会严重影响性能，不锁表，又不好解决DML语句的影响，于是有了上面这个机制。 这个会让DDL有个锁降级的过程，如下：

- 事务拿到MDL写锁
- 降级成MDL读锁
- 申请一块空间，开始改变表结构，填数据(做DDL操作)
- 升级为MDL写锁，然后把上述表替换之前的表
- 释放MDL写锁

可以知道，在锁降级之后，事务D就会拿到MDL的读锁，因此，我们升级回MDL写锁，就会被阻塞住。

> 如何安全的给小表加字段

![image-20210818184217134](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210818184217.png)



##### 行锁

MySQL 的行锁是在引擎层由各个引擎自己实现的。不是所有的引擎都支持行锁，MyISAM 引擎就不支持行锁，意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。



在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时(commit)才释放。这个就是**两阶段锁协议**。



知道了这个设定，对我们使用事务有什么帮助呢？那就是，如果你的事务中需要锁多个行**，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。**



有一个业务的操作：

- 1 从顾客 A 账户余额中扣除电影票价；
- 2 给影院 B 的账户余额增加这张电影票价；
- 3 记录一条交易日志。

这时候另一个事务是，顾客C要在影院B买票，那么就和语句2产生锁冲突了，所以我们要把语句2放在最后处理，也就是事务语句位置为3,1,2.

> 死锁和死锁检查

![](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210818211253.png)

上面会出现死锁的情况，出现死锁有两种解决办法：

- 直接进入等待，一直到超时，超时时间可以通过参数 innodb_lock_wait_timeout 来设置。
- 发起死锁检查。发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。

在 InnoDB 中，innodb_lock_wait_timeout 的默认值是 50s，意味着当出现死锁以后，第一个被锁住的线程要过 50s 才会超时退出，然后其他线程才有可能继续执行。对于在线服务来说，这个等待时间往往是无法接受的。又不可能直接把这个时间设置太小，比如 1s。这样的话如果不是死锁，而是简单的锁等待呢？所以，超时时间设置太短的话，会出现很多误伤。

**一般都采用第二种方式**：

加入这样一个过程，每个事务被锁的时候，都要查看它依赖的线程有没有被别人锁住，然后判断是否出现死锁。如果是所有事务都更行同一行(热点数据),那么每个新来的线程都会被堵住，然后判断是不是自己导致死锁，假设有1000个并发的，就是1000*1000 = 100w的检测量级。这并没有发送死锁，但是会消耗大量的CPU资源。



>怎么解决由这种热点行更新导致的性能问题呢？

1.如果确定业务一定不会出现死锁，可以关闭死锁检测。业务设计的时候一般不会把死锁当做一个严重错误，毕竟**出现死锁了，就回滚**，然后通过业务重试一般就没问题了，这是**业务无损的**。而**关掉死锁检测**意味着可能会**出现大量的超时**，这是**业务有损的**。

2.控制并发度。并发控制要做在数据库服务端。如果你有中间件，可以考虑在中间件实现。**对于相同行的更新，在进入引擎之前排队。**



### 12.Mysql实践篇

# Redis

### 常用数据结构和应用场景

#### String

##### 1.基本介绍

String 是最基本的 key-value 结构，value 是具体的值，value其实不仅是字符串， 也可以是数字（整数或浮点数），value 最多可以容纳的数据长度是 `512M`。

SDS（简单动态字符串）：

- **SDS 不仅可以保存文本数据，还可以保存二进制数据**。
  -  SDS使用len属性来判断字符串是否结束
  -  SDS 的所有 API 都会以处理二进制的方式来处理 SDS 存放在 `buf[]` 数组里的数据。
- **SDS 获取字符串长度的时间复杂度是 O(1)**
- **Redis 的 SDS API 是安全的，拼接字符串不会造成缓冲区溢出**。
  - 因为 SDS 在拼接字符串之前会检查 SDS 空间是否满足要求，如果空间不够会自动扩容，所以不会导致缓冲区溢出的问题。



##### 2.场景

- 缓存对象
- 计数：计算访问次数、点赞、转发、库存数量等等。
- Setnx 实现分布式锁
  - 参考文章：http://kaito-kidd.com/2021/06/08/is-redis-distributed-lock-really-safe/ 后面还有些深入的暂时没看
  - Setnx+过期时间（以前还需要考虑原子性，现在redis自己放进一个命令去了），问题：**客户1加锁成功，锁住了，执行时间超时，此时客户2进来加锁成功，客户1执行完毕，会删除客户2的锁**
  - 为了解决上面的问题，控制过期时间（网络复杂，这块并不能完成解决）。设置value唯一标识，比如uuid，在解锁的时候比较一下，看看是不是自己的锁。（get(key)==value ,del key）。设计到原子性的问题，可以把命令封装到lua脚本中执行
  - 控制过期时间，冗余过期时间--**加锁时，先设置一个过期时间，然后我们开启一个「守护线程」，定时去检测这个锁的失效时间，如果锁快要过期了，操作共享资源还未完成，那么就自动对锁进行「续期」，重新设置过期时间。** -- **Redisson**的做法
  - 通常使用Redis会做集群（主从切换的话，分布式锁就有问题）。Redlock提出来解决-- 
- 共享session的信息



#### LIST

##### 1.基本介绍

List 类型的底层数据结构是由**双向链表或压缩列表**实现的：

- 如果列表的元素个数小于 `512` 个，列表每个元素的值都小于 `64` 字节，使用压缩列表
- 否则使用双向链表
- 3.2版本之后，只使用quicklist作为底层实现（可以理解为是上面两个的结合体）

##### 2.应用场景

- 消息队列
  - List 可以使用 LPUSH + RPOP （或者反过来，RPUSH+LPOP）命令实现消息队列
    - **问题1**：生产者生产之后并不会通知消费者，消费者必须一直调用RPOP
    - 为了解决这个问题，Redis提供了 BRPOP 命令，**BRPOP命令也称为阻塞式读取，客户端在没有读到队列数据时，自动阻塞，直到有新的数据写入队列，再开始读取新数据**。
    - **问题2**：*如何处理重复的消息？*
    - 每个消息都有一个全局的 ID。 **List 并不会为每个消息生成 ID 号，所以我们需要自行为每个消息生成一个全局唯一ID**
    - 比如：LPUSH mq "全局ID:Message"这样
    - **问题3**：*如何保证消息可靠性？*消费者程序从 List 中读取一条消息后，List 就不会再留存这条消息了。所以，如果消费者程序在处理消息的过程出现了故障或宕机，就会导致消息没有处理完成。
    - List 类型提供了 `BRPOPLPUSH` 命令，这个命令的**作用是让消费者程序从一个 List 中读取消息，同时，Redis 会把这个消息再插入到另一个 List（可以叫作备份 List）留存**。
  - 缺点：
    - **List 不支持多个消费者消费同一条消息**
    -  **List 类型并不支持消费组的实现**。



#### 3.Hash

##### 1.基本介绍

Hash 特别适合用于存储对象。Hash 类型的底层数据结构是由**压缩列表或哈希表**实现的：

- 选择同list一样。不过7.0版本
- **压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了**。



##### 2.场景

- 缓存对象 
- 购物车：
  - 添加商品：`HSET cart:{用户id} {商品id} 1`
  - 添加数量：`HINCRBY cart:{用户id} {商品id} 1`
  - 商品总数：`HLEN cart:{用户id}`
  - 删除商品：`HDEL cart:{用户id} {商品id}`
  - 获取购物车所有商品：`HGETALL cart:{用户id}`



#### 4.Set

##### 1.基本介绍

Set 类型是一个无序并唯一的键值集合，一个集合最多可以存储 `2^32-1` 个元素，可以求交集，并集，差集。

Set 类型的底层数据结构是由**哈希表或整数集合**实现的：

- 如果集合中的元素都是整数且元素个数小于 `512` ，Redis 会使用**整数集合**作为 Set 类型的底层数据结构
- 否则使用hash表

##### 2.应用场景

Set 类型比较适合用来数据去重和保障数据的唯一性，还可以用来统计多个集合的交集、错集和并集。但是**Set 的差集、并集和交集的计算复杂度较高，在数据量较大的情况下，如果直接执行这些计算，会导致 Redis 实例阻塞**。（在主从模式中，通常使用从库完成聚合统计操作）

- 点赞： SADD article:1 uid:1 uid:2 用户1和2都给文章1点赞
- 共同关注
- 抽奖活动

#### 5.Zset

##### 1.基本介绍

Zset 类型（有序集合类型）相比于 Set 类型多了一个排序属性 score（分值）

Zset 类型的底层数据结构是由**压缩列表或跳表**实现的：

- 如果有序集合的元素个数小于 `128` 个，并且每个元素的值小于 `64` 字节时，Redis 会使用**压缩列表**（**Redis 7.0**， **listpack** 替代了压缩列表）
- 否则，Redis 会使用**跳表**作为 Zset 类型的底层数据结构；



##### 2.应用场景

- 排行榜
- 电话排序、姓名排序



#### 6.BitMap

Bitmap，即位图，是一串连续的二进制数组（0和1），可以通过偏移量（offset）定位元素。特别适合一些数据量大且使用**二值统计的场景**。



### 面试题

#### 1.认识redis

##### 1.什么是redis

- redis是基于内存的数据库，对数据的读写操作在内存中完成，读写速度非常快，常用做缓存、消息队列、分布式锁
- redis提供了多种数据类型来支持不同的业务场景，比如string、hash、List、set、zset、Bitmaps、hyperLoglog、GEO、Stream，对这些类型的操作都是原子性的，单线程执行，没有并发竞争的问题
- 除此之外，redis还支持事务、持久化、Lua脚本、多种集群方案、发布/订阅、内存淘汰、过期删除等机制

##### 2.Redis和Memcached的区别

- Redis支持更加丰富的数据类型，而Mem只支持key/value
- Redis支持持久化、Mem不支持
- Redis有容灾处理，内存满了会将数据存放在硬盘中，Mem会抛出异常
- Redis有原生的集群模式，Memcached 没有原生的集群模式，需要依靠客户端来实现
- Redsi支持发布订阅、Lua脚本、事务等功能，Mem不支持

##### 3.五种常见的数据类型的实现

- string：String 类型的底层的数据结构实现主要是 SDS（简单动态字符串）
  - SDS不仅可以保存文本数据，还能保留二进制数据。因为SDS用len来判断字符串是否结束而不是空字符，并且SDS的API都会以处理二进制的方式来处理SDS存放在buf[]里的数据
  - SDS获取长度的时间复杂度为O（1）
  - Redis中的SDS API是安全的，拼接字符串不会造成缓冲区溢出。右

#### Redis线程模型

##### Redis是单线程吗？

**Redis 单线程指的是「接收客户端请求->解析请求 ->进行数据读写等操作->发送数据给客户端」这个过程是由一个线程（主线程）来完成的**

redis并不是单线程的，在启动的时候，会启动后台线程：

- redis2.6，会启动两个后台线程，分别处理**关闭文件、AOF刷盘**两个操作
- Redis4.0之后，新增一个新的后台线程，用来异步释放redis内存，也就是 lazyfree 线程。
  - 执行 unlink key / flushdb async / flushall async 等命令，会用到上面的线程，不会阻塞主线程
  - 执行大key删除的时候，不要用del，因为 del 是在主线程处理，可以使用 unlink 命令来异步删除大key

因为`关闭文件、AOF刷盘、释放内存`等操作比较耗时，如果用主线程来执行，会导致主线程阻塞。

可以理解为生产者-消费者。生产者创建后台任务，消费者（BIO）去队列里面拿出来处理，这里用到的BIO的轮询机制

- 关闭文件、AOF 刷盘、释放内存这三个任务都有各自的任务队列，消费者不断的从队列取出任务在后台执行。

![image-20221006221400390](/Users/xuying/Library/Application Support/typora-user-images/image-20221006221400390.png)

##### redis的单线程模型



#### 3.Redis与MySQL双写一致性如何保证？

##### 一致性

- 强一致性：它要求系统写入什么，读出来的也会是什么
- 弱一致性：尽可能地保证到某个时间级别（比如秒级别）后，数据能够达到一致状态：
- 最终一致性：系统会保证**在一定时间内**，能够达到一个数据一致的状态。（弱一致性的特例）

### 缓存

#### 1.为什么用缓存？

- 高性能，用户经常访问的数据放在缓存中，就能很快访问到
- 高并发，数据库每秒查询的次数大概是1w左右，使用redis之后能达到10w

总结：为了提高用户的体验



#### 2.分布式缓存技术选型

redis和memcached

> 比较

共同点：

- 都是基于内存的数据库，用来做缓存
- 都有过期策略
- 性能高

区别：

- redis是单线程的I/O复用模型(6.0之后引入网络读写多线程I/O)，memcached是多线程的

- redis支持复杂的数据类型，memcached只支持key/value

- redis可以持久化，重启的时候可以再次加载，memcached不行

- redis有容灾机制，redis在服务器内存满了之后，可以将数据放到硬盘里，memcached会在内存用完之后抛出异常

- redis支持事务、lua脚本、发布订阅等功能，memcached不支持

- redis支持原生的集群，memcached依赖客户端实现

- 对过期数据，redis的删除策略有定时删除和惰性删除，memcached只使用了惰性删除

  

#### 3.几种缓存问题

##### 1.缓存穿透

定义： 大量请求的key不在缓存中，直接请求到了数据库，压力过大。

解决办法：

- 参数检验，对不合法的参数抛出异常
- 缓存无效的key，设置过期策略  --- 黑客大量构造无效key，进行攻击
- 布隆过滤器  -- 使用过程：
  - 先将可能存在的请求值都放进布隆过滤器中
  - 用户发起请求，先判断请求的key是否在布隆过滤器中，如果在，就查数据
  - 如果不在，就返回请求参数错误给用户

> 布隆过滤器

![image-20210722161507630](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210722161507.png)

其实就是将一个元素(字符串) ，先通过hash，变成一段01组成的位数组。 然后再位数组里面，将1对应的位置置位1。查询有没有元素在里面，只需要将元素hash，然后判断位数组对应的每个位置是否是1，如果都是1，就说明这个元素存在，否则就是不在。

缺点：

- 存在一定的错误。就是这个数本来不在这里面，但是可能会被误判在里面，因为多个元素的位会组合成新的元素。所以存放的元素越多，误判的概率越大。**但是布隆过滤器说元素不在里面，那肯定就不在**
- 不能删除元素：如果一个元素被删除，但是却不能从布隆过滤器中删除，这也是造成假阳性的原因了

##### 2.缓存雪崩

定义：缓存在同一时间大面积的失效，后面的请求都直接落到了数据库上

解决办法：

- redis集群
- 加互斥锁
- 降速限流，避免同时处理大量的请求
- 过期时间设置随机，防止同一时间大面积过期的现象发生



##### 3.缓存击穿

定义：被大量访问的数据(热点缓存)在某个时间失效了，请求到了数据库上，压力太大

解决办法：

- 缓存永不失效
- 加互斥锁



##### 4.缓存预热

缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统，这样就可以避免在用户请求的时候，先查询数据库，然后再将数据回写到缓存。

如果不进行预热， 那么 Redis 初始状态数据为空，系统上线初期，对于高并发的流量，都会访问到数据库中， 对数据库造成流量的压力。

> 操作方法

- 数据量不大的时候，工程启动的时候进行加载缓存动作；
- 数据量大的时候，设置一个定时任务脚本，进行缓存的刷新；
- 数据量太大的时候，优先保证热点数据进行提前加载到缓存。

##### 5.缓存降级

缓存降级是指缓存失效或缓存服务器挂掉的情况下，不去访问数据库，直接返回默认数据或访问服务的内存数据。

在项目实战中**通常会将部分热点数据缓存到服务的内存**中，类似HashMap、Guava这样的工具，一旦缓存出现异常，可以直接使用服务的内存数据，从而避免数据库遭受巨大压力。

当然，这样的操作对于业务是有损害的，分布式系统中很容易就出现数据不一致的问题。



#### 4、redis为什么这么快

- 操作是基于内存的
- IO多路复用，基于epoll/select/kqueue的IO多路复用技术，实现高吞吐的网络IO 。 **linux用的是epoll**
- 单线程模型，避免了多线程频繁上下文切换
- redis内置了多种优化后的数据结构实现，性能非常高

### 事务

#### 1.事务相关的命令

- watch ：  监视指定的kye
- Multi ：   开启一个事务
- unwatch  ：取消watch对所有key的监视
- discard  ： 放弃事务
- exec  ：触发并执行事务中的所有命令



redis事务没有隔离级别的概念。且事务不保证原子性

redis的事务就是使用`multi`开启事务，然后所有的命令就进入一个队列，然后用exec命令，依次执行。

> 事务取消执行

1.可以使用`DISCARD`命令回滚。取消事务

2.编译型异常，命令输入有误，事务里的所有命令都不会执行

==运行时异常，只会让这一个命令失效，其他命令正常执行。比如1/0这种==



#### redis锁

使用watch监控。watch可以看出redis的乐观锁。开启事务之前，先watch一个对象，然后执行过程中，会比较这个对象有没有被修改过。如果被其他线程改过，就会使事务执行失败。

### 持久化

#### 1.RDB(Redis DataBase)

指定的时间间隔，将数据集快照写入磁盘。实际操作过程是fork一个子进程，先将数据集写入临时文件，写入成功后，再替换之前的文件，再二进制压缩存储

优点:

- 容灾性，方便备份
- 性能最大化。fork子进程来写，主进程能够继续处理命令。保证了redis的高性能
- 数据集大的时候，比AOF启动更快

缺点：

- 安全性低。存在时间间隔，如果时间内redis宕机了，那么就丢失数据
- RDB通过fork子进程协助，如果数据集很大的时候，可能会导致整个服务器停止服务几百毫秒甚至1s

> 触发

- 手动触发：save命令，这个是主进程进行RDB持久化操作，会阻塞当前的Redis服务器，知道RDB过程完成，不建议使用
- 自动触发：bgsave方式。一般可以配置多久触发一次，比如xx秒内修改xx次。或者使用shutdown命令，或者从节点全量复制的时候会触发

> bgsave的过程

bgsave是父进程fork出一个子进程进行持久化操作，所以不会影响redis服务器。

![image-20210819111733861](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210819111733.png)

- 执行bgsave命令，Redis父进程判断当前是否存在正在执行的子进程，如果存在，bgsave命令直接返回
- 父进程执行fork操作创建子进程，fork操作过程中父进程会阻塞
- 父进程fork完成后，bgsave命令返回“Background saving started”信息并不再阻塞父进程
- 子进程创建RDB文件，根据父进程内存生成临时快照文件，完成后对原有文件进行原子替换
- 进程发送信号给父进程表示完成，父进程更新统计信息

#### 2.AOF(Append only File)

日志的形式，记录服务器处理的每一个写、删除操作。文本的方式

（1）所有的写入命令会追加到aof_buf（缓冲区）中。

（2）AOF缓冲区根据对应的策略向硬盘做同步操作。

（3）随着AOF文件越来越大，需要定期对AOF文件进行重写，达到压缩的目的。

（4）当Redis服务器重启时，可以加载AOF文件进行数据恢复。

> AOF为什么把命令追加到aof_buf中？

Redis使用单线程响应命令，如果每次写AOF文件命令都直接追加到硬盘，那么性能完全取决于当前硬盘负载。先写入缓冲区aof_buf中，还有另一个好处，Redis可以提供多种缓冲区同步硬盘的策略，在性能和安全性方面做出平衡。



**优点**：

- 数据安全：- 三种同步策略
  - 每秒同步  -- 可能会丢失一秒的数据，redis宕机
  - 每修改同步  --  数据更完整
  - 不同步    -- 效率最高
- append模式写文件，服务器宕机不会破坏已经存在的内容，redis-check-aof可以解决数据一致性的问题
- AOF的rewrite模式，定期对AOF文件重写，压缩--- （**有的命令可以整合**）

> rewrite机制

重写的目的：

- 减小AOF文件占用空间；
- 更小的AOF 文件可以更快地被Redis加载恢复。

AOF重写可以分为手动触发和自动触发：

- 手动触发：直接调用bgrewriteaof命令。
- 自动触发：根据auto-aof-rewrite-min-size和auto-aof-rewrite-percentage参数确定自动触发时机。

**缺点**：

- AOF比RDb大，恢复速度慢
- 启动效率比RDB低
- 运行效率比RDB低，根据同步策略看



`appendonly` 改为yes就开启了 aof！



> Redis4.0支持混合持久化

Redis 4.0 开始支持 RDB 和 AOF 的混合持久化（默认关闭，可以通过配置项` aof-use-rdb-preamble` 开启）。

如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。当然缺点也是有的， AOF 里面的 RDB 部分是压缩格式不再是 AOF 格式，可读性较差。

**如果AOF和RDB都开启了，优先加载AOF文件**

 数据恢复流程说明：

（1）AOF持久化开启且存在AOF文件时，优先加载AOF文件。

（2）AOF关闭或者AOF文件不存在时，加载RDB文件。

（3）加载AOF/RDB文件成功后，Redis启动成功。

（4）AOF/RDB文件存在错误时，Redis启动失败并打印错误信息。





### 过期时间

#### 1.为什么要设计过期时间

- 缓解内存的消耗
- 某些特定场景需要(验证码等)



#### 2.redis如何判断数据是否过期

redis通过一个过期字典保存数据过期的时间

```c
typedef struct redisDb {
    ...

    dict *dict;     //数据库键空间,保存着数据库中所有键值对
    dict *expires   // 过期字典,保存着键的过期时间
    ...
} redisDb;
```

![image-20210722164654876](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210722164654.png)

#### 3.过期数据的删除策略

**定期删除**：redis默认是每隔100ms就随机抽取一些设置了过期时间的key，检查其是否过期，如果过期就删除。为什么要随机呢?假如redis存了几十万个key，每隔100ms就遍历所有的设置过期时间的key的话，就会给CPU带来很大的负载。

**惰性删除**：定期删除是随机选取key，所以有的key没有被删掉，这样的话，只有你的系统去查一下那个key，才会被redis删除

定期删除对内存更加友好，惰性删除对 CPU 更加友好。于是redis就两者结合起来



但是实际上这还是有问题的，如果定期删除漏掉了很多过期key，然后你也没及时去查，也就没走惰性删除，此时会怎么样？ 　如果大量过期key堆积在内存里，导致redis内存块耗尽了，怎么办？

答案：**走内存淘汰机制。**

#### 4、八种内存淘汰机制

volatile-lru（least recently used）：从设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据，淘汰
volatile-ttl：从设置过期时间的数据集中挑选要过期的数据，淘汰
volatile-random：从已设置过期时间的数据集中任意选择数据淘汰
allkeys-lru（least recently used）：在键空间中移除最近最少使用的key
allkeys-random：数据集中任意淘汰数据
no-eviction：内存不足容纳写入数据时，新写入操作会报错
-- 这两个是4.0后增加的
volatile-lfu（least frequently used）：从已设置过期时间的数据集中挑选最不经常使用的数据淘汰
allkeys-lfu（least frequently used）：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key



### 线程模型

#### 1、Redis 单线程模型详解  

-- 看一下nio那些，现在不会

#### 2、Redis 没有使用多线程？为什么不使用多线程？

实际上，**Redis 在 4.0 之后的版本中就已经加入了对多线程的支持。** Redis 4.0 增加的多线程主要是针对一些大键值对的删除操作的命令，使用这些命令就会使用主处理之外的其他线程来“异步处理”。

>**Redis6.0 之前 为什么不使用多线程？**

1. 单线程编程容易并且更容易维护；
2. Redis 的性能瓶颈不在 CPU ，主要在内存和网络；
3. 多线程就会存在死锁、线程上下文切换等问题，甚至会影响性能。

> Redis6.0 之后为何引入了多线程？

**Redis6.0 引入多线程主要是为了提高网络 IO 读写性能**，因为这个算是 Redis 中的一个性能瓶颈（Redis 的瓶颈主要受限于内存和网络）。

### 集群

#### 主从复制

是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master/leader)，后者称为从节点(slave/follower)； **数据的复制是单向的**，只能由主节点到从节点。

主从复制的作用：

- 数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。
- 故障恢复：主节点出现问题，可以由从节点提供服务，服务冗余
- 负载均衡：配合上读写分离，主机提供写服务，从机提供读服务，可以提高并发量
- 高可用(集群)基石：主从复制 是哨兵和集群能够实施的基础。

> 实现原理

- 连接建立阶段：在主从节点之间建立连接，为数据同步做好准备。

  - **从节点执行slaveof**，这个命令是异步的，从节点立即向客户端返回ok，然后在内部维护两个字段，masterhost和masterport字段，用于存储主节点的ip和port信息

  - **建立socket连接**：从节点每秒调用函数，如果发现有主节点可以连接，就根据主节点的ip和port建立socket连接，从节点为该socket建立一个专门处理复制工作的文件事件处理器 。 主节点接收到从节点的socket连接后（即accept之后），为该socket创建相应的客户端状态，并将从节点看做是连接到主节点的一个客户端

  - **发送ping命令**：从节点发送ping进行首次请求，检查socket连接是否可用。可能会有下面三种情况

    - （1）返回pong：说明socket连接正常，且主节点当前可以处理请求，复制过程继续。

      （2）超时：一定时间后从节点仍未收到主节点的回复，说明socket连接不可用，则从节点断开socket连接，并重连。

      （3）返回pong以外的结果：如果主节点返回其他结果，如正在处理超时运行的脚本，说明主节点当前无法处理命令，则从节点断开socket连接，并重连

  - **身份验证**：如果从节点中设置了masterauth选项，则从节点需要向主节点进行身份验证；从节点进行身份验证是通过向主节点发送auth命令进行的，auth命令的参数即为配置文件中的masterauth的值。如果主节点设置密码的状态，与从节点masterauth的状态一致(密码相同)，则身份验证通过，复制过程继续；如果不一致，则从节点断开socket连接，并重连。

  - **发送从节点端口信息**：从节点发送自己的端口号，主节点保存到该从节点对应的客户端的slave_listening_port字段。

- 数据同步阶段：从节点向主节点发送psync命令（Redis2.8以前是sync命令），开始同步。数据同步阶段是主从复制最核心的阶段，根据主从节点当前状态的不同，可以分为全量复制和增量复制。

- 命令传播阶段：数据同步阶段完成后，主从节点进入命令传播阶段；在这个阶段主节点将自己执行的写命令发送给从节点，从节点接收命令并执行，从而保证主从节点数据的一致性。**命令传播是异步的过程，即主节点发送写命令后并不会等待从节点的回复**；因此实际上主从节点之间很难保持实时的一致性，延迟在所难免。





一主二从，多个从机，一个主机。

如果主机挂掉了，怎么办？  可以其他的从机自己升级`SLAVEOF no one`



优点：

- 读写分离，减少了主节点压力

缺点：

- Redis不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要人工恢复
- 主机宕机，宕机前有部分数据未能及时同步到从机，切换后还会引入数据不一致的问题
- 如果多个从节点宕机了，不要在同一时间段重启，因为重启要发送sync请求和主机全量同步，会导致主节点IO增加，引起宕机
- Redis 较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂；

#### 哨兵模式

主从切换技术的方法是：当主服务器宕机后，需要手动把一台从服务器切换为主服务器，这就需要人工 干预，费事费力，还会造成一段时间内服务不可用。

哨兵模式是一种特殊的模式，首先Redis提供了哨兵的命令，哨兵是一个独立的进程，作为进程，它会独
立运行。其原理是哨兵通过发送命令，等待Redis服务器响应，从而监控运行的多个Redis实例。

一个哨兵可能会出问题，加上多个哨兵，每个哨兵之间也互相监督

![image-20210722171518274](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210722171518.png)

> 心跳机制



- sentinel是特殊的Redis节点，哨兵模式创建时，需要通过配置指定 Sentinel 与 Redis Master Node 之间的关系**， Sentinel 会从主节点上获取所有从节点的信息**，然后定时向主节点和从节点发送 info 命令获取其拓扑结构和状态信息。

- 基于 Redis 的订阅发布功能， 每个 Sentinel 节点会向主节点的 `sentinel：hello `频道上发送该 Sentinel 节点对于主节点的判断以及当前 Sentinel 节点的信息 ，同时每个 Sentinel 节点也会订阅该频道， 来获取其他 Sentinel 节点的信息以及它们对主节点的判断。



通过以上两步所有的 Sentinel 节点以及它们与所有的 Redis 节点之间都已经彼此感知到，之后每个 Sentinel 节点会向主节点、从节点、**以及其余 Sentinel 节点**定时发送 **ping 命令作为心跳检测， 来确认这些节点是否可达**。



> 下线

每个 Sentinel 都会定时进行心跳检查，当发现主节点出现心跳检测超时的情况时，此时认为该主节点已经不可用，这种判定称为**主观下线**。之后这个Sentinel 会发送命令给其他Sentinel 节点询问对这个主节点的判断，当quorum(一般是Sentinel的1/2 +1，半数以上)个Sentinel 认为这个节点故障，就执行**客观下线**。



之后： Sentinel 节点之间会再做一次选举工作， 基于 **Raft 算法**选出一个` Sentinel 领导者`来进行故障转移的工作。

- 选一个节点作为新节点
- Sentinel 领导者节点会对选出来的从节点执行 slaveof no one 命令让其成为主节点。
- Sentinel 领导者节点会向剩余的从节点发送命令，让他们从新的主节点上复制数据。
- Sentinel 领导者会将原来的主节点更新为从节点， 并对其进行监控， 当其恢复后命令它去复制新的主节点。

> Sentinel怎么选出master

筛选出所有在线的slave，然后按照下面的标准进行选取

- slave 优先级 ：设置节点的优先级，优先级最高的直接变成master。如果没有优先级最高的，再判断复制进度
  - 可以通过 slave-priority 手动设置 slave 的优先级。
- 复制进度 ：Sentinel 总是希望选择出数据最完整（与旧 master 数据最接近）也就是复制进度最快的 slave 被提升为新的 master。
- runid(运行 id) ：如果有多个 slave 的优先级和复制进度一样的话，那就 **runid 小的成为新的 master**，每个 redis 节点启动时都有一个 40 字节随机字符串作为运行 id。（通常前两种就已经能够选出来了）

> 优缺点

优点：

- 系统可用性更好
- 这是主从模式的升级，更加健壮

缺点：

- 配置比较复杂
- edis较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。

#### Cluster集群

不管是主从模式还是哨兵模式都只能由一个master在写数据，在海量数据高并发场景，一个节点写数据容易出现瓶颈，引入Cluster模式可以实现多个节点同时写数据。

Redis 的哨兵模式基本已经可以实现高可用，读写分离 ，但是在这种模式下每台 Redis 服务器都存储相同的数据，很浪费内存，所以在 redis3.0上加入了 Cluster 集群模式，实现了 Redis 的分布式存储，**也就是说每台 Redis 节点上存储不同的内容**。

Redis-Cluster采用无中心结构，每个节点都保存数据，节点之间互相连接从而知道整个集群状态。



redis cluster ： 多个master组成集群，然后每个master又基于主从复制，会带着slave节

功能： **负载均衡，故障切换，主从复制**



Redis 集群没有使用一致性 hash，而是引入了哈希槽【hash slot】的概念。

##### Redis哈希槽

Redis 集群有16384 个哈希槽，每个 key 通过 CRC16 校验后对 16384 取模来决定放置哪个槽。集群的每个节点负责一部分hash槽，举个例子，比如当前集群有3个节点，那么：

- 节点 A 包含 0 到 5460 号哈希槽
- 节点 B 包含 5461 到 10922 号哈希槽
- 节点 C 包含 10923 到 16383 号哈希槽

当redis客户端设置值时，会拿key进行CRC16算法，然后 跟16384取模。`slot = CRC16(key) & 16383`  根据记录就能找出是哪个节点管理这个槽。

```
这样使用，我们为每个节点创建一个jedis对象实例，然后通过slots.get（ slot）就能获取到对应槽的节点的连接jedis，然后进行操作
```



这种结构很容易添加或者删除节点。比如如果我想新添加个节点 D ， 我需要从节点 A， B， C 中得部分槽到 D 上。如果我想移除节点 A ，需要将 A 中的槽移到 B 和 C 节点上，然后将没有任何槽的 A 节点从集群中移除即可。





#### redis集群最大个数

16384



#### redis分布式锁

使用setnx来争抢锁，抢到之后用expire加一个过期时间，免得忘了释放。

> 如果执行expire前进程意外挂掉了怎么办

可以用setnxExp ，就是setnx和expire合成为一个的指令，忘了叫啥名



#### redis集群数量常用配置

> 主从复制

1主2从

> 哨兵

1主2从3哨兵

> 集群模式

3主3从

### 缓存读写策略

#### 3种常用的缓存读写策略

##### 1.Cache Aside Pattern 旁路缓存

Cache Aside Pattern 是我们平时使用比较多的一个缓存读写模式，**比较适合读请求比较多的场景。**

Cache Aside Pattern 中服务端需要同时维系 DB 和 cache，并且是以 DB 的结果为准。

读写步骤：

- 写
  - 先更新DB
  - 直接删除cache
- 读
  - 从cache中读取数据，读取到就直接返回
  - 没有，就去DB中找
  - 把数据放入cache

> 为什么先删除cache而不是更新cache

- **对服务端资源造成浪费**：
- 产生数据不一致问题 

> 提问： 写数据可以先删缓存再更新DB吗

不行，会造成数据不一致的问题。

- 请求1删除缓存
- 请求2读数据A，没有缓存，更新到cache里
- 请求1更新DB

这时候，缓存里的A就是原来的旧值，可能会有问题



=》 那么先更新DB再删缓存就一定没问题？

**answer**：理论上来说还是可能会出现数据不一致性的问题，不过概率非常小，因为缓存的写入速度是比数据库的写入速度快很多！

> 模式的缺点

- 首次请求数据一定不在cache中
  - 解决办法：热点数据提前放入cache中
- 写操作比较频繁，会cache中的数据会被频繁删除，就会影响缓存命中率
  - 两种场景下的解决办法如下
  - **数据库和缓存数据强一致场景** ：更新DB的时候同样更新cache，不过我们需要加一个**锁/分布式锁**来保证更新cache的时候不存在线程安全问题。
  - 可以**短暂地允许数据库和缓存数据不一致**的场景 ：更新DB的时候同样更新cache，但是给缓存**加一个比较短的过期时间**，这样的话就可以保证即使数据不一致的话影响也比较小。



##### 2.Read/write through pattern 读写穿透

Read/Write Through Pattern 中服务端把 cache 视为主要数据存储，从中读取数据并将数据写入其中。cache 服务负责将此数据读取和写入 DB

- 写：
  - 先查cache，cache不存在，直接更新DB(在DB里面修改，不更新cache)
  - cache存在，先更新cache，然后cache服务自己更新DB和cache
- 读
  - 从cache中读，读到就返回
  - 读不到，就去DB加载，写入到cache然后返回响应

和 Cache Aside Pattern 一样， Read-Through Pattern 也有首次请求数据一定不再 cache 的问题，对于热点数据可以提前放入缓存中。

##### 3.Write Behind Pattern（异步缓存写入）

和Read/write through pattern很像，都是用cache来负责cache和DB的读写

也有很大的区别：Read/write through pattern是同步更新cache和DB的。而write behind pattern则是异步更新，先更新完cache，**再用异步批量的方式来更新 DB**。

会存在还没更新完DB，cache挂掉的风险。

**优点**： 写性能非常高，适合用于数据一致性要求不高的地方。比如浏览量、点赞量等



### 性能

#### redis常见性能问题

- Master最好不要写内存快照，save调度rdbSave函数，会阻塞主线程工作
- 数据比较重要的话，Slave开启AOF备份，设置为每秒同步
- 避免在压力很大的主库上增加从库

#### 加入Redis里面有1亿个key，其中有10w个key是以固定的前缀开头，如何找出来

使用keys指令 。

> 如果这个redis正在提供服务，使用keys会有什么问题

redis是单线程的，keys指令会导致线程阻塞一段时间，线上服务会停顿，一直到指令执行完毕，服务才能恢复。那么我们可以scan指令，scan可以无阻塞的提取出指定模式的key列表，会有一定的重复，做一次去重就可以了。时间花费会比keys长



# Kafka

#### 1.发布订阅模型



#### 2.kafka重复消费

> why does it repeat?

the data that  already consumed on the server-side was not successfully submitted in offset(consumer downtime)

> how to solve the problem of repeated consumption ?

- Idempotent checks(幂等校验),such as redis's set , mysql's primary key

- 关闭自动提交，改为手动提交，怎么



# Spring

#### 1.springboot的自动配置原理

自动装配可以简单理解为：**通过注解或者一些简单的配置就能在 Spring Boot 的帮助下实现某块功能。**

先看一下 SpringBoot 的核心注解 `SpringBootApplication`  

上面那个注解里面有 `@Configuration`、`@EnableAutoConfiguration`、`@ComponentScan` 注解的集合



- `@EnableAutoConfiguration`：启用 SpringBoot 的自动配置机制   **是实现自动装配的重要注解，我们以这个注解入手**
- `@Configuration`：允许在上下文中注册额外的 bean 或导入其他配置类
- `@ComponentScan`： 扫描被`@Component` (`@Service`,`@Controller`)注解的 bean，注解默认会扫描启动类所在的包下所有的类 ，可以自定义不扫描某些 bean。



@EnableAutoConfiguration 有AutoConfigurationImportSelector，

自动装配核心功能的实现实际是通过 `AutoConfigurationImportSelector`类。 加载自动装配类

`AutoConfigurationImportSelector` 类里面有个方法 (`selectImports`方法)，该方法主要用于**获取所有符合条件的类的全限定类名，这些类需要被加载到 IoC 容器中**。



#### [1.Spring AOP 和 AspectJ AOP 有什么区别？](https://snailclimb.gitee.io/javaguide/#/docs/system-design/framework/spring/Spring常见问题总结?id=spring-aop-和-aspectj-aop-有什么区别？)

**Spring AOP 属于运行时增强，而 AspectJ 是编译时增强。** Spring AOP 基于代理(Proxying)，而 AspectJ 基于字节码操作(Bytecode Manipulation)。

Spring AOP 已经集成了 AspectJ ，AspectJ 应该算的上是 Java 生态系统中最完整的 AOP 框架了。AspectJ 相比于 Spring AOP 功能更加强大，但是 Spring AOP 相对来说更简单，

如果我们的切面比较少，那么两者性能差异不大。但是，当切面太多的话，最好选择 AspectJ ，它比 Spring AOP 快很多





### SpringBean

#### springBean的作用域

- **singleton** : 唯一 bean 实例，Spring 中的 bean 默认都是单例的，对单例设计模式的应用。
- **prototype** : 每次请求都会创建一个新的 bean 实例。
- **request** : 每一次 HTTP 请求都会产生一个新的 bean，该 bean 仅在当前 HTTP request 内有效。
- **session** : 每一次 HTTP 请求都会产生一个新的 bean，该 bean 仅在当前 HTTP session 内有效。
- **global-session** ： 全局 session 作用域，仅仅在基于 portlet 的 web 应用中才有意义，Spring5 已经没有了。Portlet 是能够生成语义代码(例如：HTML)片段的小型 Java Web 插件。它们基于 portlet 容器，可以像 servlet 一样处理 HTTP 请求。但是，与 servlet 不同，每个 portlet 都有不同的会话。



#### [@Component 和 @Bean 的区别是什么？](https://snailclimb.gitee.io/javaguide/#/docs/system-design/framework/spring/Spring常见问题总结?id=component-和-bean-的区别是什么？)

1. `@Component` 注解作用于类，而`@Bean`注解作用于方法。
2. `@Component`通常是通过类路径扫描来自动侦测以及自动装配到 Spring 容器中（我们可以使用 `@ComponentScan` 注解定义要扫描的路径从中找出标识了需要装配的类自动装配到 Spring 的 bean 容器中）。`@Bean` 注解通常是我们在标有该注解的方法中定义产生这个 bean,`@Bean`告诉了 Spring 这是某个类的实例，当我需要用它的时候还给我。
3. `@Bean` 注解比 `@Component` 注解的自定义性更强，而且很多地方我们只能通过 `@Bean` 注解来注册 bean。比如当我们引用第三方库中的类需要装配到 `Spring`容器时，则只能通过 `@Bean`来实现。

#### Bean的生命周期

![image-20210908161818758](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210908161818.png)



#### Spring框架中有哪些设计模式

- **工厂设计模式** : Spring 使用工厂模式通过 `BeanFactory`、`ApplicationContext` 创建 bean 对象。
- **代理设计模式** : Spring AOP 功能的实现。

- **单例设计模式** : Spring 中的 Bean 默认都是单例的。

### [Spring 事务](https://snailclimb.gitee.io/javaguide/#/docs/system-design/framework/spring/Spring常见问题总结?id=spring-事务)

#### Spring 管理事务的方式有几种？

- **编程式事务** ： 在代码中硬编码(不推荐使用) : 通过 `TransactionTemplate`或者 `TransactionManager` 手动管理事务，实际应用中很少使用，但是对于你理解 Spring 事务管理原理有帮助。
- **声明式事务** ： 在 XML 配置文件中配置或者直接基于注解（推荐使用） : 实际是通过 AOP 实现（基于`@Transactional` 的全注解方式使用最多）



#### Spring事务的传播级别

***\*PROPAGATION_REQUIRED\**** ，默认的spring事务传播级别，如果上下文中已经存在事务，那么就加入到事务中执行，如果当前上下文中不存在事务，则新建事务执行。

***\*PROPAGATION_REQUIRES_NEW\**** ，每次都要一个新事务，该传播级别的特点是，每次都会新建一个事务，并且同时将上下文中的事务挂起，执行当前新建事务完成以后，上下文事务恢复再执行。

***\*PROPAGATION_SUPPORTS\**** ，如果上下文存在事务，则支持事务加入事务，如果没有事务，则使用非事务的方式执行。

***\*PROPAGATION_NOT_SUPPORTED\**** ，上下文中存在事务，则挂起事务，执行当前逻辑，结束后恢复上下文的事务。

***\*PROPAGATION_MANDATORY\**** ， 该级别的事务要求上下文中必须要存在事务，否则就会抛出异常！

***\*PROPAGATION_NEVER\****，上下文中不能存在事务，一旦有事务，就抛出runtime异常，强制停止执行！

***\*PROPAGATION_NESTED\**** ，如果上下文中存在事务，则嵌套事务执行，如果不存在事务，则新建事务。



> 什么是嵌套事务

子事务套在父事务中执行，子事务是父事务的一部分，在进入子事务之前，父事务建立一个回滚点，叫save point，然后执行子事务，这个子事务的执行也算是父事务的一部分，然后子事务执行结束，父事务继续执行。

- ***如果子事务回滚，会发生什么？\**** 
  - 父事务会回滚到进入子事务前建立的save point，然后尝试其他的事务或者其他的业务逻辑，父事务之前的操作不会受到影响，更不会自动回滚

- ***\*如果父事务回滚，会发生什么？\**** 
  - 父事务回滚，子事务也会跟着回滚！为什么呢，因为父事务结束之前，子事务是不会提交的，我们说子事务是父事务的一部分，正是这个道理。
- ***\*事务的提交，是什么情况？\**** 
  - 子事务先提交，父事务再提交





# Netty

Netty的异步不是异步IO而是 调用异步，使用IO多路复用，然后

#### 1.Netty是什么？

- netty是一个基于NIO的C/S框架，用它可以快速简单的开发网络应用程序
- 简化了TCP和UDP套接字服务器等网络编程，性能和安全性也更好
- 支持多种协议  - FTP、SMTP、HTTp等

#### 2.为什么用Netty

 Netty 具有下面这些优点

- 简单性能高
- 自带编码器解决TCP 沾包/拆包问题
- 安全性高
- 社区活跃，比较稳定
- 很多开源项目都用了，比如Dubbo、RocketMQ

#### 3.Netty 应用场景了解么？

- RPC框架的网络通信工具
- HTTp服务器
- 即使通讯系统
- 消息推送系统



#### 4、Netty的核心组件

- Channel：包含基本的IO操作，bind、connect、read、write。常用的实现类是NioServerSocketChannel （服务端）和 NioSocketChannel。分别对应 ServerSocket 以及 Socket
- EventLoop： 负责监听⽹络事件并调⽤**事件处理器(handler)**进⾏相关 I/O 操 作的处理,相当于反应器模式里面的reactor，EventLoop 负责处理注册到其上的 Channel
- ChannelFuture：Netty 是异步⾮阻塞的，所有的 I/O 操作都为异步的。你可以通过 ChannelFuture 接⼝的 addListener() ⽅法注册⼀个 ChannelFutureListener ，当操作执⾏成功或者失败时，监听就会⾃动触发返回结果。我们还可以通过 ChannelFuture 接⼝的 sync() ⽅法让异步的操作变成同步的。
- ChannelHandler 和 ChannelPipeline
  - ChannelHandler 是消息的具体处理器，负责处理读写操作、客户端连接等事情。
  - ChannelPipeline 为 ChannelHandler 的链，提供了⼀个容器并定义了⽤于沿着链传播⼊站和出站 事件流的 API 。通过 addLast() ⽅法添加⼀个或者多个 ChannelHandler ，因为⼀ 个数据或者事件可能会被多个 Handler 处理

#### 5、EventLoop中设置的线程数

```java
// 方法最后是运行的这个方法，可以看到当设置为0 的时候去找默认的 DEFAULT_EVENT_LOOP_THREADS 数量
protected MultithreadEventLoopGroup(int nThreads, Executor executor, Object... args) {
    super(nThreads == 0 ? DEFAULT_EVENT_LOOP_THREADS : nThreads, executor, args);
}  


private static final int DEFAULT_EVENT_LOOP_THREADS;
// 这个默认的数量在静态方法中设置为cpu核数的两倍，netty运行时获得
DEFAULT_EVENT_LOOP_THREADS = Math.max(1, SystemPropertyUtil.getInt(
                "io.netty.eventLoopThreads", NettyRuntime.availableProcessors() * 2));

```



# Zookeeper



### 1.基础

#### 1.Zookeeper的特点

![image-20210811154037264](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210811154037.png)



leader进行写，follower读。

为什么适合奇数，因为5台挂了三台就不能用，6台集群也是挂三台就不能用，浪费了一台。所以更适合奇数台



#### 2.数据结构

![image-20210811154935005](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210811154935.png)

#### 3.应用场景

![image-20210811155015293](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210811155015.png)



> 统一命名服务

![image-20210811155152942](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210811155153.png)

> 统一配置管理

![image-20210811155301909](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210811155302.png)



> 统一集群管理

![image-20210811155413689](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210811155413.png)

管理集群的状态。

> 软负载均衡

![image-20210811185348597](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210811185348.png)







### 4、源码分析

#### 1.算法基础

##### 1.1 拜占庭将军问题

将军们必须全体一致是否攻击某一支敌军，然后各个将军的部队都是分离的，里面有叛徒。必须所有的将军都同意，才能做出决定。

##### 1.2 Paxos算法

![image-20210813205226484](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210813205226.png)

##### ZAB协议

在Paxos算法上改进的协议，Zookeeper用的是这个  ==两阶段提交==



![image-20210813210403079](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210813210403.png)

![image-20210813210438539](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210813210438.png)



> 崩溃恢复-异常假设

两种情况：

- leader在commit发出去之后，挂了，所有的follower必须提交
- leader在commit还没有发就挂了，那么提案就丢掉

> 崩溃恢复 - leader选举

![image-20210813210828824](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210813210828.png)



> 数据恢复

![image-20210813210952128](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210813210952.png)

### CAP理论

#### 1.ZooKeeper 是什么？

ZooKeeper 是一个分布式协调服务，它是集群的管理者，监视着集群中各个节点的状态根据节点提交的反馈进行下一步合理操作。最终，将简单易用的接口和性能高效、功能稳定的系统提供给用户。
ZooKeeper 为我们提供了高可用、高性能、稳定的分布式数据一致性解决方案，通常被用于实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master 选举、分布式锁和分布式队列等功能。**ZooKeeper 将数据保存在内存中，性能是非常棒的。**

客户端的读请求可以被集群中的任意一台机器处理，对于写请求，这些请求会同时发给其他 zookeeper 机器并且达成一致后，请求才会返回成功。因此，随着 zookeeper 的集群机器增多，读请求的吞吐会提高但是写请求的吞吐会下降。



有序性是 zookeeper 中非常重要的一个特性，所有的更新都是全局有序的，每个更新都有一个唯一的时间戳，这个时间戳称为 zxid（Zookeeper Transaction Id）

#### Zookeeper特点

- **顺序一致性：** 从同一客户端发起的事务请求，最终将会严格地按照顺序被应用到 ZooKeeper 中去。
- **原子性：** 所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，也就是说，要么整个集群中所有的机器都成功应用了某一个事务，要么都没有应用。
- **单一系统映像 ：** 无论客户端连到哪一个 ZooKeeper 服务器上，其看到的服务端数据模型都是一致的。
- **可靠性：** 一旦一次更改请求被应用，更改的结果就会被持久化，直到被下一次更改覆盖。

#### 2.zookeeper的文件系统

Zookeeper 提供一个多层级的节点命名空间（节点称为 znode）。与文件系统不同的是，**这些节点都可以设置关联的数据**，而文件系统中只有文件节点可以存放数据而目录节点不行。Zookeeper 为了保证高吞吐和低延迟，在内存中维护了这个树状的目录结构，所以Zookeeper 不能用于存放大量的数据，每个节点的存放数据上限为1M。

#### zookeeper应用场景

- 分布式锁：创建唯一节点获得分布式锁，当获得锁的一方执行完相关代码或者是挂掉之后就释放锁。
- **命名服务** ：可以通过 ZooKeeper 的顺序节点生成全局唯一 ID
- **数据发布/订阅** ：通过 **Watcher 机制** 可以很方便地实现数据发布/订阅。当你将数据发布到 ZooKeeper 被监听的节点上，其他机器可通过监听 ZooKeeper 上节点的变化来实现配置的动态更新。

### 基本概念



#### 数据模型

ZooKeeper 数据模型采用层次化的多叉树形结构，每个节点上都可以存储数据，这些数据可以是数字、字符串或者是二级制序列。每个node可以存1M

![image-20210822130851841](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210822130858.png)

#### 数据节点

> Znode四种类型

- **持久（PERSISTENT）节点** ：一旦创建就一直存在即使 ZooKeeper 集群宕机，直到将其删除。
- **临时（EPHEMERAL）节点** ：临时节点的生命周期是与 **客户端会话（session）** 绑定的，**会话消失则节点消失** 。并且，**临时节点只能做叶子节点** ，不能创建子节点。
- **持久顺序（PERSISTENT_SEQUENTIAL）节点** ：除了具有持久（PERSISTENT）节点的特性之外， 子节点的名称还具有顺序性。比如 `/node1/app0000000001` 、`/node1/app0000000002` 。
- **临时顺序（EPHEMERAL_SEQUENTIAL）节点** ：除了具备临时（EPHEMERAL）节点的特性之外，子节点的名称还具有顺序性。

> znode数据结构

每个 znode 由 2 部分组成:

- **stat** ：状态信息
  - cZxid	create ZXID，即该数据节点被创建时的事务 id
  - mZxid	modified ZXID，即该节点最终一次更新时的事务 id
  - aclVersion	节点的 ACL 版本号，表示该节点 ACL 信息变更次数
- **data** ： 节点存放的数据的具体内容

> ACL (权限控制)

对于 znode 操作的权限，ZooKeeper 提供了以下 5 种：

- **CREATE** : 能创建子节点
- **READ** ：能获取节点数据和列出其子节点
- **WRITE** : 能设置/更新节点数据
- **DELETE** : 能删除子节点
- **ADMIN** : 能设置节点 ACL 的权限



### 1.Zookeeper的选举制度

> 第一次初始化的时候

假设有五台机器，需要上线三台才能选举成功

- 首先，第一台服务器上线，投票给自己，未到半数以上
- 然后第二台上线，都投给自己，并交换选票的信息，此时第一台服务器发现另外一台的myid大于自己的，就把选票给了第二台服务器
- 第三台服务器上线，投给了自己，交换选票信息，第二台发现第三台的myid大于自己的，就把选票给第三台了，此时选票数大于半数，leader选举成功。
- 此时如果有第四台上线，投给自己，因为第三台的票数》第四台的，直接成为follower，并把选票给leader

> 非第一次启动的情况

无服务运行期间无法和leader保持连接： 两种情况

- 集群中有leader但是连接不上
  - 想去选举的话，其他机器会告诉他leader还在，你要去继续尝试连接
- 集群中的leader挂掉了



![image-20210811192916829](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210811192916.png)

字段的意思：

- SID，服务器的ID，用来标识集群中的机器
- ZXID，事务ID，就是标识这个服务器状态变更的次数，比如做了一次操作就加1
- Epoch，投票的次数，比如初始化之后，他们就是1，第二次投票就变成2了

leader挂掉按照下面的步骤选取：

假设有五台机器，SID分别是1,2,3,4,5 ，ZXID分别是8,8,8,7,7. 然后SID为3的机器是Leader，此时，3和5号机器挂掉了，开始进行Leader选举

![image-20210811193130016](https://xy-picgo.oss-cn-shenzhen.aliyuncs.com/20210811193130.png)

EPOCH越大代表他存在的时间越长，
